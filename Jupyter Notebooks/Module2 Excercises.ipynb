{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb696c68-5487-46df-82c5-4e8db0dfb9a3",
   "metadata": {},
   "source": [
    "# A: Where Data Comes From"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b8e759-0b72-4241-822b-ec46203fe341",
   "metadata": {},
   "source": [
    "This section will cover the main places data comes from, what assumptions each source bakes in, and how to do a quick *source audit* before cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc5ca67-4ce9-4595-9cd7-682db17e8930",
   "metadata": {},
   "source": [
    "## A.1 Files: CSV, JSON, Excel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd08049-78c9-4d9b-ac5a-552a20e6c864",
   "metadata": {},
   "source": [
    "Flat files are common, portable, and simple\n",
    "\n",
    "**What these formats are good at:**\n",
    "<table style=\"text-align=left\";>\n",
    "    <tr>\n",
    "        <th>Format</th>\n",
    "        <th>Best suited for</th>\n",
    "        <th>Common misuse</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>CSV</th>\n",
    "        <th>Simple rectangular tables; system exports; quick sharing</th>\n",
    "        <th>Encoding complex structure or multiple tables in one file</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Excel</th>\n",
    "        <th>Human-facing analysis, manual edits, reporting</th>\n",
    "        <th>Using as a source of truth or automated data pipeline input</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>JSON</th>\n",
    "        <th>Nested or semi-structured records; API responses</th>\n",
    "        <th>Assuming fields are stable or consistently present</th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e90a741-d994-449a-a0ef-e0b5b7a14286",
   "metadata": {},
   "source": [
    "### Hidden assumptions\n",
    "* Someone chose column names, encodings, delimiters, and header rows\n",
    "* Missing values may be implicit(\"\", NA, -1).\n",
    "* Types are inferred later, not enforced at creation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c2c84-ceff-4192-8772-ff899b8f2c2b",
   "metadata": {},
   "source": [
    "### Microlab: File sanity check\n",
    "\n",
    "Simulate loading messy exports and practice the first questions that should be asked:\n",
    "* What are the columns?\n",
    "* What looks like missing data?\n",
    "* What types are being inferred?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6608396c-9659-4554-8afc-6e2c50f6b713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CSV export (note blanks, NA, weird spacing) ===\n",
      "   user_id   age   income              city\n",
      "0      101  34.0  72000.0            Denver\n",
      "1      102   NaN      NaN           Boulder\n",
      "2      103  29.0  65000.0            Denver\n",
      "3      104  -1.0   5400.0  Colorado Springs\n",
      "\n",
      "Dtypes: {'user_id': dtype('int64'), 'age': dtype('float64'), 'income': dtype('float64'), 'city': dtype('O')}\n",
      "Missing by column: {'user_id': 0, 'age': 1, 'income': 1, 'city': 0}\n",
      "\n",
      "=== JSON export (nested fields) ===\n",
      "   user_id income  profile.age profile.city\n",
      "0      201  80000         31.0       Denver\n",
      "1      202  79000          NaN      Boulder\n",
      "2      203  61000          NaN       Denver\n",
      "\n",
      "Dtypes: {'user_id': dtype('int64'), 'income': dtype('O'), 'profile.age': dtype('float64'), 'profile.city': dtype('O')}\n",
      "\n",
      "Try:\n",
      "- Replace -1 with a real age and re-check missingness\n",
      "- Make income consistently numeric\n",
      "- Rename columns to something consistent (snake_case)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import json\n",
    "\n",
    "print(\"=== CSV export (note blanks, NA, weird spacing) ===\")\n",
    "csv_text = \"\"\"\n",
    "user_id,age,income,city\n",
    "101,34,72000,Denver\n",
    "102,,NA, Boulder\n",
    "103,29,65000,Denver\n",
    "104, -1,5400, \"Colorado Springs\"\n",
    "\"\"\"\n",
    "df_csv = pd.read_csv(StringIO(csv_text),\n",
    "                     skipinitialspace=True)\n",
    "print(df_csv)\n",
    "print(\"\\nDtypes:\", df_csv.dtypes.to_dict())\n",
    "print(\"Missing by column:\", df_csv.isna().sum().to_dict())\n",
    "\n",
    "print(\"\\n=== JSON export (nested fields) ===\")\n",
    "json_text = json.dumps([\n",
    "      {\"user_id\": 201, \"profile\": {\"age\": 31, \"city\": \"Denver\"}, \"income\": 80000},\n",
    "      {\"user_id\": 202, \"profile\": {\"age\": None, \"city\": \"Boulder\"}, \"income\": \"79000\"},\n",
    "      {\"user_id\": 203, \"profile\": {\"city\": \"Denver\"}, \"income\": 61000}\n",
    "])\n",
    "\n",
    "records = json.loads(json_text)\n",
    "df_json = pd.json_normalize(records)\n",
    "print(df_json)\n",
    "print(\"\\nDtypes:\", df_json.dtypes.to_dict())\n",
    "\n",
    "print(\"\\nTry:\")\n",
    "print(\"- Replace -1 with a real age and re-check missingness\")\n",
    "print(\"- Make income consistently numeric\")\n",
    "print(\"- Rename columns to something consistent (snake_case)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abd55c4-9b9d-4eca-ba27-f62302e68d2a",
   "metadata": {},
   "source": [
    "#### Example with cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4be4648a-1491-40eb-9b19-5eebfce68ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CSV export (note blanks, NA, weird spacing) ===\n",
      "   user_id  age  income              city\n",
      "0      101   34   72000            Denver\n",
      "1      102   27   99000           Boulder\n",
      "2      103   29   65000            Denver\n",
      "3      104   44    5400  Colorado Springs\n",
      "\n",
      "Dtypes: {'user_id': dtype('int64'), 'age': dtype('int64'), 'income': dtype('int64'), 'city': dtype('O')}\n",
      "Missing by column: {'user_id': 0, 'age': 0, 'income': 0, 'city': 0}\n",
      "\n",
      "=== JSON export (nested fields) ===\n",
      "   user_id  income  profile.age profile.city\n",
      "0      201   80000           31       Denver\n",
      "1      202   79000           27      Boulder\n",
      "2      203   61000           44       Denver\n",
      "\n",
      "Dtypes: {'user_id': dtype('int64'), 'income': dtype('int64'), 'profile.age': dtype('int64'), 'profile.city': dtype('O')}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import json\n",
    "\n",
    "print(\"=== CSV export (note blanks, NA, weird spacing) ===\")\n",
    "csv_text = \"\"\"\n",
    "user_id,age,income,city\n",
    "101,34,72000,Denver\n",
    "102,27,99000,Boulder\n",
    "103,29,65000,Denver\n",
    "104,44,5400,Colorado Springs\n",
    "\"\"\"\n",
    "df_csv = pd.read_csv(StringIO(csv_text),\n",
    "                     skipinitialspace=True)\n",
    "print(df_csv)\n",
    "print(\"\\nDtypes:\", df_csv.dtypes.to_dict())\n",
    "print(\"Missing by column:\", df_csv.isna().sum().to_dict())\n",
    "\n",
    "print(\"\\n=== JSON export (nested fields) ===\")\n",
    "json_text = json.dumps([\n",
    "      {\"user_id\": 201, \"profile\": {\"age\": 31, \"city\": \"Denver\"}, \"income\": 80000},\n",
    "      {\"user_id\": 202, \"profile\": {\"age\": 27, \"city\": \"Boulder\"}, \"income\": 79000},\n",
    "      {\"user_id\": 203, \"profile\": {\"age\": 44, \"city\": \"Denver\"}, \"income\": 61000}\n",
    "])\n",
    "\n",
    "records = json.loads(json_text)\n",
    "df_json = pd.json_normalize(records)\n",
    "print(df_json)\n",
    "print(\"\\nDtypes:\", df_json.dtypes.to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6046c3c1-abaf-4668-a633-cbe5c7088016",
   "metadata": {},
   "source": [
    "## A.2 SQL databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb2683-69cb-47c6-94a1-741c5411b15a",
   "metadata": {},
   "source": [
    "Databases reflect how applications think about the world.  \n",
    "\n",
    "**Why databases exist**  \n",
    "\n",
    "Databases are optimized for transactions, consistency, and multi-user access, not analysis. Their schemas encode business logic: users, orders, events, states.  \n",
    "\n",
    "<table style=\"text-align:left;\">\n",
    "    <tr>\n",
    "        <th>Type</th>\n",
    "        <th>What a row represents</th>\n",
    "        <th>Typical pitfall</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>Events</th>\n",
    "        <th>Something that happened at a time</th>\n",
    "        <th>Accidentally double counting or missing time windows</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th>State</th>\n",
    "        <th>Current snapshot of something</th>\n",
    "        <th>Assuming it contains historical truth</th>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bed7b1f-9d0a-4325-bfc9-890ce276f3aa",
   "metadata": {},
   "source": [
    "### Microlab: Join logic and granularity traps\n",
    "\n",
    "This microlab creates two tables (users and orders) and shows how a join can silently change your \"row meaning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b6ac734-3d32-4568-b929-d3cede53f537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== users (state table) ===\n",
      "(1, 'free')\n",
      "(2, 'paid')\n",
      "(3, 'paid')\n",
      "\n",
      "=== orders (event table) ====\n",
      "(101, 2, 20.0)\n",
      "(102, 2, 35.0)\n",
      "(103, 3, 15.0)\n",
      "(104, 3, 60.0)\n",
      "\n",
      "=== joined view ===\n",
      "(1, 'free', None, None)\n",
      "(2, 'paid', 101, 20.0)\n",
      "(2, 'paid', 102, 35.0)\n",
      "(3, 'paid', 103, 15.0)\n",
      "(3, 'paid', 104, 60.0)\n",
      "\n",
      "Question: How many paid users are there?\n",
      "Correct (from users table): 2\n",
      "WRONG (after join, counting rows): 4\n",
      "\n",
      "Fix: define unite of analysis explicitly.\n",
      "Paid users (DISTINCT user_id): 2\n",
      "\n",
      "Try:\n",
      "- Insert another order for user 2\n",
      "- Compute total revenue by plan using GROUP BY\n",
      "- Ask: what does ONE ROW represent after each query?\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Create an in-memory SQLite database\n",
    "conn = sqlite3.connect(\":memory:\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Create tables\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE users (\n",
    "    user_id INTEGER PRIMARY KEY,\n",
    "    plan TEXT\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE orders (\n",
    "    order_id INTEGER PRIMARY KEY,\n",
    "    user_id INTEGER,\n",
    "    amount REAL\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "# Insert data\n",
    "cur.executemany(\n",
    "    \"INSERT INTO users (user_id, plan) VALUES (?, ?)\",\n",
    "    [(1, \"free\"), (2, \"paid\"), (3, \"paid\")]\n",
    ")\n",
    "\n",
    "cur.executemany(\n",
    "    \"INSERT INTO orders (order_id, user_id, amount) VALUES (?, ?, ?)\",\n",
    "    [(101, 2, 20.0), (102, 2, 35.0), (103, 3, 15.0), (104, 3, 60.0)]\n",
    ")\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "print(\"=== users (state table) ===\")\n",
    "for row in cur.execute(\"SELECT * FROM users\"):\n",
    "    print(row)\n",
    "\n",
    "print(\"\\n=== orders (event table) ====\")\n",
    "for row in cur.execute(\"SELECT * FROM orders\"):\n",
    "    print(row)\n",
    "\n",
    "print(\"\\n=== joined view ===\")\n",
    "for row in cur.execute(\"\"\"\n",
    "SELECT u.user_id, u.plan, o.order_id, o.amount\n",
    "FROM users u\n",
    "LEFT JOIN orders o\n",
    "ON u.user_id = o.user_id\n",
    "\"\"\"):\n",
    "    print(row)\n",
    "\n",
    "print(\"\\nQuestion: How many paid users are there?\")\n",
    "\n",
    "# Correct answer\n",
    "cur.execute(\"SELECT COUNT(*) FROM users WHERE plan = 'paid'\")\n",
    "print(\"Correct (from users table):\", cur.fetchone()[0])\n",
    "\n",
    "# WRONG answer: counting rows after join\n",
    "cur.execute(\"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM users u\n",
    "LEFT JOIN orders o\n",
    "ON u.user_id = o.user_id\n",
    "WHERE u.plan = 'paid'\n",
    "\"\"\")\n",
    "print(\"WRONG (after join, counting rows):\", cur.fetchone()[0])\n",
    "\n",
    "print(\"\\nFix: define unite of analysis explicitly.\")\n",
    "\n",
    "#Correct fix using DISTINCT\n",
    "cur.execute(\"\"\"\n",
    "SELECT COUNT(DISTINCT u.user_id)\n",
    "FROM users u\n",
    "LEFT JOIN orders o\n",
    "ON u.user_id = o.user_id\n",
    "WHERE u.plan = 'paid'\n",
    "\"\"\")\n",
    "print(\"Paid users (DISTINCT user_id):\", cur.fetchone()[0])\n",
    "\n",
    "print(\"\\nTry:\")\n",
    "print(\"- Insert another order for user 2\")\n",
    "print(\"- Compute total revenue by plan using GROUP BY\")\n",
    "print(\"- Ask: what does ONE ROW represent after each query?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ba7c4f-97c1-4444-97ec-a2bcaf7967ea",
   "metadata": {},
   "source": [
    "## A.3 APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c3c8de-d278-4175-a078-1206fac37b32",
   "metadata": {},
   "source": [
    "APIs give you data through someone else's interface and rules  \n",
    "\n",
    "**What APIs provide**  \n",
    "\n",
    "* Programmatic access to live or regularly updated data.\n",
    "* Structured responses (often JSON).\n",
    "* Authentication, quotas, and versioning\n",
    "\n",
    "**Common constraints**\n",
    "* Rate limits: you cannot pull everything at once\n",
    "* Partial views: pagination, filters, or redacted fields\n",
    "* Instability: fields can change or disappear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cb0da0-39fb-4436-9dd5-0e65873bf876",
   "metadata": {},
   "source": [
    "### Microlab: Pagination + schema drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dfa7669-1f42-47c8-8df1-8eb87279d378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id name score country\n",
      "0   1  Ava  0.91     NaN\n",
      "1   2  Ben  0.74     NaN\n",
      "2   3  Cam  0.88      US\n",
      "3   4  Dee  0.67    None\n",
      "\n",
      "Dtypes: {'id': dtype('int64'), 'name': dtype('O'), 'score': dtype('O'), 'country': dtype('O')}\n",
      "\n",
      "Common API tasks:\n",
      "1) Combine pages (done)\n",
      "2) Normalize fields (types + names)\n",
      "3) Decide how to handle missing optional fields\n",
      "\n",
      "After forcing score numeric:\n",
      "   id name  score country\n",
      "0   1  Ava   0.91     NaN\n",
      "1   2  Ben   0.74     NaN\n",
      "2   3  Cam   0.88      US\n",
      "3   4  Dee   0.67    None\n",
      "\n",
      "Dtypes: {'id': dtype('int64'), 'name': dtype('O'), 'score': dtype('float64'), 'country': dtype('O')}\n",
      "\n",
      "Try:\n",
      "- Add a page3 missing 'name'\n",
      "- Rename 'id' to 'user_id'\n",
      "- Drop rows with missing critical fields vs keep and flag\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Simulated API responses (page 1 vs page 2)\n",
    "page1 = [\n",
    "    {\"id\": 1, \"name\": \"Ava\", \"score\": 0.91},\n",
    "    {\"id\": 2, \"name\": \"Ben\", \"score\": 0.74},\n",
    "]\n",
    "\n",
    "page2 = [\n",
    "    {\"id\": 3, \"name\": \"Cam\", \"score\": \"0.88\", \"country\": \"US\"},\n",
    "    {\"id\": 4, \"name\": \"Dee\", \"score\": 0.67, \"country\": None},\n",
    "]\n",
    "\n",
    "df = pd.json_normalize(page1 + page2)\n",
    "\n",
    "print(df)\n",
    "print(\"\\nDtypes:\", df.dtypes.to_dict())\n",
    "\n",
    "print(\"\\nCommon API tasks:\")\n",
    "print(\"1) Combine pages (done)\")\n",
    "print(\"2) Normalize fields (types + names)\")\n",
    "print(\"3) Decide how to handle missing optional fields\")\n",
    "\n",
    "# Example: force score numeric\n",
    "df[\"score\"] = pd.to_numeric(df[\"score\"], errors=\"coerce\")\n",
    "print(\"\\nAfter forcing score numeric:\")\n",
    "print(df)\n",
    "print(\"\\nDtypes:\", df.dtypes.to_dict())\n",
    "\n",
    "print(\"\\nTry:\")\n",
    "print(\"- Add a page3 missing 'name'\")\n",
    "print(\"- Rename 'id' to 'user_id'\")\n",
    "print(\"- Drop rows with missing critical fields vs keep and flag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6993b141-710c-4e61-8fed-9c6d193465a7",
   "metadata": {},
   "source": [
    "## A.4 Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47289689-47cb-4111-8f15-0333c652963f",
   "metadata": {},
   "source": [
    "Scraping is extracting structure from pages built for humans.  \n",
    "\n",
    "**Why scraping exists**  \n",
    "\n",
    "Sometimes the data is visible but not downloadable. Scraping turns HTML pages into rows and columns.  \n",
    "\n",
    "**Why scraping is fragile**  \n",
    "* HTML structure changes without notice\n",
    "* Content may be dynamically loaded\n",
    "* Legal and ethical constraints apply\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616baae1-8439-47d4-a8ef-ae56dc89b309",
   "metadata": {},
   "source": [
    "### Microlab: parse a tiny HTML snippet into a table\n",
    "\n",
    "This is a minimal example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ff32694-ad0c-429c-8a23-1f9520506aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       name price\n",
      "0  Widget A   $10\n",
      "1  Widget B   $12\n",
      "\n",
      "Try:\n",
      "- Change <td>$10</td> to <td>10 usd</td> and clean price\n",
      "- Add a new column in the HTML and update your parser\n",
      "- Remove the header row and see how the assumptions break\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = \"\"\"\n",
    "<table>\n",
    "  <tr><th>Name</th><th>Price</th></tr>\n",
    "  <tr><td>Widget A</td><td>$10</td></tr>\n",
    "  <tr><td>Widget B</td><td>$12</td></tr>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "rows = []\n",
    "for tr in soup.find_all(\"tr\")[1:]:\n",
    "    tds = tr.find_all(\"td\")\n",
    "    rows.append({\n",
    "        \"name\": tds[0].get_text(strip=True),\n",
    "        \"price\": tds[1].get_text(strip=True),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df)\n",
    "\n",
    "print(\"\\nTry:\")\n",
    "print(\"- Change <td>$10</td> to <td>10 usd</td> and clean price\")\n",
    "print(\"- Add a new column in the HTML and update your parser\")\n",
    "print(\"- Remove the header row and see how the assumptions break\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0bd2c1-dfa3-47df-88a1-f5ac59734af1",
   "metadata": {},
   "source": [
    "## A.5 Practice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e412e436-1d44-4c16-9520-e4f7cccd4962",
   "metadata": {},
   "source": [
    "**Goals**\n",
    "* **Files:** clean a messy CSV, normalize a nested JSON, handle Excel-style human edits\n",
    "* **SQL:** use SQLite to see how joins change row meaning and how to aggregate safely\n",
    "* **APIs:** combine paginated responses and handle schema drift (simulated)\n",
    "* **Scraping:** parse a tiny HTML table and clean extracted fields.\n",
    "* **MiniProject:** merge sources into one analysis-ready table + write a data quality report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e996c7-c46c-4264-ac5d-81b3f5e552fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
