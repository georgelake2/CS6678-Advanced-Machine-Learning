{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76ffd72a-6ea0-48d3-b25b-b56146bbcaca",
   "metadata": {},
   "source": [
    "# Module 2.A - Where Data Comes From (Real-World Pipeline Starter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f781be-2019-4f56-9cdc-d0eba52a15bb",
   "metadata": {},
   "source": [
    "### Core dataset for the whole module \n",
    "\n",
    "**NYC 311 Service Requests (2020 - present)** (NYC Open Data/Socrata)  \n",
    "Why this dataset works for learning:\n",
    "* **Real mess:** missing values, inconsistent strings, free-text fields, and \"weird\" categories.\n",
    "* **Real scale:** the full dataset is huge, so must learn how to pull a *slice*\n",
    "* **Multiple access modes:** the same data is available as **CSV, API (JSON), SQL**\n",
    "* **Real change over time:** fields and value distributions can shift (schema drift)\n",
    "\n",
    "Will also create two supporting assets that will be reused later:\n",
    "* **Data dictionary Excel file:** (`.xlsx`) from the publisher (documentation)\n",
    "* **Borough reference table:** either scraped from the web or created as a seed file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ceafff-0797-4d5c-9798-ce449f63132a",
   "metadata": {},
   "source": [
    "### What will be built in 2.A  \n",
    "\n",
    "Will produce a local, module-scoped workspace. Organized by module and stored as described:  \n",
    "```bash\n",
    "~/work/m2/data/\n",
    "    raw/          # downloaded files, API responses\n",
    "    reference/    # lookup tables, dictionaries\n",
    "    warehouse/    # SQLite databases\n",
    "```\n",
    "\n",
    "Later notebooks will assume these exist:\n",
    "* **2.B** Data quality: missingness, duplicates, inconsistent categories, schema drift\n",
    "* **2.C** Wrangling: groupby, joins, string cleaning, feature construction\n",
    "* **2.D** Scaling: incremental refresh, \"raw &rarr; staged &rarr; curated\" thinking\n",
    "* **2.E** Outliers/validation: response times, anomaly checks, \"is this plausible?\" rules\n",
    "\n",
    "The goal in 2.A is not perfect cleaning. It is learning how to acquire data reliably and keep the process reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a43184-3f38-4d12-b376-6bed75c45565",
   "metadata": {},
   "source": [
    "## Setup (requests, BeautifulSoup, and a writable workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810bac2c-e64d-42ea-ba60-6752e1d214b9",
   "metadata": {},
   "source": [
    "Common libraries:\n",
    "* **requests:** a simple way to make HTTP requests\n",
    "* **BeautifulSoup:** parses HTML to extract pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460c6389-197e-4e02-8d38-00bb053b413b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writable Module 2 data workspace ready:\n",
      "  /home/glake/Nextcloud/Classwork/CS6678 - Advanced Machine Learning/Jupyter Notebooks/work/m2/data\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 60)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "# Writable workspace (module-scoped)\n",
    "WORK_DIR   = Path(\"work\")\n",
    "MODULE_DIR = WORK_DIR / \"m2\"\n",
    "DATA_DIR   = MODULE_DIR / \"data\"\n",
    "RAW_DIR    = DATA_DIR / \"raw\"\n",
    "REF_DIR    = DATA_DIR / \"reference\"\n",
    "WH_DIR     = DATA_DIR / \"warehouse\"\n",
    "\n",
    "for d in [RAW_DIR, REF_DIR, WH_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Writable Module 2 data workspace ready:\")\n",
    "print(\" \", DATA_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc54439-d0b3-4c49-aa60-bcc77c157d0d",
   "metadata": {},
   "source": [
    "## A.0 - Source Audit Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de33a29-bda7-45bc-8955-0015fdcc8a8f",
   "metadata": {},
   "source": [
    "Before cleaning, provide answers to:  \n",
    "* What does one row represent\n",
    "* What system produced it?\n",
    "* What time range does it cover?\n",
    "* What are known limitations?\n",
    "* Which fields look risky (missing, free-text, inconsistent categories)?\n",
    "\n",
    "We will keep a small structured dictionary of notes that can be reused later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a50976b2-57ee-4cc3-a219-1f9958393009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'NYC 311 Service Requests (2020-present)',\n",
       " 'publisher': 'NYC Open Data / 311',\n",
       " 'where_it_comes_from': 'City 311 request intake system (customer service requests routed to agencies).',\n",
       " 'unit_of_analysis': 'Each row represents one 311 service request.',\n",
       " 'time_grain': 'Requests are created continuously; rows include timestamps for created/closed when available.',\n",
       " 'known_limitations': ['Many fields are optional depending on request type (expect missingness).',\n",
       "  'Free-text fields (descriptor/address) can be inconsistent and messy.',\n",
       "  'The dataset is continuously updated; results can change between runs.'],\n",
       " 'Notes 1/30/26': []}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_audit = {\n",
    "    \"dataset_name\": \"NYC 311 Service Requests (2020-present)\",\n",
    "    \"publisher\": \"NYC Open Data / 311\",\n",
    "    \"where_it_comes_from\": \"City 311 request intake system (customer service requests routed to agencies).\",\n",
    "    \"unit_of_analysis\": \"Each row represents one 311 service request.\", \n",
    "    \"time_grain\": \"Requests are created continuously; rows include timestamps for created/closed when available.\",\n",
    "    \"known_limitations\": [\n",
    "        \"Many fields are optional depending on request type (expect missingness).\",\n",
    "        \"Free-text fields (descriptor/address) can be inconsistent and messy.\",\n",
    "        \"The dataset is continuously updated; results can change between runs.\",\n",
    "    ],\n",
    "    \"Notes 1/30/26\": []\n",
    "}\n",
    "\n",
    "source_audit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d007fc-6579-400b-9e30-56fb78247772",
   "metadata": {},
   "source": [
    "## A.1 Files (CSV): Download a Reproducible Slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3497e542-745e-4b3b-8108-3c315aae2f0b",
   "metadata": {},
   "source": [
    "Large public datasets are often too big to download in full for learning. A useful technique is to define a slice that is:  \n",
    "* small enough to iterate quickly (seconds, not minutes)\n",
    "* recent enough to include real mess\n",
    "* refreshable\n",
    "\n",
    "We will pull the **last 14 days** of NYC 311 requests as a CSV  \n",
    "\n",
    "**Note on Socrata Timestamps**  \n",
    "\n",
    "NYC Open Data uses Socrata. Many timestamp fields are \"floating timestamps\" and expect ISO8601 without timezone suffixes (No Z, No +00:00) in the query string. So we format timestamps like: `2026-01-04T04:03:21`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d46976b-2d28-4958-811e-4c97cbeecbce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where clause: created_date >= '2026-01-17T14:18:35'AND created_date < '2026-01-31T14:18:35'\n",
      "Used cached: work/m2/data/raw/nyc311_last14d.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('work/m2/data/raw/nyc311_last14d.csv')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYC311_BASE = \"https://data.cityofnewyork.us/resource/erm2-nwe9\"\n",
    "\n",
    "# Stable subset of columns that will be reused across Module 2.\n",
    "NYC311_COLUMNS = [\n",
    "    \"unique_key\",\n",
    "    \"created_date\",\n",
    "    \"closed_date\",\n",
    "    \"agency\",\n",
    "    \"agency_name\",\n",
    "    \"complaint_type\",\n",
    "    \"descriptor\",\n",
    "    \"status\",\n",
    "    \"borough\",\n",
    "    \"incident_zip\",\n",
    "    \"incident_address\",\n",
    "    \"street_name\",\n",
    "    \"city\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "]\n",
    "\n",
    "def iso_floating(dt: datetime) -> str:\n",
    "    \"\"\"\n",
    "    Socrata floating timestamps expect ISO8601 without timezone suffix.\n",
    "    We will drop tzinfo and milliseconds to be conservative\n",
    "    \"\"\"\n",
    "    dt = dt.astimezone(timezone.utc).replace(tzinfo=None)\n",
    "    return dt.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "def download_if_missing(url: str, path: Path, params: dict | None = None, timeout: int = 30) -> Path:\n",
    "    \"\"\"\n",
    "    Download a URL to disk only if the file is not already cached.\n",
    "    We chace downloads so later notebooks (2.B - 2.E) can reuse the same files\n",
    "    without hammering the public API repeatedly.\n",
    "    \"\"\"\n",
    "    if path.exists() and path.stat().st_size > 0:\n",
    "        print(\"Used cached:\", path)\n",
    "        return path\n",
    "\n",
    "    print(\"Downloading:\", url)\n",
    "    r = requests.get(url, params=params, timeout=timeout)\n",
    "\n",
    "    if r.status_code >= 400:\n",
    "        print(\"Status:\", r.status_code)\n",
    "        print(\"Body (first 300 chars):\", r.text[:300])\n",
    "\n",
    "    r.raise_for_status()\n",
    "    path.write_bytes(r.content)\n",
    "    print(\"Saved:\", path, f\"({path.stat().st_size/1e6:.2f} MB)\")\n",
    "    return path\n",
    "\n",
    "def socrata_csv_params(days: int=14, limit: int=5000) -> dict:\n",
    "    end = datetime.now(timezone.utc)\n",
    "    start = end - timedelta(days=days)\n",
    "\n",
    "    select = \",\".join(NYC311_COLUMNS)\n",
    "    where = (\n",
    "        f\"created_date >= '{iso_floating(start)}'\"\n",
    "        f\"AND created_date < '{iso_floating(end)}'\"\n",
    "    )\n",
    "    return {\"$select\": select, \"$where\": where, \"$order\": \"created_date DESC\", \"$limit\": limit}\n",
    "\n",
    "CSV_PATH = RAW_DIR / \"nyc311_last14d.csv\"\n",
    "params = socrata_csv_params(days=14, limit=50000)\n",
    "\n",
    "print(\"Where clause:\", params[\"$where\"])\n",
    "download_if_missing(f\"{NYC311_BASE}.csv\", CSV_PATH, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0752da8f-8e7d-4a99-b900-4b9a0ba78a76",
   "metadata": {},
   "source": [
    "### Load the CSV and do a quick source audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ad1efa-5939-48e4-a37f-4dd131817495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>status</th>\n",
       "      <th>borough</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30T01:51:21.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30T01:51:04.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOE</td>\n",
       "      <td>Department of Education</td>\n",
       "      <td>School Maintenance</td>\n",
       "      <td>Heating Problem</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11226.0</td>\n",
       "      <td>911 FLATBUSH AVENUE</td>\n",
       "      <td>FLATBUSH AVENUE</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40.649787</td>\n",
       "      <td>-73.958550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30T01:50:53.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10025.0</td>\n",
       "      <td>936 AMSTERDAM AVENUE</td>\n",
       "      <td>AMSTERDAM AVENUE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>40.800498</td>\n",
       "      <td>-73.965680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67707975</td>\n",
       "      <td>2026-01-30T01:50:52.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>10302.0</td>\n",
       "      <td>190 TRANTOR PLACE</td>\n",
       "      <td>TRANTOR PLACE</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>40.629156</td>\n",
       "      <td>-74.144411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67771794</td>\n",
       "      <td>2026-01-30T01:50:32.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Taxi and Limousine Commission</td>\n",
       "      <td>Taxi Complaint</td>\n",
       "      <td>Driver Complaint - Non Passenger</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11430.0</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JAMAICA</td>\n",
       "      <td>40.648320</td>\n",
       "      <td>-73.788281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key             created_date closed_date agency                      agency_name       complaint_type  \\\n",
       "0    67720523  2026-01-30T01:51:21.000         NaN   NYPD  New York City Police Department   Noise - Commercial   \n",
       "1    67746090  2026-01-30T01:51:04.000         NaN    DOE          Department of Education   School Maintenance   \n",
       "2    67758820  2026-01-30T01:50:53.000         NaN   NYPD  New York City Police Department  Noise - Residential   \n",
       "3    67707975  2026-01-30T01:50:52.000         NaN   NYPD  New York City Police Department  Noise - Residential   \n",
       "4    67771794  2026-01-30T01:50:32.000         NaN    TLC    Taxi and Limousine Commission       Taxi Complaint   \n",
       "\n",
       "                         descriptor       status        borough  incident_zip        incident_address             street_name  \\\n",
       "0                  Loud Music/Party  Unspecified    Unspecified           NaN                     NaN                     NaN   \n",
       "1                   Heating Problem  In Progress       BROOKLYN       11226.0     911 FLATBUSH AVENUE         FLATBUSH AVENUE   \n",
       "2                  Loud Music/Party  In Progress      MANHATTAN       10025.0    936 AMSTERDAM AVENUE        AMSTERDAM AVENUE   \n",
       "3                  Loud Music/Party  In Progress  STATEN ISLAND       10302.0       190 TRANTOR PLACE           TRANTOR PLACE   \n",
       "4  Driver Complaint - Non Passenger  In Progress         QUEENS       11430.0  JOHN F KENNEDY AIRPORT  JOHN F KENNEDY AIRPORT   \n",
       "\n",
       "            city   latitude  longitude  \n",
       "0            NaN        NaN        NaN  \n",
       "1       BROOKLYN  40.649787 -73.958550  \n",
       "2       NEW YORK  40.800498 -73.965680  \n",
       "3  STATEN ISLAND  40.629156 -74.144411  \n",
       "4        JAMAICA  40.648320 -73.788281  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv = pd.read_csv(CSV_PATH)\n",
    "df_csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68d17ed2-1361-4f29-bca2-02aaad41a2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_key            int64\n",
       "created_date         object\n",
       "closed_date          object\n",
       "agency               object\n",
       "agency_name          object\n",
       "complaint_type       object\n",
       "descriptor           object\n",
       "status               object\n",
       "borough              object\n",
       "incident_zip        float64\n",
       "incident_address     object\n",
       "street_name          object\n",
       "city                 object\n",
       "latitude            float64\n",
       "longitude           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4a7a92-f774-4b08-ac6b-69ccf4556502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "closed_date         0.60766\n",
       "city                0.07640\n",
       "street_name         0.02592\n",
       "incident_address    0.02588\n",
       "latitude            0.01222\n",
       "longitude           0.01222\n",
       "incident_zip        0.00732\n",
       "descriptor          0.00680\n",
       "complaint_type      0.00000\n",
       "agency              0.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.isna().mean().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59cb715-e1f4-48d5-84a7-8fe1dcdb4557",
   "metadata": {},
   "source": [
    "**Update Source Audit**  \n",
    "\n",
    "Add 3 observations to `source_audit[\"today_notes\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47c8d1d5-a987-4896-84a6-115d242e4502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'NYC 311 Service Requests (2020-present)',\n",
       " 'publisher': 'NYC Open Data / 311',\n",
       " 'where_it_comes_from': 'City 311 request intake system (customer service requests routed to agencies).',\n",
       " 'unit_of_analysis': 'Each row represents one 311 service request.',\n",
       " 'time_grain': 'Requests are created continuously; rows include timestamps for created/closed when available.',\n",
       " 'known_limitations': ['Many fields are optional depending on request type (expect missingness).',\n",
       "  'Free-text fields (descriptor/address) can be inconsistent and messy.',\n",
       "  'The dataset is continuously updated; results can change between runs.'],\n",
       " 'Notes 1/30/26': ['incident_zip does not need to be a float64',\n",
       "  'There is at least one entry that is incomplete',\n",
       "  'closed_date is often missing']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clear current notes so that the cell does not create duplicate entries\n",
    "source_audit[\"Notes 1/30/26\"] = []\n",
    "source_audit[\"Notes 1/30/26\"].append(\"incident_zip does not need to be a float64\")\n",
    "source_audit[\"Notes 1/30/26\"].append(\"There is at least one entry that is incomplete\")\n",
    "source_audit[\"Notes 1/30/26\"].append(\"closed_date is often missing\")\n",
    "\n",
    "source_audit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedab84d-83d9-4481-ab57-f00a74462a85",
   "metadata": {},
   "source": [
    "## A.2 SQL databases (SQLite): Land Raw Data Into a Local Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9f288a2-ac12-48cf-9fad-d00fbae2ad3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB: /home/glake/Nextcloud/Classwork/CS6678 - Advanced Machine Learning/Jupyter Notebooks/work/m2/data/warehouse/module2.db\n"
     ]
    }
   ],
   "source": [
    "DB_PATH = WH_DIR / \"module2.db\"\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "print(\"DB:\", DB_PATH.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97839e0-0e6b-4e8a-be56-4c84dac86155",
   "metadata": {},
   "source": [
    "### Write the raw CSV into a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44b8b112-3750-41d8-ba33-5402b02d332a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in nyc311_raw: 50000\n"
     ]
    }
   ],
   "source": [
    "df_csv.to_sql(\"nyc311_raw\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE INDEX IF NOT EXISTS idx_nyc311_created_date ON nyc311_raw(created_date)\")\n",
    "cur.execute(\"CREATE INDEX IF NOT EXISTS idx_nyc311_borough ON nyc311_raw(borough)\")\n",
    "cur.execute(\"CREATE INDEX IF NOT EXISTS idx_nyc311_complaint_type ON nyc311_raw(complaint_type)\")\n",
    "conn.commit()\n",
    "\n",
    "print(\"Rows in nyc311_raw:\", cur.execute(\"SELECT COUNT(*) FROM nyc311_raw\").fetchone()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eedb0d-99e1-4150-bba7-d05243b033be",
   "metadata": {},
   "source": [
    "### SQL sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04c041d7-865c-4355-8f7d-5f056f0afa95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borough</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>15654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRONX</td>\n",
       "      <td>10806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>8876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unspecified</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         borough      n\n",
       "0       BROOKLYN  15654\n",
       "1         QUEENS  11831\n",
       "2          BRONX  10806\n",
       "3      MANHATTAN   8876\n",
       "4  STATEN ISLAND   2798\n",
       "5    Unspecified     35"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT borough, COUNT(*) AS n\n",
    "FROM nyc311_raw\n",
    "GROUP BY borough\n",
    "ORDER BY n DESC\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(q, conn).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05519193-992d-4507-95a8-35f03d4a9c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snow or Ice</td>\n",
       "      <td>12376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEAT/HOT WATER</td>\n",
       "      <td>11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Illegal Parking</td>\n",
       "      <td>4922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blocked Driveway</td>\n",
       "      <td>2790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UNSANITARY CONDITION</td>\n",
       "      <td>1288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PLUMBING</td>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PAINT/PLASTER</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DOOR/WINDOW</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WATER LEAK</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Traffic Signal Condition</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Water System</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Homeless Person Assistance</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GENERAL</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ELECTRIC</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                complaint_type      n\n",
       "0                  Snow or Ice  12376\n",
       "1               HEAT/HOT WATER  11890\n",
       "2              Illegal Parking   4922\n",
       "3             Blocked Driveway   2790\n",
       "4          Noise - Residential   2492\n",
       "5         UNSANITARY CONDITION   1288\n",
       "6                     PLUMBING   1212\n",
       "7                PAINT/PLASTER    819\n",
       "8                  DOOR/WINDOW    773\n",
       "9                   WATER LEAK    750\n",
       "10    Traffic Signal Condition    722\n",
       "11                Water System    549\n",
       "12  Homeless Person Assistance    530\n",
       "13                     GENERAL    474\n",
       "14                    ELECTRIC    465"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT complaint_type, COUNT(*) AS n\n",
    "FROM nyc311_raw\n",
    "GROUP BY complaint_type\n",
    "ORDER BY n DESC\n",
    "LIMIT 15\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(q, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fac982-8c72-4208-ab09-f2bf143b59f7",
   "metadata": {},
   "source": [
    "## A.3 APIs: query the same dataset via Socrata (JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffc4f89d-78dc-4eed-b967-f43b6d1cf7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records fetched (JSON): 2000\n",
      "Example record keys: ['unique_key', 'created_date', 'agency', 'agency_name', 'complaint_type', 'descriptor', 'status', 'borough']\n"
     ]
    }
   ],
   "source": [
    "def socrata_json(days: int=14, limit: int=1000, offset: int=0) -> List[Dict[str, Any]]:\n",
    "    end = datetime.now(timezone.utc)\n",
    "    start = end - timedelta(days=days)\n",
    "\n",
    "    select = \",\".join(NYC311_COLUMNS)\n",
    "    where = (\n",
    "        f\"created_date >= '{iso_floating(start)}'\"\n",
    "        f\"AND created_date < '{iso_floating(end)}'\"\n",
    "    )\n",
    "\n",
    "    params = {\"$select\": select, \"$where\": where, \"$order\": \"created_date DESC\", \"$limit\": limit, \"$offset\": offset}\n",
    "    r = requests.get(f\"{NYC311_BASE}.json\", params=params, timeout=30)\n",
    "\n",
    "    if r.status_code >= 400:\n",
    "        print(\"Status:\", r.status_code)\n",
    "        print(\"Where:\", where)\n",
    "        print(\"Body (first 300 chars):\", r.text[300])\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "page1 = socrata_json(days=14, limit=1000, offset=0)\n",
    "page2 = socrata_json(days=14, limit=1000, offset=1000)\n",
    "records = page1 + page2\n",
    "\n",
    "print(\"Records fetched (JSON):\", len(records))\n",
    "print(\"Example record keys:\", list(records[0].keys())[:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fa26e7-761f-48e0-a7ae-3d6d3dd1fee9",
   "metadata": {},
   "source": [
    "### Save raw JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f8f129a-f8f2-4c38-be3e-f2a893293109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: work/m2/data/raw/nyc311_last14d.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>status</th>\n",
       "      <th>borough</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>closed_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30T01:51:21.000</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30T01:51:04.000</td>\n",
       "      <td>DOE</td>\n",
       "      <td>Department of Education</td>\n",
       "      <td>School Maintenance</td>\n",
       "      <td>Heating Problem</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11226</td>\n",
       "      <td>911 FLATBUSH AVENUE</td>\n",
       "      <td>FLATBUSH AVENUE</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40.64978696357874</td>\n",
       "      <td>-73.95854980692795</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30T01:50:53.000</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10025</td>\n",
       "      <td>936 AMSTERDAM AVENUE</td>\n",
       "      <td>AMSTERDAM AVENUE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>40.80049840941944</td>\n",
       "      <td>-73.96567975561733</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_key             created_date agency                      agency_name       complaint_type        descriptor       status  \\\n",
       "0   67720523  2026-01-30T01:51:21.000   NYPD  New York City Police Department   Noise - Commercial  Loud Music/Party  Unspecified   \n",
       "1   67746090  2026-01-30T01:51:04.000    DOE          Department of Education   School Maintenance   Heating Problem  In Progress   \n",
       "2   67758820  2026-01-30T01:50:53.000   NYPD  New York City Police Department  Noise - Residential  Loud Music/Party  In Progress   \n",
       "\n",
       "       borough incident_zip      incident_address       street_name      city           latitude           longitude closed_date  \n",
       "0  Unspecified          NaN                   NaN               NaN       NaN                NaN                 NaN         NaN  \n",
       "1     BROOKLYN        11226   911 FLATBUSH AVENUE   FLATBUSH AVENUE  BROOKLYN  40.64978696357874  -73.95854980692795         NaN  \n",
       "2    MANHATTAN        10025  936 AMSTERDAM AVENUE  AMSTERDAM AVENUE  NEW YORK  40.80049840941944  -73.96567975561733         NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON_PATH = RAW_DIR / \"nyc311_last14d.json\"\n",
    "if not JSON_PATH.exists():\n",
    "    JSON_PATH.write_text(json.dumps(records, indent=2))\n",
    "    print(\"Saved:\", JSON_PATH)\n",
    "else:\n",
    "    print(\"Using cached:\", JSON_PATH)\n",
    "\n",
    "df_api = pd.json_normalize(records)\n",
    "df_api.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282635ee-3b3e-4226-bf76-b3f70070888f",
   "metadata": {},
   "source": [
    "### Compare CSV vs API quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bb77300-e8ef-4d6c-b179-97dd3483ff01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'csv_columns': 15,\n",
       " 'api_columns': 15,\n",
       " 'columns_only_in_csv': [],\n",
       " 'columns_only_in_api': [],\n",
       " 'csv_missing_rate_top10': {'closed_date': 0.60766,\n",
       "  'city': 0.0764,\n",
       "  'street_name': 0.02592,\n",
       "  'incident_address': 0.02588,\n",
       "  'latitude': 0.01222,\n",
       "  'longitude': 0.01222,\n",
       "  'incident_zip': 0.00732,\n",
       "  'descriptor': 0.0068,\n",
       "  'complaint_type': 0.0,\n",
       "  'agency': 0.0},\n",
       " 'api_missing_rate_top10': {'closed_date': 0.649,\n",
       "  'city': 0.046,\n",
       "  'street_name': 0.024,\n",
       "  'incident_address': 0.024,\n",
       "  'latitude': 0.019,\n",
       "  'longitude': 0.019,\n",
       "  'incident_zip': 0.0075,\n",
       "  'status': 0.0,\n",
       "  'descriptor': 0.0,\n",
       "  'complaint_type': 0.0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_notes = {\n",
    "    \"csv_columns\": len(df_csv.columns),\n",
    "    \"api_columns\": len(df_api.columns),\n",
    "    \"columns_only_in_csv\": sorted(set(df_csv.columns) - set(df_api.columns))[:20],\n",
    "    \"columns_only_in_api\": sorted(set(df_api.columns) - set(df_csv.columns))[:20],\n",
    "    \"csv_missing_rate_top10\": df_csv.isna().mean().sort_values(ascending=False).head(10).to_dict(),\n",
    "    \"api_missing_rate_top10\": df_api.isna().mean().sort_values(ascending=False).head(10).to_dict(),\n",
    "}\n",
    "\n",
    "comparison_notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa7961-95c7-425b-bbff-47ac51ff3d9c",
   "metadata": {},
   "source": [
    "## A.4 Reference Data: Borough Lookup (Scrape OR Seed File)\n",
    "\n",
    "Try **Scrape** first, if it fails (403), fall back to **Seed File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c153ef5-ec35-4239-a3b5-7c8afde1d60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option A success: scraped boroughs and saved: work/m2/data/reference/nyc_boroughs.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jurisdiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Bronx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brooklyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Queens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Staten Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>City of New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>State of New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sources : [ 3 ] [ 4 ] [ 5 ] [ 6 ] and see indi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             borough\n",
       "0                                       Jurisdiction\n",
       "1                                          The Bronx\n",
       "2                                           Brooklyn\n",
       "3                                          Manhattan\n",
       "4                                             Queens\n",
       "5                                      Staten Island\n",
       "6                                   City of New York\n",
       "7                                  State of New York\n",
       "8  Sources : [ 3 ] [ 4 ] [ 5 ] [ 6 ] and see indi..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BORO_PATH = REF_DIR / \"nyc_boroughs.csv\"\n",
    "\n",
    "if BORO_PATH.exists():\n",
    "    print(\"Using cached:\", BORO_PATH)\n",
    "    df_boro = pd.read_csv(BORO_PATH)\n",
    "    display(df_boro)\n",
    "else:\n",
    "    WIKI_URL = \"https://en.wikipedia.org/wiki/Boroughs_of_New_York_City\"\n",
    "    HEADERS = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (educational; JupyterLab) requests\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        r = requests.get(WIKI_URL, headers=HEADERS, timeout=30)\n",
    "        if r.status_code >= 400:\n",
    "            raise RuntimeError(f\"HTTP {r.status_code} from Wikipedia\")\n",
    "\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "        tables = soup.find_all(\"table\", class_=\"wikitable\")\n",
    "        target = None\n",
    "        for t in tables:\n",
    "            header_text = t.get_text(\" \", strip=True).lower()\n",
    "            if \"borough\" in header_text and \"population\" in header_text:\n",
    "                target = t\n",
    "                break\n",
    "\n",
    "        if target is None:\n",
    "            raise RuntimeError(\"Could not find expected borough table (page structure may have changed).\")\n",
    "\n",
    "        rows = []\n",
    "        for tr in target.find_all(\"tr\")[1:]:\n",
    "            tds = tr.find_all([\"th\", \"td\"])\n",
    "            if not tds:\n",
    "                continue\n",
    "            borough = tds[0].get_text(\" \", strip=True).strip()\n",
    "            if borough and borough.lower() != \"borough\":\n",
    "                rows.append({\"borough\": borough})\n",
    "\n",
    "        df_boro = pd.DataFrame(rows).drop_duplicates().reset_index(drop=True)\n",
    "        df_boro.to_csv(BORO_PATH, index=False)\n",
    "        print(\"Option A success: scraped boroughs and saved:\", BORO_PATH)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Option A failed (scraping). Reason:\", e)\n",
    "        print(\"Falling back to Option B (seed file).\")\n",
    "    \n",
    "        df_boro = pd.DataFrame([\n",
    "            {\"borough\": \"BRONX\"},\n",
    "            {\"borough\": \"BROOKLYN\"},\n",
    "            {\"borough\": \"MANHATTAN\"},\n",
    "            {\"borough\": \"QUEENS\"},\n",
    "            {\"borough\": \"STATEN ISLAND\"},\n",
    "        ])\n",
    "        df_boro.to_csv(BORO_PATH, index=False)\n",
    "        print(\"Option B success: saved seed borough table:\", BORO_PATH)\n",
    "    \n",
    "    display(df_boro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656e59d-ac6f-4c8f-b565-8c648cd346ff",
   "metadata": {},
   "source": [
    "**Notes:**  \n",
    "* Scraping can break even if the code is correct (403, HTML changes)\n",
    "* In many teams, seed files are the standard approach for small reference tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a2c59d-41cf-4119-a9b7-3583446b21ad",
   "metadata": {},
   "source": [
    "## A.5 Excel: Download the 311 data dictionary (XLSX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb6c3f24-fa5d-4626-9efa-ab0a76cccf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://nycopendata.socrata.com/api/views/erm2-nwe9/files/b372b884-f86a-453b-ba16-1fe06ce9d212?download=true&filename=311_ServiceRequest_2010-Present_DataDictionary_Updated_2023.xlsx\n",
      "Saved: work/m2/data/reference/nyc311_data_dictionary.xlsx (0.50 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('work/m2/data/reference/nyc311_data_dictionary.xlsx')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DICTIONARY_URL = (\n",
    "    \"https://nycopendata.socrata.com/api/views/erm2-nwe9/files/\"\n",
    "    \"b372b884-f86a-453b-ba16-1fe06ce9d212?download=true&filename=311_ServiceRequest_2010-Present_DataDictionary_Updated_2023.xlsx\"\n",
    ")\n",
    "\n",
    "XLSX_PATH = REF_DIR / \"nyc311_data_dictionary.xlsx\"\n",
    "download_if_missing(DATA_DICTIONARY_URL, XLSX_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "434ab8a0-0d39-48d3-bf6d-3133300958f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dataset Information',\n",
       " 'Column Information',\n",
       " 'All Agencies Complaint<>Details',\n",
       " 'HPD Complaint<>Details',\n",
       " 'Dataset Revision History',\n",
       " 'Primer Page & InternaI Informat',\n",
       " 'Hidden_Frequencies',\n",
       " 'Hidden_Agencies',\n",
       " 'Hidden_DataTypes']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openpyxl\n",
    "wb = openpyxl.load_workbook(XLSX_PATH, read_only=True)\n",
    "wb.sheetnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4d61c9a-86f2-4f43-a255-ad8fd7ac73c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/glake/miniconda3/envs/ml/lib/python3.12/site-packages/openpyxl/worksheet/_read_only.py:85: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Dictionary - Dataset Information</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dataset Name</td>\n",
       "      <td>311 Service Requests from 2010 to Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dataset URL</td>\n",
       "      <td>https://data.cityofnewyork.us/Social-Services/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Provided by\\nThe name of the NYC agency p...</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Each row is a... \\nThe unit of analysis/level ...</td>\n",
       "      <td>311 Service Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Publishing Frequency\\nHow often changed data i...</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Change Frequency\\nHow often the data unde...</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Frequency Details\\nAdditional details about th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dataset Description\\nOverview of the informati...</td>\n",
       "      <td>NYC311 responds to thousands of inquiries, com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Why is this data collected?\\nPurpose behind th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How is this data collected?\\nThe methods used ...</td>\n",
       "      <td>This dataset describes site-specific non-emerg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How can this data be used?\\nExamples of and/or...</td>\n",
       "      <td>Some questions that you can explore with this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What are the unique characteristics or limitat...</td>\n",
       "      <td>This dataset does not include inquiries, some ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Additional geospatial information\\nFor any dat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Unnamed: 0                                         Unnamed: 1\n",
       "0                                                 NaN                                                NaN\n",
       "1                                                 NaN                                                NaN\n",
       "2                                                 NaN                                                NaN\n",
       "3                                                 NaN                                                NaN\n",
       "4                                                 NaN                                                NaN\n",
       "5                                                 NaN                                                NaN\n",
       "6               Data Dictionary - Dataset Information                                                NaN\n",
       "7                                        Dataset Name          311 Service Requests from 2010 to Present\n",
       "8                                         Dataset URL  https://data.cityofnewyork.us/Social-Services/...\n",
       "9   Data Provided by\\nThe name of the NYC agency p...                                                311\n",
       "10  Each row is a... \\nThe unit of analysis/level ...                                311 Service Request\n",
       "11  Publishing Frequency\\nHow often changed data i...                                              Daily\n",
       "12  Data Change Frequency\\nHow often the data unde...                                              Daily\n",
       "13  Frequency Details\\nAdditional details about th...                                                NaN\n",
       "14  Dataset Description\\nOverview of the informati...  NYC311 responds to thousands of inquiries, com...\n",
       "15  Why is this data collected?\\nPurpose behind th...                                                NaN\n",
       "16  How is this data collected?\\nThe methods used ...  This dataset describes site-specific non-emerg...\n",
       "17  How can this data be used?\\nExamples of and/or...  Some questions that you can explore with this ...\n",
       "18  What are the unique characteristics or limitat...  This dataset does not include inquiries, some ...\n",
       "19  Additional geospatial information\\nFor any dat...                                                NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet = wb.sheetnames[0]\n",
    "df_dict_preview = pd.read_excel(XLSX_PATH, sheet_name=sheet)\n",
    "df_dict_preview.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77984639-93eb-40fa-adac-49229dbb76a3",
   "metadata": {},
   "source": [
    "Many data dictionaries are human-formatted spreadsheets with title blocks and notes. The first read may look messy (Unnamed columns, NaNs). That is normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c4acb1-7360-4098-bfec-62319bba3718",
   "metadata": {},
   "source": [
    "## A.6 Wrap-up: Verify Reusable Artifacts Exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27716ded-1e6d-42c0-ab68-2edbcde7c67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('work/m2/data/raw/nyc311_last14d.csv', True, 12.143),\n",
       " ('work/m2/data/raw/nyc311_last14d.json', True, 1.036),\n",
       " ('work/m2/data/reference/nyc_boroughs.csv', True, 0.0),\n",
       " ('work/m2/data/reference/nyc311_data_dictionary.xlsx', True, 0.497),\n",
       " ('work/m2/data/warehouse/module2.db', True, 13.627)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = [CSV_PATH, JSON_PATH, BORO_PATH, XLSX_PATH, DB_PATH]\n",
    "[(str(p), p.exists(), round(p.stat().st_size/1e6, 3) if p.exists() else None) for p in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd462c81-999f-4af2-8dd8-dfaf0f3da01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'row_definition': 'Each row represents one 311 service request.',\n",
       " 'incremental_key': '',\n",
       " 'high_risk_columns': [],\n",
       " 'sensitive_columns': []}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reflection = {\n",
    "    \"row_definition\": \"Each row represents one 311 service request.\",\n",
    "    \"incremental_key\": \"\",\n",
    "    \"high_risk_columns\": [],\n",
    "    \"sensitive_columns\": [],\n",
    "}\n",
    "reflection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dd8608-e9b4-413f-a175-9df13a11ebf4",
   "metadata": {},
   "source": [
    "# Module 2.B - Data Quality & Structure (NYC 311)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2334db-7fe3-4ef0-bf87-8e989c6879e7",
   "metadata": {},
   "source": [
    "in this notebook we will practice a realistic workflow.  \n",
    "1. **Load** the same NYC311 slice created in 2.A\n",
    "2. **Audit quality:** missingness, duplicates, inconsistencies\n",
    "3. **Detect drift:** \"today vs yesterday\" schema differences\n",
    "4. Produce a short **Data Quality Report** that will be reused in later modules\n",
    "\n",
    "**Note**:  \n",
    "We are not trying to make the dataset perfect.  \n",
    "We are trying to make it **trustworthy enough for a special decision** and to document what was done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10fc27e-0361-4a6a-99a3-a2d94c2fb55f",
   "metadata": {},
   "source": [
    "## 2B.0 - Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc49e2c-0c38-40f5-8f0a-b2813ed80cdd",
   "metadata": {},
   "source": [
    "This notebook expects that **Module 2.A** has already been ran and that a module data workspace has been created  \n",
    "\n",
    "`/work/m2/data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3389f046-a071-4737-aa54-4d0bbd0a47ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /home/glake/Nextcloud/Classwork/CS6678 - Advanced Machine Learning/Jupyter Notebooks/work/m2/data\n",
      "CSV exists? True | work/m2/data/raw/nyc311_last14d.csv\n",
      "JSON exists? True | work/m2/data/raw/nyc311_last14d.json\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 80)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "WORK_DIR   = Path(\"work\")\n",
    "MODULE_DIR = WORK_DIR / \"m2\"\n",
    "DATA_DIR = MODULE_DIR / \"data\"\n",
    "\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "REF_DIR = DATA_DIR / \"reference\"\n",
    "WH_DIR  = DATA_DIR / \"warehouse\"\n",
    "\n",
    "for d in [RAW_DIR, REF_DIR, WH_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CSV_PATH = RAW_DIR / \"nyc311_last14d.csv\"\n",
    "JSON_PATH = RAW_DIR / \"nyc311_last14d.json\"  # optional if you created via API in 2.A\n",
    "\n",
    "print(\"Data directory:\", DATA_DIR.resolve())\n",
    "print(\"CSV exists?\", CSV_PATH.exists(), \"|\", CSV_PATH)\n",
    "print(\"JSON exists?\", JSON_PATH.exists(), \"|\", JSON_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831734f6-d25b-4a07-8fec-19616042f4a7",
   "metadata": {},
   "source": [
    "## 2B.1 - Load the Data and Establish a Row Definition\n",
    "\n",
    "**Row definition (target):** Each row represents one 311 service request, identified by `unique_key`  \n",
    "\n",
    "Before cleaning, we load as-is and profile the mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6c27193-1060-4270-829d-47b36397d7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (50000, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>status</th>\n",
       "      <th>borough</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30T01:51:21.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30T01:51:04.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOE</td>\n",
       "      <td>Department of Education</td>\n",
       "      <td>School Maintenance</td>\n",
       "      <td>Heating Problem</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11226.0</td>\n",
       "      <td>911 FLATBUSH AVENUE</td>\n",
       "      <td>FLATBUSH AVENUE</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40.649787</td>\n",
       "      <td>-73.958550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30T01:50:53.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10025.0</td>\n",
       "      <td>936 AMSTERDAM AVENUE</td>\n",
       "      <td>AMSTERDAM AVENUE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>40.800498</td>\n",
       "      <td>-73.965680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67707975</td>\n",
       "      <td>2026-01-30T01:50:52.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>10302.0</td>\n",
       "      <td>190 TRANTOR PLACE</td>\n",
       "      <td>TRANTOR PLACE</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>40.629156</td>\n",
       "      <td>-74.144411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67771794</td>\n",
       "      <td>2026-01-30T01:50:32.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Taxi and Limousine Commission</td>\n",
       "      <td>Taxi Complaint</td>\n",
       "      <td>Driver Complaint - Non Passenger</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11430.0</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JAMAICA</td>\n",
       "      <td>40.648320</td>\n",
       "      <td>-73.788281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key             created_date closed_date agency                      agency_name       complaint_type  \\\n",
       "0    67720523  2026-01-30T01:51:21.000         NaN   NYPD  New York City Police Department   Noise - Commercial   \n",
       "1    67746090  2026-01-30T01:51:04.000         NaN    DOE          Department of Education   School Maintenance   \n",
       "2    67758820  2026-01-30T01:50:53.000         NaN   NYPD  New York City Police Department  Noise - Residential   \n",
       "3    67707975  2026-01-30T01:50:52.000         NaN   NYPD  New York City Police Department  Noise - Residential   \n",
       "4    67771794  2026-01-30T01:50:32.000         NaN    TLC    Taxi and Limousine Commission       Taxi Complaint   \n",
       "\n",
       "                         descriptor       status        borough  incident_zip        incident_address             street_name  \\\n",
       "0                  Loud Music/Party  Unspecified    Unspecified           NaN                     NaN                     NaN   \n",
       "1                   Heating Problem  In Progress       BROOKLYN       11226.0     911 FLATBUSH AVENUE         FLATBUSH AVENUE   \n",
       "2                  Loud Music/Party  In Progress      MANHATTAN       10025.0    936 AMSTERDAM AVENUE        AMSTERDAM AVENUE   \n",
       "3                  Loud Music/Party  In Progress  STATEN ISLAND       10302.0       190 TRANTOR PLACE           TRANTOR PLACE   \n",
       "4  Driver Complaint - Non Passenger  In Progress         QUEENS       11430.0  JOHN F KENNEDY AIRPORT  JOHN F KENNEDY AIRPORT   \n",
       "\n",
       "            city   latitude  longitude  \n",
       "0            NaN        NaN        NaN  \n",
       "1       BROOKLYN  40.649787 -73.958550  \n",
       "2       NEW YORK  40.800498 -73.965680  \n",
       "3  STATEN ISLAND  40.629156 -74.144411  \n",
       "4        JAMAICA  40.648320 -73.788281  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(CSV_PATH)\n",
    "print(\"Shape:\", df_raw.shape)\n",
    "df_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e90d61f-3e54-4ef4-833e-e855a29cf8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>status</th>\n",
       "      <th>borough</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dtype</th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_key created_date closed_date  agency agency_name complaint_type descriptor  status borough incident_zip incident_address  \\\n",
       "dtype      int64       object      object  object      object         object     object  object  object      float64           object   \n",
       "\n",
       "      street_name    city latitude longitude  \n",
       "dtype      object  object  float64   float64  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.dtypes.to_frame(\"dtype\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3509cca0-82c4-4d0b-98f1-ebd2cb7bc9e5",
   "metadata": {},
   "source": [
    "### Create quality notes  \n",
    "\n",
    "Write row definition and first impressions. Add 3-6 bullets:\n",
    "* What does one row represent?\n",
    "* What columns look risky?\n",
    "* What looks like \"encoded missingness\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa399c7e-9475-4aff-afb6-70180029a87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'row_definition': 'Each row is one 311 service request (unique_key) created at created_date.',\n",
       " 'data_type_notes': ['incident_zip should be treated as a string to preserve leading zeros.',\n",
       "  'descriptor/incident_address are free-text and likely inconsistent.'],\n",
       " 'completeness_issues': [],\n",
       " 'date_added': '1/30/26'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_notes = {\n",
    "    \"row_definition\": \"Each row is one 311 service request (unique_key) created at created_date.\",\n",
    "    \"data_type_notes\": [\n",
    "        \"incident_zip should be treated as a string to preserve leading zeros.\",\n",
    "        \"descriptor/incident_address are free-text and likely inconsistent.\",\n",
    "    ],\n",
    "    \"completeness_issues\": [],\n",
    "    \"date_added\": \"1/30/26\"\n",
    "}\n",
    "quality_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f5272-6ded-4259-972f-9a0d1e7afcea",
   "metadata": {},
   "source": [
    "## 2B.2 - Missing data: Measure, then explain\n",
    "\n",
    "First rule: **do not impute yet**  \n",
    "Start by quantifying missingness and asking why it might be missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6ed7413-b941-453f-8a63-a1240cf122e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "closed_date         0.60766\n",
       "city                0.07640\n",
       "street_name         0.02592\n",
       "incident_address    0.02588\n",
       "latitude            0.01222\n",
       "longitude           0.01222\n",
       "incident_zip        0.00732\n",
       "descriptor          0.00680\n",
       "complaint_type      0.00000\n",
       "agency              0.00000\n",
       "created_date        0.00000\n",
       "unique_key          0.00000\n",
       "agency_name         0.00000\n",
       "status              0.00000\n",
       "borough             0.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_rate = df_raw.isna().mean().sort_values(ascending=False)\n",
    "missing_rate.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23599b62-771b-4a4c-9f81-1856a27c5ad6",
   "metadata": {},
   "source": [
    "### Normalize common \"missing\" encodings  \n",
    "\n",
    "Many real datasets use sentinel values like `\"\"`, `\"UNKNOWN\"`, `\"N/A\"`, or whitespace  \n",
    "\n",
    "Create a `df` as a cleaned copy while keeping `df_raw` unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a39c2d8-77f9-4d43-817b-b186934b9ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "closed_date         0.60766\n",
       "longitude           0.01222\n",
       "latitude            0.01222\n",
       "incident_zip        0.00732\n",
       "agency              0.00000\n",
       "unique_key          0.00000\n",
       "created_date        0.00000\n",
       "descriptor          0.00000\n",
       "complaint_type      0.00000\n",
       "agency_name         0.00000\n",
       "status              0.00000\n",
       "incident_address    0.00000\n",
       "borough             0.00000\n",
       "city                0.00000\n",
       "street_name         0.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "MISSING_TOKENS = {\"\", \" \", \"  \", \"UNKNOWN\", \"Unknown\", \"N/A\", \"NA\", \"NULL\", \"null\"}\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        # Normalize whitespace-only strings\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "        df.loc[df[col].isin(MISSING_TOKENS), col] = np.nan\n",
    "\n",
    "# Parse timestamps (coerce errors to NaT)\n",
    "for col in [\"created_date\", \"closed_date\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "\n",
    "# Treat ZIP as string (preserve leading zeros, handle NaN)\n",
    "if \"incident_zip\" in df.columns:\n",
    "    df[\"incident_zip\"] = df[\"incident_zip\"].astype(\"string\")\n",
    "\n",
    "df.isna().mean().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add9dba2-64cf-4100-a199-64b56276c543",
   "metadata": {},
   "source": [
    "### Missingness by group  \n",
    "\n",
    "If missingness varies a lot by group (borough, agency, complaint type), it is often not random, and that affects modeling and fairness  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aada2c64-572c-4121-a85a-7ab0c13140a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting missingness for: incident_address\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "borough\n",
       "BRONX            0.0\n",
       "BROOKLYN         0.0\n",
       "MANHATTAN        0.0\n",
       "QUEENS           0.0\n",
       "STATEN ISLAND    0.0\n",
       "Unspecified      0.0\n",
       "Name: is_missing, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a column with substantial missingness to inspect\n",
    "target_col = \"incident_address\" if \"incident_address\" in df.columns else df.columns[df.isna().mean().idxmax()]\n",
    "print(\"Inspecting missingness for:\", target_col)\n",
    "\n",
    "group_col = \"borough\" if \"borough\" in df.columns else \"agency\"\n",
    "tmp = df[[group_col, target_col]].copy()\n",
    "tmp[\"is_missing\"] = tmp[target_col].isna().astype(int)\n",
    "\n",
    "missing_by_group = tmp.groupby(group_col)[\"is_missing\"].mean().sort_values(ascending=False)\n",
    "missing_by_group.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "833a1b50-2e11-4014-a7f5-c3bdbc2c4a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed Date missingness for: closed_date\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "borough\n",
       "Unspecified      0.857143\n",
       "STATEN ISLAND    0.728735\n",
       "MANHATTAN        0.631478\n",
       "BROOKLYN         0.598952\n",
       "BRONX            0.593374\n",
       "QUEENS           0.584989\n",
       "Name: is_missing, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check another column - Closed Date\n",
    "target_col = \"closed_date\" if \"closed_date\" in df.columns else df.columns[df.isna().mean().idxmax()]\n",
    "print(\"Closed Date missingness for:\", target_col)\n",
    "\n",
    "group_col = \"borough\" if \"borough\" in df.columns else \"agency\"\n",
    "tmp = df[[group_col, target_col]].copy()\n",
    "tmp[\"is_missing\"] = tmp[target_col].isna().astype(int)\n",
    "\n",
    "missing_by_group = tmp.groupby(group_col)[\"is_missing\"].mean().sort_values(ascending=False)\n",
    "missing_by_group.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ada2c-5915-4df6-8da8-baac9854cb23",
   "metadata": {},
   "source": [
    "### Task - Missingness Hypothesis  \n",
    "\n",
    "Pick one column with missingness > 20% and answer:\n",
    "1. What might cause it to be missing?\n",
    "2. Is it \"optional by design\" (depends on complaint type)?\n",
    "3. Would dropping rows with missing values change what the data represents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eecd232-9b38-402a-ade9-8a966450b81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Column: closed_date': 'often missing because requests are still open, or closure not required',\n",
       " 'More data': 'More data'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missingness_hypothesis = {\n",
    "    \"Column: closed_date\" : \"often missing because requests are still open, or closure not required\",\n",
    "    \"More data\" : \"More data\"\n",
    "}\n",
    "\n",
    "missingness_hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1bafa3-97dc-45a5-8cd1-77bbf20e165d",
   "metadata": {},
   "source": [
    "## 2B.3 - Duplicates: Exact vs Entity Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc8eb5e-331a-46af-8129-13df7a3300b1",
   "metadata": {},
   "source": [
    "For this dataset, `unique_key` should identify a request.  \n",
    "* **Exact duplicates:** identical rows repeated (export/pipeline issues)\n",
    "* **Key duplicates:** `unique_key` repeats (should be rare; indicates ingestion error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80165834-975f-4cae-b8c7-e284e2f7a6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact duplicate rows: 0\n",
      "Duplicate unique_key values: 0\n"
     ]
    }
   ],
   "source": [
    "# Exact duplicates across all columns\n",
    "exact_dup_count = df.duplicated().sum()\n",
    "print(\"Exact duplicate rows:\", int(exact_dup_count))\n",
    "\n",
    "# Duplicates in the request identifier\n",
    "if \"unique_key\" in df.columns:\n",
    "    key_dup_count = df[\"unique_key\"].duplicated().sum()\n",
    "    print(\"Duplicate unique_key values:\", int(key_dup_count))\n",
    "else:\n",
    "    print(\"No unique_key column found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad7ee661-b3a1-4f40-90ae-72fbca6b28da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No key duplicates found (good).\n"
     ]
    }
   ],
   "source": [
    "if \"unique_key\" in df.columns and df[\"unique_key\"].duplicated().any():\n",
    "    dup_keys = df.loc[df[\"unique_key\"].duplicated(keep=False), \"unique_key\"].head(10).tolist()\n",
    "    df[df[\"unique_key\"].isin(dup_keys)].sort_values(\"unique_key\").head(20)\n",
    "else:\n",
    "    print(\"No key duplicates found (good).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba6865f-fab7-467e-9d7a-c39c66a19016",
   "metadata": {},
   "source": [
    "### Decide a depupe rule (if needed)\n",
    "\n",
    "If key duplicates exists, must choose a rule:\n",
    "* keep the newest record (by created_date)\n",
    "* keep the most complete record\n",
    "* keep the first seen (not recommended unless you know ordering is stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c2c23bb-c20c-4eb4-8b31-8bfcdfa52065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (50000, 15) | After: (50000, 15)\n"
     ]
    }
   ],
   "source": [
    "def dedupe_by_key_keep_most_complete(df_in: pd.DataFrame, key: str) -> pd.DataFrame:\n",
    "    \"\"\"Example rule: keep the row with the fewest missing values per key.\"\"\"\n",
    "    if key not in df_in.columns:\n",
    "        return df_in.copy()\n",
    "\n",
    "    df_tmp = df_in.copy()\n",
    "    miss = df_tmp.isna().sum(axis=1)\n",
    "    df_tmp[\"_missing_count\"] = miss\n",
    "    df_tmp = df_tmp.sort_values([key, \"_missing_count\"]).drop_duplicates(subset=[key], keep=\"first\")\n",
    "    return df_tmp.drop(columns=[\"_missing_count\"])\n",
    "\n",
    "df_deduped = dedupe_by_key_keep_most_complete(df, \"unique_key\")\n",
    "print(\"Before:\", df.shape, \"| After:\", df_deduped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6064ee-77e5-4323-8658-052deee28824",
   "metadata": {},
   "source": [
    "**Dedupe Notes:**  \n",
    "\n",
    "If duplicates are present, document the rule. If none are present document what was checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9162ff8f-8b47-440d-947f-1444648ea298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_duplicates': 'None found (or dropped them).',\n",
       " 'unique_key_duplicates': 'None found (or deduped by most complete row).',\n",
       " 'rationale': 'unique_key should be the request identifier; duplicates would indicate pipeline/export issues.',\n",
       " 'deduplication_date': '1/30/26'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedupe_notes = {\n",
    "    \"exact_duplicates\": \"None found (or dropped them).\",\n",
    "    \"unique_key_duplicates\": \"None found (or deduped by most complete row).\",\n",
    "    \"rationale\": \"unique_key should be the request identifier; duplicates would indicate pipeline/export issues.\",\n",
    "    \"deduplication_date\": \"1/30/26\"\n",
    "}\n",
    "dedupe_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69141d08-91eb-48f1-8a36-ae1d402bec55",
   "metadata": {},
   "source": [
    "## 2B.4 - Inconsistencies: Categories, Strings, and \"Almost the Same\" Values  \n",
    "\n",
    "In this dataset, the biggest inconsistency risk tends to be  \n",
    "* **casing / whitespace** (e.g. borough values)\n",
    "* **free-text fields** (descriptor, address)\n",
    "* **categorical sprawl** (complaint_type has many levels)\n",
    "\n",
    "We will do light normalization and build a category audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76a9b682-088b-4fbc-812d-db8bbe729afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== borough ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>borough</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BROOKLYN</th>\n",
       "      <td>15654</td>\n",
       "      <td>0.31308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEENS</th>\n",
       "      <td>11831</td>\n",
       "      <td>0.23662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRONX</th>\n",
       "      <td>10806</td>\n",
       "      <td>0.21612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANHATTAN</th>\n",
       "      <td>8876</td>\n",
       "      <td>0.17752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATEN ISLAND</th>\n",
       "      <td>2798</td>\n",
       "      <td>0.05596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unspecified</th>\n",
       "      <td>35</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count    share\n",
       "borough                      \n",
       "BROOKLYN       15654  0.31308\n",
       "QUEENS         11831  0.23662\n",
       "BRONX          10806  0.21612\n",
       "MANHATTAN       8876  0.17752\n",
       "STATEN ISLAND   2798  0.05596\n",
       "Unspecified       35   0.0007"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== agency ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agency</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HPD</th>\n",
       "      <td>18618</td>\n",
       "      <td>0.37236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DSNY</th>\n",
       "      <td>13160</td>\n",
       "      <td>0.2632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NYPD</th>\n",
       "      <td>11651</td>\n",
       "      <td>0.23302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOT</th>\n",
       "      <td>1980</td>\n",
       "      <td>0.0396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEP</th>\n",
       "      <td>1339</td>\n",
       "      <td>0.02678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOB</th>\n",
       "      <td>766</td>\n",
       "      <td>0.01532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOHMH</th>\n",
       "      <td>624</td>\n",
       "      <td>0.01248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DHS</th>\n",
       "      <td>613</td>\n",
       "      <td>0.01226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DPR</th>\n",
       "      <td>531</td>\n",
       "      <td>0.01062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TLC</th>\n",
       "      <td>246</td>\n",
       "      <td>0.00492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOE</th>\n",
       "      <td>144</td>\n",
       "      <td>0.00288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCWP</th>\n",
       "      <td>141</td>\n",
       "      <td>0.00282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count    share\n",
       "agency                \n",
       "HPD     18618  0.37236\n",
       "DSNY    13160   0.2632\n",
       "NYPD    11651  0.23302\n",
       "DOT      1980   0.0396\n",
       "DEP      1339  0.02678\n",
       "DOB       766  0.01532\n",
       "DOHMH     624  0.01248\n",
       "DHS       613  0.01226\n",
       "DPR       531  0.01062\n",
       "TLC       246  0.00492\n",
       "DOE       144  0.00288\n",
       "DCWP      141  0.00282"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== status ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Closed</th>\n",
       "      <td>18894</td>\n",
       "      <td>0.37788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>15728</td>\n",
       "      <td>0.31456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In Progress</th>\n",
       "      <td>15014</td>\n",
       "      <td>0.30028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assigned</th>\n",
       "      <td>203</td>\n",
       "      <td>0.00406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Started</th>\n",
       "      <td>137</td>\n",
       "      <td>0.00274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pending</th>\n",
       "      <td>22</td>\n",
       "      <td>0.00044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unspecified</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count    share\n",
       "status                     \n",
       "Closed       18894  0.37788\n",
       "Open         15728  0.31456\n",
       "In Progress  15014  0.30028\n",
       "Assigned       203  0.00406\n",
       "Started        137  0.00274\n",
       "Pending         22  0.00044\n",
       "Unspecified      2  0.00004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== complaint_type ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complaint_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Snow or Ice</th>\n",
       "      <td>12376</td>\n",
       "      <td>0.24752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEAT/HOT WATER</th>\n",
       "      <td>11890</td>\n",
       "      <td>0.2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illegal Parking</th>\n",
       "      <td>4922</td>\n",
       "      <td>0.09844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blocked Driveway</th>\n",
       "      <td>2790</td>\n",
       "      <td>0.0558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Noise - Residential</th>\n",
       "      <td>2492</td>\n",
       "      <td>0.04984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNSANITARY CONDITION</th>\n",
       "      <td>1288</td>\n",
       "      <td>0.02576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLUMBING</th>\n",
       "      <td>1212</td>\n",
       "      <td>0.02424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAINT/PLASTER</th>\n",
       "      <td>819</td>\n",
       "      <td>0.01638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOOR/WINDOW</th>\n",
       "      <td>773</td>\n",
       "      <td>0.01546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WATER LEAK</th>\n",
       "      <td>750</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traffic Signal Condition</th>\n",
       "      <td>722</td>\n",
       "      <td>0.01444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water System</th>\n",
       "      <td>549</td>\n",
       "      <td>0.01098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count    share\n",
       "complaint_type                          \n",
       "Snow or Ice               12376  0.24752\n",
       "HEAT/HOT WATER            11890   0.2378\n",
       "Illegal Parking            4922  0.09844\n",
       "Blocked Driveway           2790   0.0558\n",
       "Noise - Residential        2492  0.04984\n",
       "UNSANITARY CONDITION       1288  0.02576\n",
       "PLUMBING                   1212  0.02424\n",
       "PAINT/PLASTER               819  0.01638\n",
       "DOOR/WINDOW                 773  0.01546\n",
       "WATER LEAK                  750    0.015\n",
       "Traffic Signal Condition    722  0.01444\n",
       "Water System                549  0.01098"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def value_counts_audit(df_in: pd.DataFrame, col: str, n: int = 15) -> pd.DataFrame:\n",
    "    vc = df_in[col].astype(\"string\").value_counts(dropna=False).head(n)\n",
    "    out = vc.to_frame(\"count\")\n",
    "    out[\"share\"] = out[\"count\"] / len(df_in)\n",
    "    return out\n",
    "\n",
    "for col in [\"borough\", \"agency\", \"status\", \"complaint_type\"]:\n",
    "    if col in df.columns:\n",
    "        print(\"\\n===\", col, \"===\")\n",
    "        display(value_counts_audit(df, col, n=12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71555d5f-8224-4f9a-8a3d-f546472c3525",
   "metadata": {},
   "source": [
    "### Normalize a few high-impact fields  \n",
    "\n",
    "Do not destroy meaning - just remove noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2de4a4b-45a4-498f-aaf7-ffb325658a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After normalization:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>borough</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BROOKLYN</th>\n",
       "      <td>15654</td>\n",
       "      <td>0.31308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEENS</th>\n",
       "      <td>11831</td>\n",
       "      <td>0.23662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRONX</th>\n",
       "      <td>10806</td>\n",
       "      <td>0.21612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANHATTAN</th>\n",
       "      <td>8876</td>\n",
       "      <td>0.17752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATEN ISLAND</th>\n",
       "      <td>2798</td>\n",
       "      <td>0.05596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;NA&gt;</th>\n",
       "      <td>35</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count    share\n",
       "borough                      \n",
       "BROOKLYN       15654  0.31308\n",
       "QUEENS         11831  0.23662\n",
       "BRONX          10806  0.21612\n",
       "MANHATTAN       8876  0.17752\n",
       "STATEN ISLAND   2798  0.05596\n",
       "<NA>              35   0.0007"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Closed</th>\n",
       "      <td>18894</td>\n",
       "      <td>0.37788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>15728</td>\n",
       "      <td>0.31456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In Progress</th>\n",
       "      <td>15014</td>\n",
       "      <td>0.30028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assigned</th>\n",
       "      <td>203</td>\n",
       "      <td>0.00406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Started</th>\n",
       "      <td>137</td>\n",
       "      <td>0.00274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pending</th>\n",
       "      <td>22</td>\n",
       "      <td>0.00044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unspecified</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count    share\n",
       "status                     \n",
       "Closed       18894  0.37788\n",
       "Open         15728  0.31456\n",
       "In Progress  15014  0.30028\n",
       "Assigned       203  0.00406\n",
       "Started        137  0.00274\n",
       "Pending         22  0.00044\n",
       "Unspecified      2  0.00004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = df_deduped.copy()\n",
    "\n",
    "# Standardize borough to a small canonical set where possible\n",
    "if \"borough\" in df2.columns:\n",
    "    df2[\"borough\"] = df2[\"borough\"].astype(\"string\").str.strip().str.upper()\n",
    "\n",
    "    # Some datasets use \"Unspecified\" or blanks\n",
    "    df2.loc[df2[\"borough\"].isin([\"\", \"NAN\", \"UNSPECIFIED\"]), \"borough\"] = pd.NA\n",
    "\n",
    "# Standardize status\n",
    "if \"status\" in df2.columns:\n",
    "    df2[\"status\"] = df2[\"status\"].astype(\"string\").str.strip().str.title()\n",
    "\n",
    "print(\"After normalization:\")\n",
    "if \"borough\" in df2.columns:\n",
    "    display(value_counts_audit(df2, \"borough\", n=10))\n",
    "if \"status\" in df2.columns:\n",
    "    display(value_counts_audit(df2, \"status\", n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3740033-e9a2-4d9e-b938-1a4bbf21191c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status_column': {'valid_set': 'Appears to be {Open, Closed, Assigned, Pending} (verify)',\n",
       "  'cleaning_policy': \"Strip whitespace, title-case, map near-duplicates (e.g., 'CLOSED' -> 'Closed').\",\n",
       "  'rare_values': \"If rare statuses exist (<0.5%), consider grouping as 'Other' depending on analysis goal.\"}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_policy_notes = {\n",
    "    \"status_column\": {\n",
    "        \"valid_set\": \"Appears to be {Open, Closed, Assigned, Pending} (verify)\",\n",
    "        \"cleaning_policy\": \"Strip whitespace, title-case, map near-duplicates (e.g., 'CLOSED' -> 'Closed').\",\n",
    "        \"rare_values\": \"If rare statuses exist (<0.5%), consider grouping as 'Other' depending on analysis goal.\"\n",
    "    }\n",
    "}\n",
    "category_policy_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59184f0-1f6e-46d3-849c-2f4787d000a7",
   "metadata": {},
   "source": [
    "## 2B.5 - Schema Drift: Compare Versions and Fail Safely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04370c-8f31-4162-891a-34ed5c012db5",
   "metadata": {},
   "source": [
    "Drift can show up as:\n",
    "* column added/removed\n",
    "* type changes (number - string)\n",
    "* semantic changes (same name, different meaning)\n",
    "\n",
    "We will do two comparisons.  \n",
    "1. **CSV vs JSON**\n",
    "2. **yesterday vs today simulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1031df68-7aa9-43f6-9973-cc5a68b5282e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agency</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agency_name</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>borough</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>city</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>closed_date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         column           dtype\n",
       "3        agency          object\n",
       "4   agency_name          object\n",
       "8       borough          string\n",
       "12         city          object\n",
       "2   closed_date  datetime64[ns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def schema_signature(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    return pd.DataFrame({\"column\": df_in.columns, \"dtype\": [str(t) for t in df_in.dtypes]}).sort_values(\"column\")\n",
    "\n",
    "def schema_diff(sig_a: pd.DataFrame, sig_b: pd.DataFrame) -> dict:\n",
    "    a_cols = set(sig_a[\"column\"])\n",
    "    b_cols = set(sig_b[\"column\"])\n",
    "    added = sorted(list(b_cols - a_cols))\n",
    "    removed = sorted(list(a_cols - b_cols))\n",
    "\n",
    "    merged = sig_a.merge(sig_b, on=\"column\", how=\"outer\", suffixes=(\"_a\", \"_b\"))\n",
    "    changed = merged[(merged[\"dtype_a\"].notna()) & (merged[\"dtype_b\"].notna()) & (merged[\"dtype_a\"] != merged[\"dtype_b\"])]\n",
    "    return {\n",
    "        \"added\": added,\n",
    "        \"removed\": removed,\n",
    "        \"dtype_changed\": changed.sort_values(\"column\")\n",
    "    }\n",
    "\n",
    "sig_csv = schema_signature(df2)\n",
    "sig_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09edb9e9-6ec3-46e8-a6d2-e2c52ed662a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CSV vs JSON schema drift ===\n",
      "Added in JSON (vs CSV): [] \n",
      "Removed in JSON (vs CSV): [] \n",
      "\n",
      "Dtype changes (top 20):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype_a</th>\n",
       "      <th>dtype_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>borough</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>closed_date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>created_date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>incident_zip</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>latitude</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>longitude</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>status</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>unique_key</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          column         dtype_a dtype_b\n",
       "2        borough          string  object\n",
       "4    closed_date  datetime64[ns]  object\n",
       "6   created_date  datetime64[ns]  object\n",
       "9   incident_zip          string  object\n",
       "10      latitude         float64  object\n",
       "11     longitude         float64  object\n",
       "12        status          string  object\n",
       "14    unique_key           int64  object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if JSON_PATH.exists():\n",
    "    records = json.loads(JSON_PATH.read_text())\n",
    "    df_json = pd.json_normalize(records)\n",
    "\n",
    "    sig_json = schema_signature(df_json)\n",
    "    diff = schema_diff(sig_csv, sig_json)\n",
    "\n",
    "    print(\"=== CSV vs JSON schema drift ===\")\n",
    "    print(\"Added in JSON (vs CSV):\", diff[\"added\"][:20], \"...\" if len(diff[\"added\"])>20 else \"\")\n",
    "    print(\"Removed in JSON (vs CSV):\", diff[\"removed\"][:20], \"...\" if len(diff[\"removed\"])>20 else \"\")\n",
    "    print(\"\\nDtype changes (top 20):\")\n",
    "    display(diff[\"dtype_changed\"].head(20))\n",
    "else:\n",
    "    print(\"JSON not found. (That's okay.) Run 2.A API section to generate:\", JSON_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c4f50a-893f-4fea-a00b-f82adc972fdc",
   "metadata": {},
   "source": [
    "### Drift Simulation - intentially mutate a new version  \n",
    "\n",
    "This is what drift feels like operationally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2a9e808-1ccc-4190-8396-547ece0804e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Today vs 'new version' ===\n",
      "Added: ['incident_zipcode']\n",
      "Removed: ['incident_zip']\n",
      "\n",
      "Dtype changes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype_a</th>\n",
       "      <th>dtype_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>unique_key</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        column dtype_a dtype_b\n",
       "15  unique_key   int64  object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_new = df2.copy()\n",
    "\n",
    "# Simulate drift: rename a column and change a type\n",
    "if \"incident_zip\" in df_new.columns:\n",
    "    df_new = df_new.rename(columns={\"incident_zip\": \"incident_zipcode\"})  # column rename\n",
    "\n",
    "if \"unique_key\" in df_new.columns:\n",
    "    df_new[\"unique_key\"] = df_new[\"unique_key\"].astype(str)  # type change (int -> str)\n",
    "\n",
    "sig_new = schema_signature(df_new)\n",
    "diff2 = schema_diff(sig_csv, sig_new)\n",
    "\n",
    "print(\"=== Today vs 'new version' ===\")\n",
    "print(\"Added:\", diff2[\"added\"])\n",
    "print(\"Removed:\", diff2[\"removed\"])\n",
    "print(\"\\nDtype changes:\")\n",
    "display(diff2[\"dtype_changed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76b6462e-44b6-41bb-a004-d4d22dcb80ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'required_columns': ['unique_key',\n",
       "  'created_date',\n",
       "  'complaint_type',\n",
       "  'status'],\n",
       " 'policies': {'missing_required': 'Fail hard and alert (stop pipeline).',\n",
       "  'missing_optional': 'Add column filled with nulls + log warning.',\n",
       "  'dtype_changes': 'Attempt safe coercion; if coercion fails above threshold, fail hard.'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drift_strategy_notes = {\n",
    "    \"required_columns\": [\"unique_key\", \"created_date\", \"complaint_type\", \"status\"],\n",
    "    \"policies\": {\n",
    "        \"missing_required\": \"Fail hard and alert (stop pipeline).\",\n",
    "        \"missing_optional\": \"Add column filled with nulls + log warning.\",\n",
    "        \"dtype_changes\": \"Attempt safe coercion; if coercion fails above threshold, fail hard.\"\n",
    "    }\n",
    "}\n",
    "drift_strategy_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b16fb-9ba8-4176-b3dd-e1e5fb71ee5f",
   "metadata": {},
   "source": [
    "## 2B.6 - Deliverable: Data Quality Report (draft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce61facd-28c8-4194-8d6b-72b4bd002cb4",
   "metadata": {},
   "source": [
    "This is a short artifact that can be reused in future modules  \n",
    "\n",
    "**Include:**\n",
    "1. Row definition\n",
    "2. Biggest missingness findings + hypothesis\n",
    "3. Dedupe checks + rule\n",
    "4. Category policy note\n",
    "5. Drift Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75854273-a0ac-4f30-9ee8-f8fea6adf4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"dataset\": \"NYC 311 Service Requests (last 14 days slice)\",\n",
      "  \"generated_at_utc\": \"2026-02-01T17:16:54.060563+00:00\",\n",
      "  \"row_definition\": \"Each row represents one 311 service request (unique_key).\",\n",
      "  \"quality_notes\": {\n",
      "    \"row_definition\": \"Each row is one 311 service request (unique_key) created at created_date.\",\n",
      "    \"data_type_notes\": [\n",
      "      \"incident_zip should be treated as a string to preserve leading zeros.\",\n",
      "      \"descriptor/incident_address are free-text and likely inconsistent.\"\n",
      "    ],\n",
      "    \"completeness_issues\": [],\n",
      "    \"date_added\": \"1/30/26\"\n",
      "  },\n",
      "  \"missingness_hypothesis\": {\n",
      "    \"Column: closed_date\": \"often missing because requests are still open, or closure not required\",\n",
      "    \"More data\": \"More data\"\n",
      "  },\n",
      "  \"dedupe_notes\": {\n",
      "    \"exact_duplicates\": \"None found (or dropped them).\",\n",
      "    \"unique_key_duplicates\": \"None found (or deduped by most complete row).\",\n",
      "    \"rationale\": \"unique_key should be the request identifier; duplicates would indicate pipeline/export issues.\",\n",
      "    \"deduplication_date\": \"1/30/26\"\n",
      "  },\n",
      "  \"category_policy_notes\": {\n",
      "    \"status_column\": {\n",
      "      \"valid_set\": \"Appears to be {Open, Closed, Assigned, Pending} (verify)\",\n",
      "      \"cleaning_policy\": \"Strip whitespace, title-case, map near-duplicates (e.g., 'CLOSED' -> 'Closed').\",\n",
      "      \"rare_values\": \"If rare statuses exist (<0.5%), consider grouping as 'Other' depending on analysis goal.\"\n",
      "    }\n",
      "  },\n",
      "  \"drift_strategy_notes\": {\n",
      "    \"required_columns\": [\n",
      "      \"unique_key\",\n",
      "      \"created_date\",\n",
      "      \"complaint_type\",\n",
      "      \"status\"\n",
      "    ],\n",
      "    \"policies\": {\n",
      "      \"missing_required\": \"Fail hard and alert (stop pipeline).\",\n",
      "      \"missing_optional\": \"Add column filled with nulls + log warning.\",\n",
      "      \"dtype_changes\": \"Attempt safe coercion; if coercion fails above threshold, fail hard.\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "... (truncated preview) ...\n"
     ]
    }
   ],
   "source": [
    "report = {\n",
    "    \"dataset\": \"NYC 311 Service Requests (last 14 days slice)\",\n",
    "    \"generated_at_utc\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"row_definition\": \"Each row represents one 311 service request (unique_key).\",\n",
    "    \"quality_notes\": quality_notes,\n",
    "    \"missingness_hypothesis\": missingness_hypothesis,\n",
    "    \"dedupe_notes\": dedupe_notes,\n",
    "    \"category_policy_notes\": category_policy_notes,\n",
    "    \"drift_strategy_notes\": drift_strategy_notes,\n",
    "}\n",
    "\n",
    "print(json.dumps(report, indent=2)[:2000] + \"\\n... (truncated preview) ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dab2e8-2f87-494d-8aab-717514fd2877",
   "metadata": {},
   "source": [
    "### Save Report  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "def2cc53-dcbf-4617-8f64-9e8e86290593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved report: work/m2/data/reference/quality_report.json\n"
     ]
    }
   ],
   "source": [
    "REPORT_PATH = REF_DIR / \"quality_report.json\"\n",
    "REPORT_PATH.write_text(json.dumps(report, indent=2))\n",
    "print(\"Saved report:\", REPORT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be5efb-bf1d-445f-85d6-b2e7856c7066",
   "metadata": {},
   "source": [
    "# Module 2.C - Data Wrangling and Transformation (NYC 311)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a3f9b-ef10-4845-bf02-9de8fb369e50",
   "metadata": {},
   "source": [
    "In this module, we will:  \n",
    "1. Load the NYC 311 slice created in **2.A**\n",
    "2. Reuse the quality assumptions from **2.B** (`quality_report.json`)\n",
    "3. Perform common wrangling patterns in pandas:\n",
    "    * selecting/filtering, creating columns\n",
    "    * `groupby` + aggregation\n",
    "    * merges/joins (with guardrails)\n",
    "    * string cleanup + regex extraction\n",
    "4. Construct a baseline-friendly **feature table** and save it for later modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557c354a-b089-43f9-ad70-bf0960d05e28",
   "metadata": {},
   "source": [
    "## 2C.0 - Setup and Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beba8f09-b8aa-4738-9555-4aac51551700",
   "metadata": {},
   "source": [
    "This notebook assumes the module workspace:  \n",
    "\n",
    "`/work/m2/data`\n",
    "\n",
    "* Raw data from **2.A**: `raw/nyc311_last14d.csv`\n",
    "* Quality report from **2.B**: `reference/quality_report.json`\n",
    "\n",
    "We will write outputs to:\n",
    "\n",
    "* `warehouse/nyc311_requests_features.parquet`\n",
    "* `warehouse/nyc311_daily_features.parquet`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2fb1f54-10ff-4b41-8fd2-b472bb3f1e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV: work/m2/data/raw/nyc311_last14d.csv | exists? True\n",
      "Report: work/m2/data/reference/quality_report.json | exists? True\n",
      "Warehouse: work/m2/data/warehouse\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "WORK_DIR   = Path(\"work\")\n",
    "MODULE_DIR = WORK_DIR / \"m2\"\n",
    "DATA_DIR = MODULE_DIR / \"data\"\n",
    "\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "REF_DIR = DATA_DIR / \"reference\"\n",
    "WH_DIR  = DATA_DIR / \"warehouse\"\n",
    "\n",
    "CSV_PATH = RAW_DIR / \"nyc311_last14d.csv\"\n",
    "REPORT_PATH = REF_DIR / \"quality_report.json\"\n",
    "\n",
    "OUT_REQUESTS = WH_DIR / \"nyc311_requests_features.parquet\"\n",
    "OUT_DAILY    = WH_DIR / \"nyc311_daily_features.parquet\"\n",
    "\n",
    "print(\"CSV:\", CSV_PATH, \"| exists?\", CSV_PATH.exists())\n",
    "print(\"Report:\", REPORT_PATH, \"| exists?\", REPORT_PATH.exists())\n",
    "print(\"Warehouse:\", WH_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4896248b-787d-4c91-8887-f432e84edd8f",
   "metadata": {},
   "source": [
    "### Load the quality report from from 2.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81c537fa-fbc8-4445-be9d-68ea4fccabd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded report generated_at_utc: 2026-02-01T17:16:54.060563+00:00\n",
      "Row definition: Each row represents one 311 service request (unique_key).\n",
      "\n",
      "Top-level keys: ['category_policy_notes', 'dataset', 'dedupe_notes', 'drift_strategy_notes', 'generated_at_utc', 'missingness_hypothesis', 'quality_notes', 'row_definition']\n"
     ]
    }
   ],
   "source": [
    "report = None\n",
    "if REPORT_PATH.exists():\n",
    "    report = json.loads(REPORT_PATH.read_text())\n",
    "    print(\"Loaded report generated_at_utc:\", report.get(\"generated_at_utc\"))\n",
    "    print(\"Row definition:\", report.get(\"row_definition\"))\n",
    "else:\n",
    "    print(\"No quality_report.json found. Run 2.B to generate it.\")\n",
    "\n",
    "# Optional: inspect notes\n",
    "if report:\n",
    "    print(\"\\nTop-level keys:\", sorted(report.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d1dfff-64f5-42a0-8679-515062163cb3",
   "metadata": {},
   "source": [
    "## 2C.1 - Load Data and Re-apply Light Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a8a84-dc3d-4849-b3f5-6f1583f1e909",
   "metadata": {},
   "source": [
    "We keep this normalization conservative and explainable.  \n",
    "\n",
    "**Row definition:** Each row represents one 311 service request, identified by `unique_key`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "932cddd9-ab12-477c-9bb4-ce49101fe09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape: (50000, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>status</th>\n",
       "      <th>borough</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30T01:51:21.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30T01:51:04.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOE</td>\n",
       "      <td>Department of Education</td>\n",
       "      <td>School Maintenance</td>\n",
       "      <td>Heating Problem</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11226.0</td>\n",
       "      <td>911 FLATBUSH AVENUE</td>\n",
       "      <td>FLATBUSH AVENUE</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40.649787</td>\n",
       "      <td>-73.958550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30T01:50:53.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10025.0</td>\n",
       "      <td>936 AMSTERDAM AVENUE</td>\n",
       "      <td>AMSTERDAM AVENUE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>40.800498</td>\n",
       "      <td>-73.965680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67707975</td>\n",
       "      <td>2026-01-30T01:50:52.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>10302.0</td>\n",
       "      <td>190 TRANTOR PLACE</td>\n",
       "      <td>TRANTOR PLACE</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>40.629156</td>\n",
       "      <td>-74.144411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67771794</td>\n",
       "      <td>2026-01-30T01:50:32.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Taxi and Limousine Commission</td>\n",
       "      <td>Taxi Complaint</td>\n",
       "      <td>Driver Complaint - Non Passenger</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11430.0</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JAMAICA</td>\n",
       "      <td>40.648320</td>\n",
       "      <td>-73.788281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key             created_date closed_date agency                      agency_name       complaint_type  \\\n",
       "0    67720523  2026-01-30T01:51:21.000         NaN   NYPD  New York City Police Department   Noise - Commercial   \n",
       "1    67746090  2026-01-30T01:51:04.000         NaN    DOE          Department of Education   School Maintenance   \n",
       "2    67758820  2026-01-30T01:50:53.000         NaN   NYPD  New York City Police Department  Noise - Residential   \n",
       "3    67707975  2026-01-30T01:50:52.000         NaN   NYPD  New York City Police Department  Noise - Residential   \n",
       "4    67771794  2026-01-30T01:50:32.000         NaN    TLC    Taxi and Limousine Commission       Taxi Complaint   \n",
       "\n",
       "                         descriptor       status        borough  incident_zip        incident_address             street_name  \\\n",
       "0                  Loud Music/Party  Unspecified    Unspecified           NaN                     NaN                     NaN   \n",
       "1                   Heating Problem  In Progress       BROOKLYN       11226.0     911 FLATBUSH AVENUE         FLATBUSH AVENUE   \n",
       "2                  Loud Music/Party  In Progress      MANHATTAN       10025.0    936 AMSTERDAM AVENUE        AMSTERDAM AVENUE   \n",
       "3                  Loud Music/Party  In Progress  STATEN ISLAND       10302.0       190 TRANTOR PLACE           TRANTOR PLACE   \n",
       "4  Driver Complaint - Non Passenger  In Progress         QUEENS       11430.0  JOHN F KENNEDY AIRPORT  JOHN F KENNEDY AIRPORT   \n",
       "\n",
       "            city   latitude  longitude  \n",
       "0            NaN        NaN        NaN  \n",
       "1       BROOKLYN  40.649787 -73.958550  \n",
       "2       NEW YORK  40.800498 -73.965680  \n",
       "3  STATEN ISLAND  40.629156 -74.144411  \n",
       "4        JAMAICA  40.648320 -73.788281  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(CSV_PATH)\n",
    "print(\"Raw shape:\", df_raw.shape)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6731050-b6e3-462b-a471-93628b1e9460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized shape: (50000, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>status</th>\n",
       "      <th>borough</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30 01:51:21</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30 01:51:04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>DOE</td>\n",
       "      <td>Department of Education</td>\n",
       "      <td>School Maintenance</td>\n",
       "      <td>Heating Problem</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11226.0</td>\n",
       "      <td>911 FLATBUSH AVENUE</td>\n",
       "      <td>FLATBUSH AVENUE</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40.649787</td>\n",
       "      <td>-73.958550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30 01:50:53</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10025.0</td>\n",
       "      <td>936 AMSTERDAM AVENUE</td>\n",
       "      <td>AMSTERDAM AVENUE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>40.800498</td>\n",
       "      <td>-73.965680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67707975</td>\n",
       "      <td>2026-01-30 01:50:52</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>10302.0</td>\n",
       "      <td>190 TRANTOR PLACE</td>\n",
       "      <td>TRANTOR PLACE</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>40.629156</td>\n",
       "      <td>-74.144411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67771794</td>\n",
       "      <td>2026-01-30 01:50:32</td>\n",
       "      <td>NaT</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Taxi and Limousine Commission</td>\n",
       "      <td>Taxi Complaint</td>\n",
       "      <td>Driver Complaint - Non Passenger</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11430.0</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JAMAICA</td>\n",
       "      <td>40.648320</td>\n",
       "      <td>-73.788281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key        created_date closed_date agency                      agency_name       complaint_type  \\\n",
       "0    67720523 2026-01-30 01:51:21         NaT   NYPD  New York City Police Department   Noise - Commercial   \n",
       "1    67746090 2026-01-30 01:51:04         NaT    DOE          Department of Education   School Maintenance   \n",
       "2    67758820 2026-01-30 01:50:53         NaT   NYPD  New York City Police Department  Noise - Residential   \n",
       "3    67707975 2026-01-30 01:50:52         NaT   NYPD  New York City Police Department  Noise - Residential   \n",
       "4    67771794 2026-01-30 01:50:32         NaT    TLC    Taxi and Limousine Commission       Taxi Complaint   \n",
       "\n",
       "                         descriptor       status        borough incident_zip        incident_address             street_name  \\\n",
       "0                  Loud Music/Party  Unspecified           <NA>         <NA>                     nan                     nan   \n",
       "1                   Heating Problem  In Progress       BROOKLYN      11226.0     911 FLATBUSH AVENUE         FLATBUSH AVENUE   \n",
       "2                  Loud Music/Party  In Progress      MANHATTAN      10025.0    936 AMSTERDAM AVENUE        AMSTERDAM AVENUE   \n",
       "3                  Loud Music/Party  In Progress  STATEN ISLAND      10302.0       190 TRANTOR PLACE           TRANTOR PLACE   \n",
       "4  Driver Complaint - Non Passenger  In Progress         QUEENS      11430.0  JOHN F KENNEDY AIRPORT  JOHN F KENNEDY AIRPORT   \n",
       "\n",
       "            city   latitude  longitude  \n",
       "0            nan        NaN        NaN  \n",
       "1       BROOKLYN  40.649787 -73.958550  \n",
       "2       NEW YORK  40.800498 -73.965680  \n",
       "3  STATEN ISLAND  40.629156 -74.144411  \n",
       "4        JAMAICA  40.648320 -73.788281  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conservative normalization helpers (similar spirit 2.B)\n",
    "def normalize_missing_strings(df: pd.DataFrame, missing_tokens: str[str]) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in out.columns:\n",
    "        if out[c].dtype == \"object\":\n",
    "            s = out[c].astype(str).str.strip()\n",
    "            # Replace known tokens with NaN (exact match)\n",
    "            s = s.replace({t: np.nan for t in missing_tokens})\n",
    "            out[c] = s\n",
    "    return out\n",
    "\n",
    "MISSING_TOKENS = {\"\", \" \", \"  \", \"UNKNOWN\", \"Unkown\", \"N/A\", \"NA\", \"NULL\", \"null\"}\n",
    "\n",
    "df = normalize_missing_strings(df_raw, MISSING_TOKENS)\n",
    "\n",
    "# Parse timestamps\n",
    "for c in [\"created_date\", \"closed_date\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "\n",
    "# Preserve ZIP as string (leading zeros)\n",
    "if \"incident_zip\" in df.columns:\n",
    "    df[\"incident_zip\"] = df[\"incident_zip\"].astype(\"string\")\n",
    "\n",
    "# Normalize a few key categoricals\n",
    "if \"borough\" in df.columns:\n",
    "    df[\"borough\"] = df[\"borough\"].astype(\"string\").str.strip().str.upper()\n",
    "    df.loc[df[\"borough\"].isin([\"\", \"NAN\", \"UNSPECIFIED\"]), \"borough\"] = pd.NA\n",
    "\n",
    "if \"status\" in df.columns:\n",
    "    df[\"status\"] = df[\"status\"].astype(\"string\").str.strip().str.title()\n",
    "\n",
    "print(\"Normalized shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e7a168-dd18-4f8f-a3ab-50a9a539486a",
   "metadata": {},
   "source": [
    "### Wrangling sanity checks  \n",
    "\n",
    "These prevent accidentally breaking row meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a2fd5a1-f71c-49ea-adf6-565277739554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate unique_key: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "closed_date         0.60766\n",
       "longitude           0.01222\n",
       "latitude            0.01222\n",
       "incident_zip        0.00732\n",
       "borough             0.00070\n",
       "unique_key          0.00000\n",
       "created_date        0.00000\n",
       "descriptor          0.00000\n",
       "complaint_type      0.00000\n",
       "agency_name         0.00000\n",
       "agency              0.00000\n",
       "incident_address    0.00000\n",
       "status              0.00000\n",
       "city                0.00000\n",
       "street_name         0.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert \"unique_key\" in df.columns, \"Expected unique_key column (row identifier).\"\n",
    "\n",
    "dup_keys = df[\"unique_key\"].duplicated().sum()\n",
    "print(\"Duplicate unique_key:\", int(dup_keys))\n",
    "\n",
    "missing = df.isna().mean().sort_values(ascending=False)\n",
    "missing.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff0428f-1ca5-4f9b-8d31-e7103da2f6a5",
   "metadata": {},
   "source": [
    "## 2B.2 - Pandas Fundamentals: Derived Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce2d5b-bb50-4057-979d-c5c1db29a5b3",
   "metadata": {},
   "source": [
    "We will add a small set of readable derived fields:  \n",
    "* `created_day`(date)\n",
    "* `created_hour`, `dayofweek`, `is_weekend`\n",
    "* `is_closed`\n",
    "* `resolution_hours`(only when closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "601fd7aa-46b0-4779-b470-d38b3990c2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>status</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>resolution_hours</th>\n",
       "      <th>resolution_negative</th>\n",
       "      <th>resolution_over_30d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30 01:51:21</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30 01:51:04</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30 01:50:53</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67707975</td>\n",
       "      <td>2026-01-30 01:50:52</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67771794</td>\n",
       "      <td>2026-01-30 01:50:32</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67708260</td>\n",
       "      <td>2026-01-30 01:50:14</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>67771651</td>\n",
       "      <td>2026-01-30 01:48:41</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>67682527</td>\n",
       "      <td>2026-01-30 01:48:20</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>67720759</td>\n",
       "      <td>2026-01-30 01:45:16</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>67707981</td>\n",
       "      <td>2026-01-30 01:44:53</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key        created_date       status  is_closed  resolution_hours  resolution_negative  resolution_over_30d\n",
       "0    67720523 2026-01-30 01:51:21  Unspecified          0               NaN                    0                    0\n",
       "1    67746090 2026-01-30 01:51:04  In Progress          0               NaN                    0                    0\n",
       "2    67758820 2026-01-30 01:50:53  In Progress          0               NaN                    0                    0\n",
       "3    67707975 2026-01-30 01:50:52  In Progress          0               NaN                    0                    0\n",
       "4    67771794 2026-01-30 01:50:32  In Progress          0               NaN                    0                    0\n",
       "5    67708260 2026-01-30 01:50:14  In Progress          0               NaN                    0                    0\n",
       "6    67771651 2026-01-30 01:48:41  In Progress          0               NaN                    0                    0\n",
       "7    67682527 2026-01-30 01:48:20  In Progress          0               NaN                    0                    0\n",
       "8    67720759 2026-01-30 01:45:16  In Progress          0               NaN                    0                    0\n",
       "9    67707981 2026-01-30 01:44:53  In Progress          0               NaN                    0                    0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "df2[\"created_day\"] = df2[\"created_date\"].dt.date\n",
    "df2[\"created_hour\"] = df2[\"created_date\"].dt.hour\n",
    "df2[\"dayofweek\"] = df2[\"created_date\"].dt.dayofweek  # 0=Mon\n",
    "df2[\"is_weekend\"] = df2[\"dayofweek\"].isin([5, 6]).astype(int)\n",
    "\n",
    "df2[\"is_closed\"] = (df2[\"status\"] == \"Closed\").astype(int)\n",
    "\n",
    "df2[\"resolution_hours\"] = (df2[\"closed_date\"] - df2[\"created_date\"]).dt.total_seconds() / 3600\n",
    "df2.loc[df2[\"closed_date\"].isna(), \"resolution_hours\"] = np.nan\n",
    "\n",
    "# Flag suspicious durations (useful for later validation)\n",
    "df2[\"resolution_negative\"] = (df2[\"resolution_hours\"] < 0).astype(int)\n",
    "df2[\"resolution_over_30d\"] = (df2[\"resolution_hours\"] > (30 * 24)).astype(int)\n",
    "\n",
    "df2[[\"unique_key\",\"created_date\",\"status\",\"is_closed\",\"resolution_hours\",\"resolution_negative\",\"resolution_over_30d\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc320506-0677-4de8-be80-dd1eaf38550c",
   "metadata": {},
   "source": [
    "**Checkpoint - Row count should be unchanged**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f61d8a38-cbcf-49dc-9ccf-382edd036de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before: 50000 | after derived cols: 50000\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows before:\", len(df), \"| after derived cols:\", len(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6727ca3b-39a6-49ef-a347-0fb6d94a1683",
   "metadata": {},
   "source": [
    "## 2C.3 - Groupby: Build Summary Tables, Then Merge Back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9e5524-9489-448d-b84f-b8b7187f4c9b",
   "metadata": {},
   "source": [
    "We build two summary tables:  \n",
    "1. Daily metrics (one row per day)\n",
    "2. Agency metrics (one row per agency)\n",
    "\n",
    "Then merge them back as request-level features.  \n",
    "\n",
    "**Guardrail:** Merges should not change row count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44d5c338-62bb-4875-bdc4-2e9a6c9fb2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_day</th>\n",
       "      <th>n_requests</th>\n",
       "      <th>closed_rate</th>\n",
       "      <th>median_resolution_hours</th>\n",
       "      <th>p90_resolution_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-27</td>\n",
       "      <td>17529</td>\n",
       "      <td>0.405557</td>\n",
       "      <td>4.092778</td>\n",
       "      <td>42.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-28</td>\n",
       "      <td>16913</td>\n",
       "      <td>0.403063</td>\n",
       "      <td>2.390000</td>\n",
       "      <td>25.913028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-29</td>\n",
       "      <td>15278</td>\n",
       "      <td>0.317188</td>\n",
       "      <td>1.326389</td>\n",
       "      <td>6.508389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>280</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.480972</td>\n",
       "      <td>1.098250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  created_day  n_requests  closed_rate  median_resolution_hours  p90_resolution_hours\n",
       "0  2026-01-27       17529     0.405557                 4.092778             42.981000\n",
       "1  2026-01-28       16913     0.403063                 2.390000             25.913028\n",
       "2  2026-01-29       15278     0.317188                 1.326389              6.508389\n",
       "3  2026-01-30         280     0.435714                 0.480972              1.098250"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Daily table (unit: day)\n",
    "daily = (\n",
    "    df2.groupby(\"created_day\", dropna=False)\n",
    "       .agg(\n",
    "           n_requests=(\"unique_key\", \"count\"),\n",
    "           closed_rate=(\"is_closed\", \"mean\"),\n",
    "           median_resolution_hours=(\"resolution_hours\", \"median\"),\n",
    "           p90_resolution_hours=(\"resolution_hours\", lambda s: np.nanpercentile(s, 90) if np.isfinite(s).any() else np.nan),\n",
    "       )\n",
    "       .reset_index()\n",
    ")\n",
    "\n",
    "daily.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00fbcd82-a11f-4eae-88fa-19b3f51e469f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_n_requests</th>\n",
       "      <th>agency_closed_rate</th>\n",
       "      <th>agency_median_resolution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HPD</td>\n",
       "      <td>18618</td>\n",
       "      <td>0.239446</td>\n",
       "      <td>23.354861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DSNY</td>\n",
       "      <td>13160</td>\n",
       "      <td>0.060334</td>\n",
       "      <td>20.099722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NYPD</td>\n",
       "      <td>11651</td>\n",
       "      <td>0.981890</td>\n",
       "      <td>1.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DOT</td>\n",
       "      <td>1980</td>\n",
       "      <td>0.381313</td>\n",
       "      <td>2.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEP</td>\n",
       "      <td>1339</td>\n",
       "      <td>0.530993</td>\n",
       "      <td>1.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DOB</td>\n",
       "      <td>766</td>\n",
       "      <td>0.191906</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DOHMH</td>\n",
       "      <td>624</td>\n",
       "      <td>0.200321</td>\n",
       "      <td>14.663611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DHS</td>\n",
       "      <td>613</td>\n",
       "      <td>0.370310</td>\n",
       "      <td>13.062222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DPR</td>\n",
       "      <td>531</td>\n",
       "      <td>0.190207</td>\n",
       "      <td>13.409167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>TLC</td>\n",
       "      <td>246</td>\n",
       "      <td>0.117886</td>\n",
       "      <td>16.582778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agency  agency_n_requests  agency_closed_rate  agency_median_resolution\n",
       "10    HPD              18618            0.239446                 23.354861\n",
       "8    DSNY              13160            0.060334                 20.099722\n",
       "11   NYPD              11651            0.981890                  1.277778\n",
       "6     DOT               1980            0.381313                  2.400000\n",
       "1     DEP               1339            0.530993                  1.033333\n",
       "3     DOB                766            0.191906                  0.000000\n",
       "5   DOHMH                624            0.200321                 14.663611\n",
       "2     DHS                613            0.370310                 13.062222\n",
       "7     DPR                531            0.190207                 13.409167\n",
       "14    TLC                246            0.117886                 16.582778"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Agency table (unit: agency)\n",
    "agency = (\n",
    "    df2.groupby(\"agency\", dropna=False)\n",
    "       .agg(\n",
    "           agency_n_requests=(\"unique_key\", \"count\"),\n",
    "           agency_closed_rate=(\"is_closed\", \"mean\"),\n",
    "           agency_median_resolution=(\"resolution_hours\", \"median\")\n",
    "       )\n",
    "        .reset_index()\n",
    ")\n",
    "\n",
    "agency.sort_values(\"agency_n_requests\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02f7e1ea-457b-473d-aa20-a80a0be838f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after merges: 50000\n",
      "Row count preserved\n"
     ]
    }
   ],
   "source": [
    "# Merge summary tables\n",
    "df3 = df2.merge(\n",
    "    daily,\n",
    "    on=\"created_day\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")\n",
    "\n",
    "df3 = df3.merge(\n",
    "    agency,\n",
    "    on=\"agency\",\n",
    "    how=\"left\",\n",
    "    validate=\"many_to_one\"\n",
    ")\n",
    "\n",
    "print(\"Rows after merges:\", len(df3))\n",
    "assert len(df3) == len(df2), \"Row count changed after merges, likely a many-to-many join.\"\n",
    "print(\"Row count preserved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f68895-be0b-4774-b4ba-6c84ddac21fb",
   "metadata": {},
   "source": [
    "## 2C.4 - Strings + Regex: Normalize Categories and Extract Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba3fccd-a30c-426c-a4c4-bb3ef7979f5c",
   "metadata": {},
   "source": [
    "We will do two common tasks:  \n",
    "1. Normalize `complaint_type`\n",
    "2. Create keyword flags from `descriptor`\n",
    "3. Extract a street number from `incident_address` (imperfect on purpose)\n",
    "\n",
    "**Note:** Extraction should produce a quality metric (coverage/fail rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "436fd25b-b423-45a1-8044-8226a850b0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Street number extraction fail rate: 0.081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>complaint_type_norm</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>kw_noise</th>\n",
       "      <th>kw_rodent</th>\n",
       "      <th>kw_water</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>noise - commercial</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nan</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>School Maintenance</td>\n",
       "      <td>school maintenance</td>\n",
       "      <td>Heating Problem</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>911 FLATBUSH AVENUE</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>noise - residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>936 AMSTERDAM AVENUE</td>\n",
       "      <td>936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>noise - residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190 TRANTOR PLACE</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Taxi Complaint</td>\n",
       "      <td>taxi complaint</td>\n",
       "      <td>Driver Complaint - Non Passenger</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Snow or Ice</td>\n",
       "      <td>snow or ice</td>\n",
       "      <td>Sidewalk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>304 CANAL STREET</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Blocked Driveway</td>\n",
       "      <td>blocked driveway</td>\n",
       "      <td>Partial Access</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3498 FORT INDEPENDENCE STREET</td>\n",
       "      <td>3498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>noise - commercial</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66-48 MYRTLE AVENUE</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Snow or Ice</td>\n",
       "      <td>snow or ice</td>\n",
       "      <td>Sidewalk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>217 NOSTRAND AVENUE</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Non-Emergency Police Matter</td>\n",
       "      <td>non-emergency police matter</td>\n",
       "      <td>Trespassing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>365 THATFORD AVENUE</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                complaint_type          complaint_type_norm                        descriptor  kw_noise  kw_rodent  kw_water  \\\n",
       "0           Noise - Commercial           noise - commercial                  Loud Music/Party         1          0         0   \n",
       "1           School Maintenance           school maintenance                   Heating Problem         0          0         0   \n",
       "2          Noise - Residential          noise - residential                  Loud Music/Party         1          0         0   \n",
       "3          Noise - Residential          noise - residential                  Loud Music/Party         1          0         0   \n",
       "4               Taxi Complaint               taxi complaint  Driver Complaint - Non Passenger         0          0         0   \n",
       "5                  Snow or Ice                  snow or ice                          Sidewalk         0          0         0   \n",
       "6             Blocked Driveway             blocked driveway                    Partial Access         0          0         0   \n",
       "7           Noise - Commercial           noise - commercial                  Loud Music/Party         1          0         0   \n",
       "8                  Snow or Ice                  snow or ice                          Sidewalk         0          0         0   \n",
       "9  Non-Emergency Police Matter  non-emergency police matter                       Trespassing         0          0         0   \n",
       "\n",
       "                incident_address  street_number  \n",
       "0                            nan           <NA>  \n",
       "1            911 FLATBUSH AVENUE            911  \n",
       "2           936 AMSTERDAM AVENUE            936  \n",
       "3              190 TRANTOR PLACE            190  \n",
       "4         JOHN F KENNEDY AIRPORT           <NA>  \n",
       "5               304 CANAL STREET            304  \n",
       "6  3498 FORT INDEPENDENCE STREET           3498  \n",
       "7            66-48 MYRTLE AVENUE             66  \n",
       "8            217 NOSTRAND AVENUE            217  \n",
       "9            365 THATFORD AVENUE            365  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4 = df3.copy()\n",
    "\n",
    "# Normalize complaint_type\n",
    "if \"complaint_type\" in df4.columns:\n",
    "    df4[\"complaint_type_norm\"] = (\n",
    "        df4[\"complaint_type\"]\n",
    "          .astype(\"string\")\n",
    "          .str.strip()\n",
    "          .str.lower()\n",
    "    )\n",
    "else:\n",
    "    df4[\"complaint_type_norm\"] = pd.NA\n",
    "\n",
    "# Keyword flags from descriptor\n",
    "if \"descriptor\" in df4.columns:\n",
    "    desc = df4[\"descriptor\"].astype(\"string\").str.lower()\n",
    "    df4[\"kw_noise\"]  = desc.str.contains(r\"noise|loud|music\", regex=True, na=False).astype(int)\n",
    "    df4[\"kw_rodent\"] = desc.str.contains(r\"rat|mice|rodent\", regex=True, na=False).astype(int)\n",
    "    df4[\"kw_water\"]  = desc.str.contains(r\"water|leak|flood\", regex=True, na=False).astype(int)\n",
    "else:\n",
    "    df4[\"kw_noise\"] = 0\n",
    "    df4[\"kw_rodent\"] = 0\n",
    "    df4[\"kw_water\"] = 0\n",
    "\n",
    "# Regex extraction: leading digits as street number\n",
    "if \"incident_address\" in df4.columns:\n",
    "    addr = df4[\"incident_address\"].astype(\"string\")\n",
    "    df4[\"street_number\"] = addr.str.extract(r\"^\\s*(\\d+)\", expand=False)\n",
    "    df4[\"street_number\"] = pd.to_numeric(df4[\"street_number\"], errors=\"coerce\")\n",
    "    fail_rate = float(df4[\"street_number\"].isna().mean())\n",
    "    print(\"Street number extraction fail rate:\", round(fail_rate, 3))\n",
    "else:\n",
    "    df4[\"street_number\"] = np.nan\n",
    "\n",
    "df4[[\"complaint_type\",\"complaint_type_norm\",\"descriptor\",\"kw_noise\",\"kw_rodent\",\"kw_water\",\"incident_address\",\"street_number\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4da2944-8df6-4ef6-ae22-485c6fee2c1f",
   "metadata": {},
   "source": [
    "## 2C.5 - Feature Construction: Baseline-Friendly Encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe352214-5788-4df5-a103-ddb4cf1e39ea",
   "metadata": {},
   "source": [
    "We will build a request-level feature table with:  \n",
    "* time features\n",
    "* borough\n",
    "* compressed complaint categories (top-k &rarr; `other`)\n",
    "* text keyword flags\n",
    "* group-level features (daily + agency)\n",
    "\n",
    "We keep `status/i_closed` and `resolution_hours` as targets/analysis fields, not necessarily safe input featuers for every modeling task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d0fcb30-9d3d-4219-98ca-d8a0129d621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature table shape: (50000, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>created_day</th>\n",
       "      <th>created_hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>agency</th>\n",
       "      <th>borough_norm</th>\n",
       "      <th>complaint_topk</th>\n",
       "      <th>zip_missing</th>\n",
       "      <th>kw_noise</th>\n",
       "      <th>kw_rodent</th>\n",
       "      <th>kw_water</th>\n",
       "      <th>street_number</th>\n",
       "      <th>n_requests</th>\n",
       "      <th>closed_rate</th>\n",
       "      <th>median_resolution_hours</th>\n",
       "      <th>agency_n_requests</th>\n",
       "      <th>agency_closed_rate</th>\n",
       "      <th>agency_median_resolution</th>\n",
       "      <th>status</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>resolution_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30 01:51:21</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>280</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.480972</td>\n",
       "      <td>11651</td>\n",
       "      <td>0.981890</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30 01:51:04</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>DOE</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>911</td>\n",
       "      <td>280</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.480972</td>\n",
       "      <td>144</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>7.605000</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30 01:50:53</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>noise - residential</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>936</td>\n",
       "      <td>280</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.480972</td>\n",
       "      <td>11651</td>\n",
       "      <td>0.981890</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67707975</td>\n",
       "      <td>2026-01-30 01:50:52</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>noise - residential</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>280</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.480972</td>\n",
       "      <td>11651</td>\n",
       "      <td>0.981890</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67771794</td>\n",
       "      <td>2026-01-30 01:50:32</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>TLC</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>280</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.480972</td>\n",
       "      <td>246</td>\n",
       "      <td>0.117886</td>\n",
       "      <td>16.582778</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key        created_date created_day  created_hour  dayofweek  is_weekend agency   borough_norm       complaint_topk  \\\n",
       "0    67720523 2026-01-30 01:51:21  2026-01-30             1          4           0   NYPD           <NA>                other   \n",
       "1    67746090 2026-01-30 01:51:04  2026-01-30             1          4           0    DOE       BROOKLYN                other   \n",
       "2    67758820 2026-01-30 01:50:53  2026-01-30             1          4           0   NYPD      MANHATTAN  noise - residential   \n",
       "3    67707975 2026-01-30 01:50:52  2026-01-30             1          4           0   NYPD  STATEN ISLAND  noise - residential   \n",
       "4    67771794 2026-01-30 01:50:32  2026-01-30             1          4           0    TLC         QUEENS                other   \n",
       "\n",
       "   zip_missing  kw_noise  kw_rodent  kw_water  street_number  n_requests  closed_rate  median_resolution_hours  agency_n_requests  \\\n",
       "0            1         1          0         0           <NA>         280     0.435714                 0.480972              11651   \n",
       "1            0         0          0         0            911         280     0.435714                 0.480972                144   \n",
       "2            0         1          0         0            936         280     0.435714                 0.480972              11651   \n",
       "3            0         1          0         0            190         280     0.435714                 0.480972              11651   \n",
       "4            0         0          0         0           <NA>         280     0.435714                 0.480972                246   \n",
       "\n",
       "   agency_closed_rate  agency_median_resolution       status  is_closed  resolution_hours  \n",
       "0            0.981890                  1.277778  Unspecified          0               NaN  \n",
       "1            0.520833                  7.605000  In Progress          0               NaN  \n",
       "2            0.981890                  1.277778  In Progress          0               NaN  \n",
       "3            0.981890                  1.277778  In Progress          0               NaN  \n",
       "4            0.117886                 16.582778  In Progress          0               NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat = df4.copy()\n",
    "\n",
    "# Top-k complaint categories (normalized)\n",
    "k = 15\n",
    "if \"complaint_type_norm\" in df_feat.columns:\n",
    "    topk = df_feat[\"complaint_type_norm\"].value_counts().head(k).index\n",
    "    df_feat[\"complaint_topk\"] = df_feat[\"complaint_type_norm\"].where(df_feat[\"complaint_type_norm\"].isin(topk), other=\"other\")\n",
    "else:\n",
    "    df_feat[\"complaint_topk\"] = \"other\"\n",
    "\n",
    "# Location grouping\n",
    "df_feat[\"borough_norm\"] = df_feat[\"borough\"].astype(\"string\") if \"borough\" in df_feat.columns else pd.NA\n",
    "\n",
    "# Missingness flag example\n",
    "df_feat[\"zip_missing\"] = df_feat[\"incident_zip\"].isna().astype(int) if \"incident_zip\" in df_feat.columns else 1\n",
    "\n",
    "keep_cols = [\n",
    "    \"unique_key\",\n",
    "    \"created_date\",\n",
    "    \"created_day\",\n",
    "    \"created_hour\",\n",
    "    \"dayofweek\",\n",
    "    \"is_weekend\",\n",
    "    \"agency\",\n",
    "    \"borough_norm\",\n",
    "    \"complaint_topk\",\n",
    "    \"zip_missing\",\n",
    "    \"kw_noise\",\n",
    "    \"kw_rodent\",\n",
    "    \"kw_water\",\n",
    "    \"street_number\",\n",
    "    # group-level features\n",
    "    \"n_requests\",\n",
    "    \"closed_rate\",\n",
    "    \"median_resolution_hours\",\n",
    "    \"agency_n_requests\",\n",
    "    \"agency_closed_rate\",\n",
    "    \"agency_median_resolution\",\n",
    "    # targets/analysis fields\n",
    "    \"status\",\n",
    "    \"is_closed\",\n",
    "    \"resolution_hours\",\n",
    "]\n",
    "\n",
    "keep_cols = [c for c in keep_cols if c in df_feat.columns]\n",
    "df_model = df_feat[keep_cols].copy()\n",
    "\n",
    "print(\"Feature table shape:\", df_model.shape)\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d39bf7-21f5-4e8c-8184-ffeccf619cd4",
   "metadata": {},
   "source": [
    "### Minimal feature QA  \n",
    "\n",
    "Check missing rates and uniqueness to catch surprises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a5b6711-35a7-41ab-a441-0b555df9cce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>missing_rate</th>\n",
       "      <th>n_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>resolution_hours</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.60766</td>\n",
       "      <td>13719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>street_number</th>\n",
       "      <td>Int64</td>\n",
       "      <td>0.08100</td>\n",
       "      <td>3822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agency_median_resolution</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.00374</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>borough_norm</th>\n",
       "      <td>string</td>\n",
       "      <td>0.00070</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique_key</th>\n",
       "      <td>int64</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_date</th>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>39607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_day</th>\n",
       "      <td>object</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agency</th>\n",
       "      <td>object</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_weekend</th>\n",
       "      <td>int64</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dayofweek</th>\n",
       "      <td>int32</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_hour</th>\n",
       "      <td>int32</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_noise</th>\n",
       "      <td>int64</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_rodent</th>\n",
       "      <td>int64</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zip_missing</th>\n",
       "      <td>int64</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complaint_topk</th>\n",
       "      <td>string</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_requests</th>\n",
       "      <td>int64</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kw_water</th>\n",
       "      <td>int64</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>closed_rate</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median_resolution_hours</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agency_closed_rate</th>\n",
       "      <td>float64</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   dtype  missing_rate  n_unique\n",
       "resolution_hours                 float64       0.60766     13719\n",
       "street_number                      Int64       0.08100      3822\n",
       "agency_median_resolution         float64       0.00374        12\n",
       "borough_norm                      string       0.00070         5\n",
       "unique_key                         int64       0.00000     50000\n",
       "created_date              datetime64[ns]       0.00000     39607\n",
       "created_day                       object       0.00000         4\n",
       "agency                            object       0.00000        15\n",
       "is_weekend                         int64       0.00000         1\n",
       "dayofweek                          int32       0.00000         4\n",
       "created_hour                       int32       0.00000        24\n",
       "kw_noise                           int64       0.00000         2\n",
       "kw_rodent                          int64       0.00000         2\n",
       "zip_missing                        int64       0.00000         2\n",
       "complaint_topk                    string       0.00000        16\n",
       "n_requests                         int64       0.00000         4\n",
       "kw_water                           int64       0.00000         2\n",
       "closed_rate                      float64       0.00000         4\n",
       "median_resolution_hours          float64       0.00000         4\n",
       "agency_closed_rate               float64       0.00000        13"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = pd.DataFrame({\n",
    "    \"dtype\": df_model.dtypes.astype(str),\n",
    "    \"missing_rate\": df_model.isna().mean(),\n",
    "    \"n_unique\": df_model.nunique(dropna=True),\n",
    "}).sort_values(\"missing_rate\", ascending=False)\n",
    "\n",
    "qa.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d49b248-57e1-4aa6-b54d-70fd34adb023",
   "metadata": {},
   "source": [
    "## 2C.6 - Save Outputs for Later Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a3174e-50b6-458e-bfe3-55cda5e2297f",
   "metadata": {},
   "source": [
    "We save two artifacts:  \n",
    "\n",
    "1. Request-level feature table (one row per request)\n",
    "2. Daily feature table (one row per day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8512c65-5091-4a22-a52a-30e0b70da194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved request-level features: work/m2/data/warehouse/nyc311_requests_features.parquet\n",
      "Saved daily features: work/m2/data/warehouse/nyc311_daily_features.parquet\n"
     ]
    }
   ],
   "source": [
    "WH_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_model.to_parquet(OUT_REQUESTS, index=False)\n",
    "daily.to_parquet(OUT_DAILY, index=False)\n",
    "\n",
    "print(\"Saved request-level features:\", OUT_REQUESTS)\n",
    "print(\"Saved daily features:\", OUT_DAILY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9792e30c-6dbb-4764-ac71-6d536434f0a9",
   "metadata": {},
   "source": [
    "## 2C.7 - Deliverable: Transformation Log (short)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63907e93-9f58-4db8-bbdc-37ac13901782",
   "metadata": {},
   "source": [
    "This makes your work reproducible and reviewable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48824000-541b-4d68-b300-ed1f0671a840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved transformation log: work/m2/data/reference/transformation_log.json\n"
     ]
    }
   ],
   "source": [
    "transformation_log = {\n",
    "    \"generated_at_utc\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"row_definition_start\": \"Each row is one 311 request (unique_key).\",\n",
    "    \"row_definition_end\": \"Each row is one 311 request (unique_key), with engineered features.\",\n",
    "    \"steps\": [\n",
    "        \"Normalized missing strings; parsed timestamps; standardized borough/status.\",\n",
    "        \"Created time features and resolution fields (for analysis).\",\n",
    "        \"Aggregated daily and agency metrics; merged back with validate='many_to_one'.\",\n",
    "        \"Normalized complaint types; created descriptor keyword flags; extracted street_number via regex.\",\n",
    "        \"Compressed complaint categories to top-k + 'other'.\",\n",
    "    ],\n",
    "    \"notes\": [\n",
    "        \"street_number extraction is imperfect; measure fail rate and treat as noisy.\",\n",
    "        \"resolution_hours uses closed_date and is not safe as an input feature for predicting closure outcomes (leakage risk).\",\n",
    "    ],\n",
    "    \"artifacts\": {\n",
    "        \"request_features_parquet\": str(OUT_REQUESTS),\n",
    "        \"daily_features_parquet\": str(OUT_DAILY),\n",
    "    }\n",
    "}\n",
    "\n",
    "TRANSFORM_LOG_PATH = REF_DIR / \"transformation_log.json\"\n",
    "TRANSFORM_LOG_PATH.write_text(json.dumps(transformation_log, indent=2))\n",
    "print(\"Saved transformation log:\", TRANSFORM_LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6060b5c0-6f89-4ac2-a5c8-537270ad0257",
   "metadata": {},
   "source": [
    "## 2C.8 - Quick Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dec67d-a046-42b4-a7c8-d5ee4bfde2ff",
   "metadata": {},
   "source": [
    "Should be able to: \n",
    "* Explain what each engineered feature means\n",
    "* Verify merges did not multiple rows\n",
    "* Save a tidy feature table for reuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57610bd-5bf1-4470-ac21-3a43674f26e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Module 2.D - Scaling Data Workflows (mini pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8b0b86-7d5c-46c5-9570-177e20d2f169",
   "metadata": {},
   "source": [
    "So far we have built a small workflow:  \n",
    "* **2.A:** acquire raw data &rarr; `/work/m2/data/raw/`\n",
    "* **2.B:** write quality report &rarr; `/work/m2/data/reference/quality_report.json`\n",
    "* **2.C:** build features tables &rarr; `/work/m2/data/warehouse/*.parquet`\n",
    "\n",
    "This module turns that into a repeatable mini-pipeline:\n",
    "1. Define **pipeline contracts** (inputs/outputs)\n",
    "2. Add **pipeline tests** (fail fast)\n",
    "3. Write **partitioned outputs** (by day)\n",
    "4. Add **run logging** (what changed and why)\n",
    "5. Optional: Compare a pandas step to **Polars**\n",
    "\n",
    "**Note:**  \n",
    "The goal is not \"big data\".  It is repeatability and safety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc82cafe-8f0c-423b-bef6-152bbc475912",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2D.0 - Setup: Paths + Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d0a275-1705-44ed-931c-37a6849b1a9b",
   "metadata": {},
   "source": [
    "We will read:  \n",
    "* Raw CSV: `raw/nyc311_last14d.csv`\n",
    "* Report: `reference/quality_report.json`\n",
    "* Features: `warehouse/nyc311_requests_features.parquet`\n",
    "\n",
    "We will write:\n",
    "* `warehouse/partitions/created_day=YYYY=MM-DD/requests.parquet`\n",
    "* `reference/pipeline_runs_YYYMMDD_HHMMSS_utc.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61ce3921-0c32-4894-a38f-2c5b432c0b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV: work/m2/data/raw/nyc311_last14d.csv | exists? True\n",
      "Report: work/m2/data/reference/quality_report.json | exists? True\n",
      "Features: work/m2/data/warehouse/nyc311_requests_features.parquet | exists? True\n",
      "Partition root: work/m2/data/warehouse/partitions\n",
      "Run log dir: work/m2/data/reference/pipeline_runs\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import json\n",
    "import hashlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 120)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "WORK_DIR   = Path(\"work\")\n",
    "MODULE_DIR = WORK_DIR / \"m2\"\n",
    "DATA_DIR = MODULE_DIR / \"data\"\n",
    "\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "REF_DIR = DATA_DIR / \"reference\"\n",
    "WH_DIR  = DATA_DIR / \"warehouse\"\n",
    "\n",
    "CSV_PATH = RAW_DIR / \"nyc311_last14d.csv\"\n",
    "REPORT_PATH = REF_DIR / \"quality_report.json\"\n",
    "FEATURES_PATH = WH_DIR / \"nyc311_requests_features.parquet\"\n",
    "\n",
    "PART_DIR = WH_DIR / \"partitions\"\n",
    "RUN_DIR = REF_DIR / \"pipeline_runs\"\n",
    "\n",
    "PART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"CSV:\", CSV_PATH, \"| exists?\", CSV_PATH.exists())\n",
    "print(\"Report:\", REPORT_PATH, \"| exists?\", REPORT_PATH.exists())\n",
    "print(\"Features:\", FEATURES_PATH, \"| exists?\", FEATURES_PATH.exists())\n",
    "print(\"Partition root:\", PART_DIR)\n",
    "print(\"Run log dir:\", RUN_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579ed808-1aeb-479d-826f-ee9b66ddf539",
   "metadata": {},
   "source": [
    "## 2D.1 - Pipeline Contract: What Must Be True?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9c8eef-5de7-439e-ae5d-8284959f8248",
   "metadata": {},
   "source": [
    "A scaled workflow starts with **contracts:**\n",
    "* Required input columns\n",
    "* Allowed / expected dtypes\n",
    "* Row definition\n",
    "* Output artifacts\n",
    "\n",
    "If these contracts fail, the pipeline should **fail fast** instead of producing silently bad data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d73efa0-4ab2-403f-9e9f-8984f7465b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Required: ['agency', 'complaint_type', 'created_date', 'status', 'unique_key']\n",
      "Optional (subset): ['borough', 'closed_date', 'descriptor', 'incident_address', 'incident_zip', 'latitude'] ...\n",
      "Row definition: Each row is one 311 service request (unique_key).\n"
     ]
    }
   ],
   "source": [
    "REQUIRED_RAW_COLS = {\n",
    "    \"unique_key\",\n",
    "    \"created_date\",\n",
    "    \"agency\",\n",
    "    \"complaint_type\",\n",
    "    \"status\",\n",
    "}\n",
    "\n",
    "OPTIONAL_RAW_COLS = {\n",
    "    \"closed_date\",\n",
    "    \"borough\",\n",
    "    \"incident_zip\",\n",
    "    \"descriptor\",\n",
    "    \"incident_address\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "}\n",
    "\n",
    "ROW_DEFINITION = \"Each row is one 311 service request (unique_key).\"\n",
    "\n",
    "print(\"Required:\", sorted(REQUIRED_RAW_COLS))\n",
    "print(\"Optional (subset):\", sorted(list(OPTIONAL_RAW_COLS))[:6], \"...\")\n",
    "print(\"Row definition:\", ROW_DEFINITION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfc7544-b78a-43aa-91ef-433120e387d8",
   "metadata": {},
   "source": [
    "**Pipeline test helpers**  \n",
    "\n",
    "We will implement small checks that are cheap but high value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6806f7-2b11-4581-a7de-367a4d13b74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpers ready.\n"
     ]
    }
   ],
   "source": [
    "class PipelineError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "def check_required_columns(df: pd.DataFrame, required: set[str], context: str) -> None:\n",
    "    missing = sorted(list(required - set(df.columns)))\n",
    "    if missing:\n",
    "        raise PipelineError(f\"[{context}] Missing required columns: {missing}\")\n",
    "\n",
    "def check_unique_key(df: pd.DataFrame, key: str, context: str, allow_dupes: bool = False) -> None:\n",
    "    if key not in df.columns:\n",
    "        raise PipelineError(f\"[{context}] Missing key column: {key}\")\n",
    "    n_dupes = int(df[key].duplicated().sum())\n",
    "    if n_dupes and not allow_dupes:\n",
    "        raise PipelineError(f\"[{context}] Key '{key}' has {n_dupes} duplicates (expected unique).\")\n",
    "\n",
    "def check_nonempty(df: pd.DataFrame, context: str) -> None:\n",
    "    if len(df) == 0:\n",
    "        raise PipelineError(f\"[{context}] DataFrame is empty.\")\n",
    "\n",
    "def fingerprint_file(path: Path, n_bytes: int = 2_000_000) -> str:\n",
    "    \"\"\"Stable-ish fingerprint for a file (hash first N bytes + size).\"\"\"\n",
    "    h = hashlib.sha256()\n",
    "    with path.open(\"rb\") as f:\n",
    "        chunk = f.read(n_bytes)\n",
    "    h.update(chunk)\n",
    "    h.update(str(path.stat().st_size).encode(\"utf-8\"))\n",
    "    return h.hexdigest()[:16]\n",
    "\n",
    "print(\"Helpers ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988fa7d5-0d4c-49a4-bcd9-380bcbfb4181",
   "metadata": {},
   "source": [
    "## 2D.2 - Load Raw Data + Validate Contract "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53639bc0-de66-40db-9e82-183223273048",
   "metadata": {},
   "source": [
    "This is where we will catch issues early:\n",
    "* schema drift\n",
    "* missing required fields\n",
    "* broken keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ba9263-d0a1-4d5b-a86b-a1a3ebc903e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape: (50000, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>status</th>\n",
       "      <th>borough</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30T01:51:21.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30T01:51:04.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOE</td>\n",
       "      <td>Department of Education</td>\n",
       "      <td>School Maintenance</td>\n",
       "      <td>Heating Problem</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11226.0</td>\n",
       "      <td>911 FLATBUSH AVENUE</td>\n",
       "      <td>FLATBUSH AVENUE</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40.649787</td>\n",
       "      <td>-73.958550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30T01:50:53.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10025.0</td>\n",
       "      <td>936 AMSTERDAM AVENUE</td>\n",
       "      <td>AMSTERDAM AVENUE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>40.800498</td>\n",
       "      <td>-73.965680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67707975</td>\n",
       "      <td>2026-01-30T01:50:52.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>10302.0</td>\n",
       "      <td>190 TRANTOR PLACE</td>\n",
       "      <td>TRANTOR PLACE</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>40.629156</td>\n",
       "      <td>-74.144411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67771794</td>\n",
       "      <td>2026-01-30T01:50:32.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Taxi and Limousine Commission</td>\n",
       "      <td>Taxi Complaint</td>\n",
       "      <td>Driver Complaint - Non Passenger</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11430.0</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JAMAICA</td>\n",
       "      <td>40.648320</td>\n",
       "      <td>-73.788281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key             created_date closed_date agency                      agency_name       complaint_type  \\\n",
       "0    67720523  2026-01-30T01:51:21.000         NaN   NYPD  New York City Police Department   Noise - Commercial   \n",
       "1    67746090  2026-01-30T01:51:04.000         NaN    DOE          Department of Education   School Maintenance   \n",
       "2    67758820  2026-01-30T01:50:53.000         NaN   NYPD  New York City Police Department  Noise - Residential   \n",
       "3    67707975  2026-01-30T01:50:52.000         NaN   NYPD  New York City Police Department  Noise - Residential   \n",
       "4    67771794  2026-01-30T01:50:32.000         NaN    TLC    Taxi and Limousine Commission       Taxi Complaint   \n",
       "\n",
       "                         descriptor       status        borough  incident_zip        incident_address             street_name  \\\n",
       "0                  Loud Music/Party  Unspecified    Unspecified           NaN                     NaN                     NaN   \n",
       "1                   Heating Problem  In Progress       BROOKLYN       11226.0     911 FLATBUSH AVENUE         FLATBUSH AVENUE   \n",
       "2                  Loud Music/Party  In Progress      MANHATTAN       10025.0    936 AMSTERDAM AVENUE        AMSTERDAM AVENUE   \n",
       "3                  Loud Music/Party  In Progress  STATEN ISLAND       10302.0       190 TRANTOR PLACE           TRANTOR PLACE   \n",
       "4  Driver Complaint - Non Passenger  In Progress         QUEENS       11430.0  JOHN F KENNEDY AIRPORT  JOHN F KENNEDY AIRPORT   \n",
       "\n",
       "            city   latitude  longitude  \n",
       "0            NaN        NaN        NaN  \n",
       "1       BROOKLYN  40.649787 -73.958550  \n",
       "2       NEW YORK  40.800498 -73.965680  \n",
       "3  STATEN ISLAND  40.629156 -74.144411  \n",
       "4        JAMAICA  40.648320 -73.788281  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(CSV_PATH)\n",
    "print(\"Raw shape:\", df_raw.shape)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "650a4117-41b3-4076-9bd3-60e11c3e9091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_rows': 50000,\n",
       " 'n_cols': 15,\n",
       " 'missing_rate_top': {'closed_date': 0.60766,\n",
       "  'city': 0.0764,\n",
       "  'street_name': 0.02592,\n",
       "  'incident_address': 0.02588,\n",
       "  'latitude': 0.01222,\n",
       "  'longitude': 0.01222,\n",
       "  'incident_zip': 0.00732,\n",
       "  'descriptor': 0.0068}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tests\n",
    "check_nonempty(df_raw, \"raw_load\")\n",
    "check_required_columns(df_raw, REQUIRED_RAW_COLS, \"raw_load\")\n",
    "check_unique_key(df_raw, \"unique_key\", \"raw_load\", allow_dupes=True)  # allow in raw: handle later\n",
    "\n",
    "raw_stats = {\n",
    "    \"n_rows\": int(len(df_raw)),\n",
    "    \"n_cols\": int(df_raw.shape[1]),\n",
    "    \"missing_rate_top\": df_raw.isna().mean().sort_values(ascending=False).head(8).to_dict()\n",
    "}\n",
    "\n",
    "raw_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1044d6-eee9-4d78-b4ca-9208b961e320",
   "metadata": {},
   "source": [
    "## 2D.3 - ELT Style Staging: Normalize + Type Parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e188fdda-68a0-4008-881b-ab3002acf65f",
   "metadata": {},
   "source": [
    "In ELT, we often: \n",
    "* **Load** raw data first (keep a copy)\n",
    "* Transform into **staged** and **curated** tables\n",
    "\n",
    "We will create `staged` with conservative normalization similar to 2.B/2.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76d85dd6-0196-4088-b3fa-ed0013d4c1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staged shape: (50000, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>status</th>\n",
       "      <th>borough</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30 01:51:21</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30 01:51:04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>DOE</td>\n",
       "      <td>Department of Education</td>\n",
       "      <td>School Maintenance</td>\n",
       "      <td>Heating Problem</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11226.0</td>\n",
       "      <td>911 FLATBUSH AVENUE</td>\n",
       "      <td>FLATBUSH AVENUE</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40.649787</td>\n",
       "      <td>-73.958550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30 01:50:53</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10025.0</td>\n",
       "      <td>936 AMSTERDAM AVENUE</td>\n",
       "      <td>AMSTERDAM AVENUE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>40.800498</td>\n",
       "      <td>-73.965680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67707975</td>\n",
       "      <td>2026-01-30 01:50:52</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>10302.0</td>\n",
       "      <td>190 TRANTOR PLACE</td>\n",
       "      <td>TRANTOR PLACE</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>40.629156</td>\n",
       "      <td>-74.144411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67771794</td>\n",
       "      <td>2026-01-30 01:50:32</td>\n",
       "      <td>NaT</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Taxi and Limousine Commission</td>\n",
       "      <td>Taxi Complaint</td>\n",
       "      <td>Driver Complaint - Non Passenger</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11430.0</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JAMAICA</td>\n",
       "      <td>40.648320</td>\n",
       "      <td>-73.788281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key        created_date closed_date agency                      agency_name       complaint_type  \\\n",
       "0    67720523 2026-01-30 01:51:21         NaT   NYPD  New York City Police Department   Noise - Commercial   \n",
       "1    67746090 2026-01-30 01:51:04         NaT    DOE          Department of Education   School Maintenance   \n",
       "2    67758820 2026-01-30 01:50:53         NaT   NYPD  New York City Police Department  Noise - Residential   \n",
       "3    67707975 2026-01-30 01:50:52         NaT   NYPD  New York City Police Department  Noise - Residential   \n",
       "4    67771794 2026-01-30 01:50:32         NaT    TLC    Taxi and Limousine Commission       Taxi Complaint   \n",
       "\n",
       "                         descriptor       status        borough incident_zip        incident_address             street_name  \\\n",
       "0                  Loud Music/Party  Unspecified           <NA>         <NA>                     nan                     nan   \n",
       "1                   Heating Problem  In Progress       BROOKLYN      11226.0     911 FLATBUSH AVENUE         FLATBUSH AVENUE   \n",
       "2                  Loud Music/Party  In Progress      MANHATTAN      10025.0    936 AMSTERDAM AVENUE        AMSTERDAM AVENUE   \n",
       "3                  Loud Music/Party  In Progress  STATEN ISLAND      10302.0       190 TRANTOR PLACE           TRANTOR PLACE   \n",
       "4  Driver Complaint - Non Passenger  In Progress         QUEENS      11430.0  JOHN F KENNEDY AIRPORT  JOHN F KENNEDY AIRPORT   \n",
       "\n",
       "            city   latitude  longitude  \n",
       "0            nan        NaN        NaN  \n",
       "1       BROOKLYN  40.649787 -73.958550  \n",
       "2       NEW YORK  40.800498 -73.965680  \n",
       "3  STATEN ISLAND  40.629156 -74.144411  \n",
       "4        JAMAICA  40.648320 -73.788281  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staged = df_raw.copy()\n",
    "\n",
    "MISSING_TOKENS = {\"\", \" \", \"  \", \"UNKNOWN\", \"Unknown\", \"N/A\", \"NA\", \"NULL\", \"null\"}\n",
    "\n",
    "for c in staged.columns:\n",
    "    if staged[c].dtype == \"object\":\n",
    "        s = staged[c].astype(str).str.strip()\n",
    "        s = s.replace({t: np.nan for t in MISSING_TOKENS})\n",
    "        staged[c] = s\n",
    "\n",
    "for c in [\"created_date\", \"closed_date\"]:\n",
    "    if c in staged.columns:\n",
    "        staged[c] = pd.to_datetime(staged[c], errors=\"coerce\")\n",
    "\n",
    "if \"incident_zip\" in staged.columns:\n",
    "    staged[\"incident_zip\"] = staged[\"incident_zip\"].astype(\"string\")\n",
    "\n",
    "if \"borough\" in staged.columns:\n",
    "    staged[\"borough\"] = staged[\"borough\"].astype(\"string\").str.strip().str.upper()\n",
    "    staged.loc[staged[\"borough\"].isin([\"\", \"NAN\", \"UNSPECIFIED\"]), \"borough\"] = pd.NA\n",
    "\n",
    "if \"status\" in staged.columns:\n",
    "    staged[\"status\"] = staged[\"status\"].astype(\"string\").str.strip().str.title()\n",
    "\n",
    "print(\"Staged shape:\", staged.shape)\n",
    "staged.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec8e30-f355-43cc-aa19-a1b47524cb44",
   "metadata": {},
   "source": [
    "**Stage tests + dedupe policy**  \n",
    "\n",
    "We will dedupe by `unique_key` by keeping the most complete row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf12f594-1164-4c24-8a15-8abec8df7d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deduped rows: 50000 -> 50000 | removed: 0\n"
     ]
    }
   ],
   "source": [
    "check_required_columns(staged, REQUIRED_RAW_COLS, \"staged\")\n",
    "\n",
    "def dedupe_by_key_keep_most_complete(df_in: pd.DataFrame, key: str) -> pd.DataFrame:\n",
    "    if key not in df_in.columns:\n",
    "        return df_in.copy()\n",
    "    df_tmp = df_in.copy()\n",
    "    df_tmp[\"_missing_count\"] = df_tmp.isna().sum(axis=1)\n",
    "    df_tmp = df_tmp.sort_values([key, \"_missing_count\"]).drop_duplicates(subset=[key], keep=\"first\")\n",
    "    return df_tmp.drop(columns=[\"_missing_count\"])\n",
    "\n",
    "before = len(staged)\n",
    "staged = dedupe_by_key_keep_most_complete(staged, \"unique_key\")\n",
    "after = len(staged)\n",
    "\n",
    "print(\"Deduped rows:\", before, \"->\", after, \"| removed:\", before - after)\n",
    "check_unique_key(staged, \"unique_key\", \"staged_deduped\", allow_dupes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b7159d-6d95-428e-9ea1-2ba8291b8a3b",
   "metadata": {},
   "source": [
    "## 2D.4 - Curated Table: Minimal Features + Partitioned Write"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13fc02-f674-4b87-b268-28b05a8846b1",
   "metadata": {},
   "source": [
    "We will create a lightweight curated request table, then write Parquet aprtitions by day:  \n",
    "\n",
    "`warehouse/partitions/created_day=YYYY-MM-DD/requests.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea6a9e3b-a2d8-436a-9020-233e99a6a58b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curated shape: (50000, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>created_day</th>\n",
       "      <th>created_hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>agency</th>\n",
       "      <th>complaint_type_norm</th>\n",
       "      <th>status</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>resolution_hours</th>\n",
       "      <th>borough</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>incident_address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42208</th>\n",
       "      <td>67633298</td>\n",
       "      <td>2026-01-27 13:23:00</td>\n",
       "      <td>2026-01-27</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DEP</td>\n",
       "      <td>hazardous materials</td>\n",
       "      <td>Open</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11211.0</td>\n",
       "      <td>Chemical Spill/Release (HA1)</td>\n",
       "      <td>774 DRIGGS AVENUE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42322</th>\n",
       "      <td>67633300</td>\n",
       "      <td>2026-01-27 13:17:00</td>\n",
       "      <td>2026-01-27</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DEP</td>\n",
       "      <td>water system</td>\n",
       "      <td>Started</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11207.0</td>\n",
       "      <td>Excessive Water In Basement (WEFB)</td>\n",
       "      <td>593 WARWICK STREET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48647</th>\n",
       "      <td>67633301</td>\n",
       "      <td>2026-01-27 08:26:00</td>\n",
       "      <td>2026-01-27</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DEP</td>\n",
       "      <td>air quality</td>\n",
       "      <td>Closed</td>\n",
       "      <td>1</td>\n",
       "      <td>49.566667</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11206.0</td>\n",
       "      <td>Air: Odor/Fumes, Vehicle Idling (AD3)</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39232</th>\n",
       "      <td>67633304</td>\n",
       "      <td>2026-01-27 16:05:00</td>\n",
       "      <td>2026-01-27</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DEP</td>\n",
       "      <td>air quality</td>\n",
       "      <td>Started</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11249.0</td>\n",
       "      <td>Air: Odor/Fumes, Vehicle Idling (AD3)</td>\n",
       "      <td>52 RIVER STREET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44498</th>\n",
       "      <td>67633305</td>\n",
       "      <td>2026-01-27 11:26:00</td>\n",
       "      <td>2026-01-27</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>DEP</td>\n",
       "      <td>asbestos</td>\n",
       "      <td>Open</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11104.0</td>\n",
       "      <td>Asbestos Complaint (B1)</td>\n",
       "      <td>45-55 40 STREET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_key        created_date created_day  created_hour  dayofweek  is_weekend agency  complaint_type_norm   status  is_closed  \\\n",
       "42208    67633298 2026-01-27 13:23:00  2026-01-27            13          1           0    DEP  hazardous materials     Open          0   \n",
       "42322    67633300 2026-01-27 13:17:00  2026-01-27            13          1           0    DEP         water system  Started          0   \n",
       "48647    67633301 2026-01-27 08:26:00  2026-01-27             8          1           0    DEP          air quality   Closed          1   \n",
       "39232    67633304 2026-01-27 16:05:00  2026-01-27            16          1           0    DEP          air quality  Started          0   \n",
       "44498    67633305 2026-01-27 11:26:00  2026-01-27            11          1           0    DEP             asbestos     Open          0   \n",
       "\n",
       "       resolution_hours   borough incident_zip                             descriptor    incident_address  \n",
       "42208               NaN  BROOKLYN      11211.0           Chemical Spill/Release (HA1)   774 DRIGGS AVENUE  \n",
       "42322               NaN  BROOKLYN      11207.0     Excessive Water In Basement (WEFB)  593 WARWICK STREET  \n",
       "48647         49.566667  BROOKLYN      11206.0  Air: Odor/Fumes, Vehicle Idling (AD3)                 nan  \n",
       "39232               NaN  BROOKLYN      11249.0  Air: Odor/Fumes, Vehicle Idling (AD3)     52 RIVER STREET  \n",
       "44498               NaN    QUEENS      11104.0                Asbestos Complaint (B1)     45-55 40 STREET  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curated = staged.copy()\n",
    "\n",
    "curated[\"created_day\"] = curated[\"created_date\"].dt.date\n",
    "curated[\"created_hour\"] = curated[\"created_date\"].dt.hour\n",
    "curated[\"dayofweek\"] = curated[\"created_date\"].dt.dayofweek\n",
    "curated[\"is_weekend\"] = curated[\"dayofweek\"].isin([5,6]).astype(int)\n",
    "curated[\"is_closed\"] = (curated[\"status\"] == \"Closed\").astype(int)\n",
    "\n",
    "if \"closed_date\" in curated.columns:\n",
    "    curated[\"resolution_hours\"] = (curated[\"closed_date\"] - curated[\"created_date\"]).dt.total_seconds() / 3600\n",
    "    curated.loc[curated[\"closed_date\"].isna(), \"resolution_hours\"] = np.nan\n",
    "else:\n",
    "    curated[\"resolution_hours\"] = np.nan\n",
    "\n",
    "curated[\"complaint_type_norm\"] = curated[\"complaint_type\"].astype(\"string\").str.strip().str.lower()\n",
    "\n",
    "keep = [\n",
    "    \"unique_key\",\"created_date\",\"created_day\",\"created_hour\",\"dayofweek\",\"is_weekend\",\n",
    "    \"agency\",\"complaint_type_norm\",\"status\",\"is_closed\",\"resolution_hours\",\n",
    "    \"borough\",\"incident_zip\",\"descriptor\",\"incident_address\",\n",
    "]\n",
    "keep = [c for c in keep if c in curated.columns]\n",
    "curated = curated[keep].copy()\n",
    "\n",
    "print(\"Curated shape:\", curated.shape)\n",
    "curated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8e30ca-9f39-4525-bf8c-ee0e98e82905",
   "metadata": {},
   "source": [
    "**Partition Write**  \n",
    "\n",
    "One Parquet file per day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89585a48-f88f-4535-bd82-62a2a4a6edbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote partitions: 4\n",
      "Example: work/m2/data/warehouse/partitions/created_day=2026-01-27/requests.parquet\n"
     ]
    }
   ],
   "source": [
    "n_written = 0\n",
    "example_partition = None\n",
    "\n",
    "for day, chunk in curated.groupby(\"created_day\", dropna=False):\n",
    "    day_str = str(day)\n",
    "    out_dir = PART_DIR / f\"created_day={day_str}\"\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_path = out_dir / \"requests.parquet\"\n",
    "    chunk.to_parquet(out_path, index=False)\n",
    "    n_written += 1\n",
    "    if example_partition is None:\n",
    "        example_partition = out_path\n",
    "\n",
    "print(\"Wrote partitions:\", n_written)\n",
    "print(\"Example:\", example_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e53f422-7ff2-4a3d-8a0e-3ee19e5e9af5",
   "metadata": {},
   "source": [
    "**Read back sanity check**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59e06386-1618-4091-90e3-07fcbf8c4d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking partitions: 3\n",
      "OK: created_day=2026-01-27 rows: 17529\n",
      "OK: created_day=2026-01-28 rows: 16913\n",
      "OK: created_day=2026-01-29 rows: 15278\n"
     ]
    }
   ],
   "source": [
    "some_parts = sorted(PART_DIR.glob(\"created_day=*/requests.parquet\"))[:3]\n",
    "print(\"Checking partitions:\", len(some_parts))\n",
    "\n",
    "for p in some_parts:\n",
    "    x = pd.read_parquet(p)\n",
    "    check_nonempty(x, f\"readback:{p.parent.name}\")\n",
    "    check_required_columns(x, {\"unique_key\",\"created_date\",\"agency\",\"complaint_type_norm\",\"status\"}, f\"readback:{p.parent.name}\")\n",
    "    check_unique_key(x, \"unique_key\", f\"readback:{p.parent.name}\", allow_dupes=False)\n",
    "    print(\"OK:\", p.parent.name, \"rows:\", len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ef03a4-b5f2-46dc-948f-aebee6596e27",
   "metadata": {},
   "source": [
    "## 2D.5 - Pipeline Run Log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5475cf1a-8fc1-4664-86ec-7a2d8b4e6115",
   "metadata": {},
   "source": [
    "We log:  \n",
    "\n",
    "* input fingerprint\n",
    "* row counts before/after dedupe\n",
    "* partitions written\n",
    "* example output path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "705559f8-ef3a-4f26-b8fe-25b1492a831a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved run log: work/m2/data/reference/pipeline_runs/run_20260202_211848_utc.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'run_id': 'run_20260202_211848_utc',\n",
       " 'generated_at_utc': '2026-02-02T21:18:48.749545+00:00',\n",
       " 'row_definition': 'Each row is one 311 service request (unique_key).',\n",
       " 'inputs': {'csv_path': 'work/m2/data/raw/nyc311_last14d.csv',\n",
       "  'csv_fingerprint': 'e378ad4da4be2200'},\n",
       " 'checks': {'required_raw_cols': ['agency',\n",
       "   'complaint_type',\n",
       "   'created_date',\n",
       "   'status',\n",
       "   'unique_key'],\n",
       "  'dedupe_policy': 'keep most complete row per unique_key'},\n",
       " 'counts': {'raw_rows': 50000,\n",
       "  'staged_rows_after_dedupe': 50000,\n",
       "  'curated_rows': 50000,\n",
       "  'partitions_written': 4},\n",
       " 'outputs': {'partition_root': 'work/m2/data/warehouse/partitions',\n",
       "  'example_partition': 'work/m2/data/warehouse/partitions/created_day=2026-01-27/requests.parquet'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fp = fingerprint_file(CSV_PATH) if CSV_PATH.exists() else None\n",
    "\n",
    "run = {\n",
    "    \"run_id\": datetime.now(timezone.utc).strftime(\"run_%Y%m%d_%H%M%S_utc\"),\n",
    "    \"generated_at_utc\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"row_definition\": ROW_DEFINITION,\n",
    "    \"inputs\": {\n",
    "        \"csv_path\": str(CSV_PATH),\n",
    "        \"csv_fingerprint\": input_fp,\n",
    "    },\n",
    "    \"checks\": {\n",
    "        \"required_raw_cols\": sorted(REQUIRED_RAW_COLS),\n",
    "        \"dedupe_policy\": \"keep most complete row per unique_key\",\n",
    "    },\n",
    "    \"counts\": {\n",
    "        \"raw_rows\": int(len(df_raw)),\n",
    "        \"staged_rows_after_dedupe\": int(len(staged)),\n",
    "        \"curated_rows\": int(len(curated)),\n",
    "        \"partitions_written\": int(n_written),\n",
    "    },\n",
    "    \"outputs\": {\n",
    "        \"partition_root\": str(PART_DIR),\n",
    "        \"example_partition\": str(example_partition),\n",
    "    },\n",
    "}\n",
    "\n",
    "RUN_PATH = RUN_DIR / f\"{run['run_id']}.json\"\n",
    "RUN_PATH.write_text(json.dumps(run, indent=2))\n",
    "print(\"Saved run log:\", RUN_PATH)\n",
    "run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406a789f-3736-49c9-99ca-ecbe489ee8fa",
   "metadata": {},
   "source": [
    "## 2D.6 - ELT vs ETL: Interpret What Was Built"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a11e14-9a44-418c-8266-2e2e611ec227",
   "metadata": {},
   "source": [
    "We just implemented an ELT-style workflow:  \n",
    "* Extract + load raw CSV\n",
    "* Transform into staged / curated tables\n",
    "* Write curated, partitioned artifacts\n",
    "\n",
    "In notes explain:  \n",
    "* Why this is ELT and not ETL\n",
    "* What is the \"system of record\"\n",
    "* What contracts were enforced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "377c1a3f-a395-4eb3-bdc2-a14b5d8657df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elt_notes = []\n",
    "\n",
    "elt_notes.extend([\n",
    "    # \"This is ELT because we first load raw data as-is, then transform into staged/curated outputs.\",\n",
    "    # \"System of record: the raw CSV (raw folder) + run logs for reproducibility.\",\n",
    "    # \"Contracts: required columns, unique_key uniqueness after staging, partition read-back checks.\",\n",
    "])\n",
    "\n",
    "elt_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ceac5-26a0-441e-a7ef-4c107813b773",
   "metadata": {},
   "source": [
    "## 2D.7 - Polars Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da8f8668-8c64-42ab-ba4b-934fb23b0f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading partitions: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10, 3)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>agency</th><th>n_requests</th><th>closed_rate</th></tr><tr><td>str</td><td>u32</td><td>f64</td></tr></thead><tbody><tr><td>&quot;HPD&quot;</td><td>18618</td><td>0.239446</td></tr><tr><td>&quot;DSNY&quot;</td><td>13160</td><td>0.060334</td></tr><tr><td>&quot;NYPD&quot;</td><td>11651</td><td>0.98189</td></tr><tr><td>&quot;DOT&quot;</td><td>1980</td><td>0.381313</td></tr><tr><td>&quot;DEP&quot;</td><td>1339</td><td>0.530993</td></tr><tr><td>&quot;DOB&quot;</td><td>766</td><td>0.191906</td></tr><tr><td>&quot;DOHMH&quot;</td><td>624</td><td>0.200321</td></tr><tr><td>&quot;DHS&quot;</td><td>613</td><td>0.37031</td></tr><tr><td>&quot;DPR&quot;</td><td>531</td><td>0.190207</td></tr><tr><td>&quot;TLC&quot;</td><td>246</td><td>0.117886</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10, 3)\n",
       "\n",
       " agency  n_requests  closed_rate \n",
       " ---     ---         ---         \n",
       " str     u32         f64         \n",
       "\n",
       " HPD     18618       0.239446    \n",
       " DSNY    13160       0.060334    \n",
       " NYPD    11651       0.98189     \n",
       " DOT     1980        0.381313    \n",
       " DEP     1339        0.530993    \n",
       " DOB     766         0.191906    \n",
       " DOHMH   624         0.200321    \n",
       " DHS     613         0.37031     \n",
       " DPR     531         0.190207    \n",
       " TLC     246         0.117886    \n",
       ""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "from pathlib import Path\n",
    "\n",
    "# Read a small number of partitions to keep this fast\n",
    "PART_DIR = Path(\"work\") / \"m2\" / \"data\" / \"warehouse\" / \"partitions\"\n",
    "paths = [str(p) for p in sorted(PART_DIR.glob(\"created_day=*/requests.parquet\"))[:10]]\n",
    "\n",
    "print(\"Reading partitions:\", len(paths))\n",
    "\n",
    "# Lazy scan of Parquet partitions\n",
    "lf = pl.scan_parquet(paths)\n",
    "\n",
    "# Groupby aggregation (lazy  optimized  executed)\n",
    "agency_summary = (\n",
    "    lf.group_by(\"agency\")\n",
    "      .agg([\n",
    "          pl.len().alias(\"n_requests\"),          \n",
    "          pl.mean(\"is_closed\").alias(\"closed_rate\"),\n",
    "      ])\n",
    "      .sort(\"n_requests\", descending=True)\n",
    "      .collect()\n",
    ")\n",
    "\n",
    "agency_summary.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b718e0-e385-4452-a616-ce3496c23147",
   "metadata": {},
   "source": [
    "## 2D.8 - Quick Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cefae86-fb66-4c1b-8695-3fd2d295079b",
   "metadata": {},
   "source": [
    "We should now have the core pieces of a scaled workflow:  \n",
    "* input contracts + fail-fast checks\n",
    "* staged + curated layers\n",
    "* partitioned Parquet outputs\n",
    "* run logging for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b357ec-35dd-4ba0-b16f-cea91fd9a821",
   "metadata": {},
   "source": [
    "# Module 2.E - Outliers & Validation (NYC 311)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cc0460-d71c-4103-a6ad-48dc16a0e67d",
   "metadata": {},
   "source": [
    "This notebook builds on **2.A - 2.D**  \n",
    "\n",
    "You will:\n",
    "\n",
    "1. Load the request-level feature table created in **2.C** (or rebuild from 2.D partitions if needed)\n",
    "2. Detect anomalies (outliers that violate expectations)\n",
    "3. Write validation checks (contracts/tests you can run every pipeline execution)\n",
    "4. Do a leakage audit: identify fields/transforms that can leak future information\n",
    "5. Export a reusable `validation_report.json`\n",
    "\n",
    "**Principle:** Prefer flags and tests over deleting data. Make assumptions explicit and enforcable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c0dfec-d3b0-4de5-8b85-7f1d43fd1f9b",
   "metadata": {},
   "source": [
    "## 2E.0 - Setup and Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a88b03e-74b2-4d61-998f-c2fa3b9f9c88",
   "metadata": {},
   "source": [
    "Expected artifacts from prior sections:  \n",
    "* Raw CSV (**2.A**): `/work/m2/data/raw/nyc311_last14d.csv`\n",
    "* Quality report (**2.B**): `/work/m2/data/reference/quality_report.json`\n",
    "* Feature table (**2.C**): `/work/m2/data/warehouse/nyc311_requests_features.parquet`\n",
    "* Partitioned curated outputs (**2.D**): `/work/m2/data/warehouse/partitions/created_day=YYYY-MM-DD/requests.parquet`\n",
    "\n",
    "We will write:  \n",
    "* `/work/m2/data/reference/validation_report.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7dab44f-2c86-4e32-91e1-0aa0249fa3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV: work/m2/data/raw/nyc311_last14d.csv | exists? True\n",
      "Quality report: work/m2/data/reference/quality_report.json | exists? True\n",
      "Features: work/m2/data/warehouse/nyc311_requests_features.parquet | exists? True\n",
      "Partitions: work/m2/data/warehouse/partitions | exists? True\n",
      "Will write: work/m2/data/reference/validation_report.json\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 140)\n",
    "pd.set_option(\"display.width\", 160)\n",
    "\n",
    "WORK_DIR   = Path(\"work\")\n",
    "MODULE_DIR = WORK_DIR / \"m2\"\n",
    "DATA_DIR = MODULE_DIR / \"data\"\n",
    "\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "REF_DIR = DATA_DIR / \"reference\"\n",
    "WH_DIR  = DATA_DIR / \"warehouse\"\n",
    "\n",
    "CSV_PATH = RAW_DIR / \"nyc311_last14d.csv\"\n",
    "QUALITY_PATH = REF_DIR / \"quality_report.json\"\n",
    "FEATURES_PATH = WH_DIR / \"nyc311_requests_features.parquet\"\n",
    "PART_DIR = WH_DIR / \"partitions\"\n",
    "\n",
    "VALIDATION_PATH = REF_DIR / \"validation_report.json\"\n",
    "\n",
    "print(\"CSV:\", CSV_PATH, \"| exists?\", CSV_PATH.exists())\n",
    "print(\"Quality report:\", QUALITY_PATH, \"| exists?\", QUALITY_PATH.exists())\n",
    "print(\"Features:\", FEATURES_PATH, \"| exists?\", FEATURES_PATH.exists())\n",
    "print(\"Partitions:\", PART_DIR, \"| exists?\", PART_DIR.exists())\n",
    "print(\"Will write:\", VALIDATION_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f562b253-f95f-4320-92a5-e535b1a8d985",
   "metadata": {},
   "source": [
    "## 2E.1 - Load Request-Level Features (Preferred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654a8345-16ca-4f80-b34e-9f18b49907a4",
   "metadata": {},
   "source": [
    "If `nyc311_requests_features.parquet` exists (from 2.C), we use it. Otherwise, we fall back to the curated partitions from 2.D and concatenate them.  \n",
    "\n",
    "This module is robust to either artifact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cff1f92-99e6-499c-84b9-a4cadedd5950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: 2.C_features_parquet\n",
      "Shape: (50000, 24)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>created_day</th>\n",
       "      <th>created_hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>agency</th>\n",
       "      <th>borough_norm</th>\n",
       "      <th>complaint_topk</th>\n",
       "      <th>zip_missing</th>\n",
       "      <th>kw_noise</th>\n",
       "      <th>kw_rodent</th>\n",
       "      <th>kw_water</th>\n",
       "      <th>street_number</th>\n",
       "      <th>n_requests</th>\n",
       "      <th>closed_rate</th>\n",
       "      <th>median_resolution_hours</th>\n",
       "      <th>agency_n_requests</th>\n",
       "      <th>agency_closed_rate</th>\n",
       "      <th>agency_median_resolution</th>\n",
       "      <th>status</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>resolution_hours</th>\n",
       "      <th>_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30 01:51:21</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>280</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.480972</td>\n",
       "      <td>11651</td>\n",
       "      <td>0.981890</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.C_features_parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30 01:51:04</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>DOE</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>911</td>\n",
       "      <td>280</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.480972</td>\n",
       "      <td>144</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>7.605000</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.C_features_parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30 01:50:53</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>noise - residential</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>936</td>\n",
       "      <td>280</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.480972</td>\n",
       "      <td>11651</td>\n",
       "      <td>0.981890</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.C_features_parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67707975</td>\n",
       "      <td>2026-01-30 01:50:52</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>noise - residential</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>280</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.480972</td>\n",
       "      <td>11651</td>\n",
       "      <td>0.981890</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.C_features_parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67771794</td>\n",
       "      <td>2026-01-30 01:50:32</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>TLC</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>280</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.480972</td>\n",
       "      <td>246</td>\n",
       "      <td>0.117886</td>\n",
       "      <td>16.582778</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.C_features_parquet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key        created_date created_day  created_hour  dayofweek  is_weekend agency   borough_norm       complaint_topk  zip_missing  kw_noise  \\\n",
       "0    67720523 2026-01-30 01:51:21  2026-01-30             1          4           0   NYPD           <NA>                other            1         1   \n",
       "1    67746090 2026-01-30 01:51:04  2026-01-30             1          4           0    DOE       BROOKLYN                other            0         0   \n",
       "2    67758820 2026-01-30 01:50:53  2026-01-30             1          4           0   NYPD      MANHATTAN  noise - residential            0         1   \n",
       "3    67707975 2026-01-30 01:50:52  2026-01-30             1          4           0   NYPD  STATEN ISLAND  noise - residential            0         1   \n",
       "4    67771794 2026-01-30 01:50:32  2026-01-30             1          4           0    TLC         QUEENS                other            0         0   \n",
       "\n",
       "   kw_rodent  kw_water  street_number  n_requests  closed_rate  median_resolution_hours  agency_n_requests  agency_closed_rate  agency_median_resolution  \\\n",
       "0          0         0           <NA>         280     0.435714                 0.480972              11651            0.981890                  1.277778   \n",
       "1          0         0            911         280     0.435714                 0.480972                144            0.520833                  7.605000   \n",
       "2          0         0            936         280     0.435714                 0.480972              11651            0.981890                  1.277778   \n",
       "3          0         0            190         280     0.435714                 0.480972              11651            0.981890                  1.277778   \n",
       "4          0         0           <NA>         280     0.435714                 0.480972                246            0.117886                 16.582778   \n",
       "\n",
       "        status  is_closed  resolution_hours               _source  \n",
       "0  Unspecified          0               NaN  2.C_features_parquet  \n",
       "1  In Progress          0               NaN  2.C_features_parquet  \n",
       "2  In Progress          0               NaN  2.C_features_parquet  \n",
       "3  In Progress          0               NaN  2.C_features_parquet  \n",
       "4  In Progress          0               NaN  2.C_features_parquet  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_features() -> pd.DataFrame:\n",
    "    if FEATURES_PATH.exists():\n",
    "        df = pd.read_parquet(FEATURES_PATH)\n",
    "        df[\"_source\"] = \"2.C_features_parquet\"\n",
    "        return df\n",
    "\n",
    "    if PART_DIR.exists():\n",
    "        parts = sorted(PART_DIR.glob(\"created_day=*/requests.parquet\"))\n",
    "        if not parts:\n",
    "            raise FileNotFoundError(\"No partitions found in warehouse/partitions/\")\n",
    "        df = pd.concat([pd.read_parquet(p) for p in parts], ignore_index=True)\n",
    "        df[\"_source\"] = \"2.D_partitioned_curated\"\n",
    "        return df\n",
    "\n",
    "    raise FileNotFoundError(\"No features parquet and no partitions found. Run 2.C or 2.D first.\")\n",
    "\n",
    "df = load_features()\n",
    "print(\"Loaded:\", df[\"_source\"].iloc[0])\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ce321e-09db-4515-8063-554cfa854924",
   "metadata": {},
   "source": [
    "**Normalize a few types**  \n",
    "\n",
    "Artifacts differ slightly across 2.C vs 2.D. Normalize the most important fields:\n",
    "* timestamps\n",
    "* `created_day`\n",
    "* `status`\n",
    "* `is_closed`\n",
    "* `resolution_hours`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22326b05-e257-49a7-89da-5ea09380cd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready. Example columns present: ['unique_key', 'created_date', 'created_day', 'agency', 'status', 'is_closed', 'resolution_hours']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>created_day</th>\n",
       "      <th>created_hour</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>agency</th>\n",
       "      <th>borough_norm</th>\n",
       "      <th>complaint_topk</th>\n",
       "      <th>zip_missing</th>\n",
       "      <th>kw_noise</th>\n",
       "      <th>kw_rodent</th>\n",
       "      <th>kw_water</th>\n",
       "      <th>street_number</th>\n",
       "      <th>n_requests</th>\n",
       "      <th>closed_rate</th>\n",
       "      <th>median_resolution_hours</th>\n",
       "      <th>agency_n_requests</th>\n",
       "      <th>agency_closed_rate</th>\n",
       "      <th>agency_median_resolution</th>\n",
       "      <th>status</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>resolution_hours</th>\n",
       "      <th>_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30 01:51:21</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>280</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.480972</td>\n",
       "      <td>11651</td>\n",
       "      <td>0.981890</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.C_features_parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30 01:51:04</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>DOE</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>other</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>911</td>\n",
       "      <td>280</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.480972</td>\n",
       "      <td>144</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>7.605000</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.C_features_parquet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30 01:50:53</td>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>noise - residential</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>936</td>\n",
       "      <td>280</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.480972</td>\n",
       "      <td>11651</td>\n",
       "      <td>0.981890</td>\n",
       "      <td>1.277778</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.C_features_parquet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key        created_date created_day  created_hour  dayofweek  is_weekend agency borough_norm       complaint_topk  zip_missing  kw_noise  kw_rodent  \\\n",
       "0    67720523 2026-01-30 01:51:21  2026-01-30             1          4           0   NYPD         <NA>                other            1         1          0   \n",
       "1    67746090 2026-01-30 01:51:04  2026-01-30             1          4           0    DOE     BROOKLYN                other            0         0          0   \n",
       "2    67758820 2026-01-30 01:50:53  2026-01-30             1          4           0   NYPD    MANHATTAN  noise - residential            0         1          0   \n",
       "\n",
       "   kw_water  street_number  n_requests  closed_rate  median_resolution_hours  agency_n_requests  agency_closed_rate  agency_median_resolution       status  \\\n",
       "0         0           <NA>         280     0.435714                 0.480972              11651            0.981890                  1.277778  Unspecified   \n",
       "1         0            911         280     0.435714                 0.480972                144            0.520833                  7.605000  In Progress   \n",
       "2         0            936         280     0.435714                 0.480972              11651            0.981890                  1.277778  In Progress   \n",
       "\n",
       "   is_closed  resolution_hours               _source  \n",
       "0          0               NaN  2.C_features_parquet  \n",
       "1          0               NaN  2.C_features_parquet  \n",
       "2          0               NaN  2.C_features_parquet  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "if \"created_date\" in df2.columns and not np.issubdtype(df2[\"created_date\"].dtype, np.datetime64):\n",
    "    df2[\"created_date\"] = pd.to_datetime(df2[\"created_date\"], errors=\"coerce\")\n",
    "\n",
    "if \"created_day\" in df2.columns:\n",
    "    if df2[\"created_day\"].dtype == \"object\":\n",
    "        df2[\"created_day\"] = pd.to_datetime(df2[\"created_day\"], errors=\"coerce\").dt.date\n",
    "else:\n",
    "    if \"created_date\" in df2.columns:\n",
    "        df2[\"created_day\"] = df2[\"created_date\"].dt.date\n",
    "\n",
    "if \"status\" in df2.columns:\n",
    "    df2[\"status\"] = df2[\"status\"].astype(\"string\").str.strip().str.title()\n",
    "\n",
    "if \"is_closed\" not in df2.columns and \"status\" in df2.columns:\n",
    "    df2[\"is_closed\"] = (df2[\"status\"] == \"Closed\").astype(int)\n",
    "\n",
    "if \"resolution_hours\" in df2.columns:\n",
    "    df2[\"resolution_hours\"] = pd.to_numeric(df2[\"resolution_hours\"], errors=\"coerce\")\n",
    "\n",
    "print(\"Ready. Example columns present:\", [c for c in [\"unique_key\",\"created_date\",\"created_day\",\"agency\",\"status\",\"is_closed\",\"resolution_hours\"] if c in df2.columns])\n",
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc725fc2-2d0f-4005-95ab-a93c01395fb2",
   "metadata": {},
   "source": [
    "## 2E.2 - Anomaly Detection: Build Flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2550fc2-f83d-4c6a-ad2f-04353ee5950f",
   "metadata": {},
   "source": [
    "Outliers are not \"bad rows\" by default  \n",
    "\n",
    "We flag anomalies using explicit expectations:  \n",
    "* duplicate keys (should be unique at request level)\n",
    "* missing future timestamps\n",
    "* negative or extremely long durations\n",
    "* closed but missing duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69a736b4-2d43-4376-a3c0-cb8c7b7370ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "anom_negative_duration          0.00004\n",
       "anom_any                        0.00004\n",
       "anom_created_missing            0.00000\n",
       "anom_duplicate_unique_key       0.00000\n",
       "anom_created_in_future          0.00000\n",
       "anom_over_30d                   0.00000\n",
       "anom_over_7d                    0.00000\n",
       "anom_closed_missing_duration    0.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flags = pd.DataFrame(index=df2.index)\n",
    "\n",
    "# Duplicate key flag\n",
    "if \"unique_key\" in df2.columns:\n",
    "    flags[\"anom_duplicate_unique_key\"] = df2[\"unique_key\"].duplicated().astype(int)\n",
    "else:\n",
    "    flags[\"anom_duplicate_unique_key\"] = 0\n",
    "\n",
    "# Timestamp flags\n",
    "# Robust \"future\" check that handles tz-naive vs tz-aware timestamps\n",
    "if \"created_date\" in df2.columns:\n",
    "    cd = pd.to_datetime(df2[\"created_date\"], errors=\"coerce\")\n",
    "\n",
    "    flags[\"anom_created_missing\"] = cd.isna().astype(int)\n",
    "\n",
    "    # Compare to \"now\" with matching tz-awareness\n",
    "    if getattr(cd.dt, \"tz\", None) is None:\n",
    "        now = pd.Timestamp.now()  # tz-naive\n",
    "    else:\n",
    "        now = pd.Timestamp.now(tz=cd.dt.tz)  # tz-aware, matching cd\n",
    "\n",
    "    flags[\"anom_created_in_future\"] = (cd > now).astype(int)\n",
    "else:\n",
    "    flags[\"anom_created_missing\"] = 1\n",
    "    flags[\"anom_created_in_future\"] = 0\n",
    "\n",
    "# Duration flags (if present)\n",
    "if \"resolution_hours\" in df2.columns:\n",
    "    flags[\"anom_negative_duration\"] = (df2[\"resolution_hours\"] < 0).astype(int)\n",
    "    flags[\"anom_over_30d\"] = (df2[\"resolution_hours\"] > 30*24).astype(int)\n",
    "    flags[\"anom_over_7d\"] = (df2[\"resolution_hours\"] > 7*24).astype(int)\n",
    "else:\n",
    "    flags[\"anom_negative_duration\"] = 0\n",
    "    flags[\"anom_over_30d\"] = 0\n",
    "    flags[\"anom_over_7d\"] = 0\n",
    "\n",
    "# Consistency: closed but missing duration (when duration exists)\n",
    "if \"is_closed\" in df2.columns and \"resolution_hours\" in df2.columns:\n",
    "    flags[\"anom_closed_missing_duration\"] = ((df2[\"is_closed\"] == 1) & (df2[\"resolution_hours\"].isna())).astype(int)\n",
    "else:\n",
    "    flags[\"anom_closed_missing_duration\"] = 0\n",
    "\n",
    "flags[\"anom_any\"] = (flags.sum(axis=1) > 0).astype(int)\n",
    "\n",
    "anom_rate = flags.mean().sort_values(ascending=False)\n",
    "anom_rate.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9901faa-2619-471c-9a1c-b23d972d7ff2",
   "metadata": {},
   "source": [
    "**Investigation table (what to inspect next)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fd336e4-0c65-4140-a47b-cb69951dd391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suspicious rows: 2 out of 50000 (0.00%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>created_day</th>\n",
       "      <th>agency</th>\n",
       "      <th>status</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>resolution_hours</th>\n",
       "      <th>anom_any</th>\n",
       "      <th>anom_duplicate_unique_key</th>\n",
       "      <th>anom_created_missing</th>\n",
       "      <th>anom_created_in_future</th>\n",
       "      <th>anom_negative_duration</th>\n",
       "      <th>anom_over_30d</th>\n",
       "      <th>anom_over_7d</th>\n",
       "      <th>anom_closed_missing_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27005</th>\n",
       "      <td>67655113</td>\n",
       "      <td>2026-01-28 10:20:00</td>\n",
       "      <td>2026-01-28</td>\n",
       "      <td>DOT</td>\n",
       "      <td>Pending</td>\n",
       "      <td>0</td>\n",
       "      <td>-24.016667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46061</th>\n",
       "      <td>67648428</td>\n",
       "      <td>2026-01-27 10:12:00</td>\n",
       "      <td>2026-01-27</td>\n",
       "      <td>DOT</td>\n",
       "      <td>Pending</td>\n",
       "      <td>0</td>\n",
       "      <td>-96.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       unique_key        created_date created_day agency   status  is_closed  resolution_hours  anom_any  anom_duplicate_unique_key  anom_created_missing  \\\n",
       "27005    67655113 2026-01-28 10:20:00  2026-01-28    DOT  Pending          0        -24.016667         1                          0                     0   \n",
       "46061    67648428 2026-01-27 10:12:00  2026-01-27    DOT  Pending          0        -96.000000         1                          0                     0   \n",
       "\n",
       "       anom_created_in_future  anom_negative_duration  anom_over_30d  anom_over_7d  anom_closed_missing_duration  \n",
       "27005                       0                       1              0             0                             0  \n",
       "46061                       0                       1              0             0                             0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_for_view = [c for c in [\"unique_key\",\"created_date\",\"created_day\",\"agency\",\"status\",\"is_closed\",\"resolution_hours\"] if c in df2.columns]\n",
    "anom_cols = [c for c in flags.columns if c.startswith(\"anom_\") and c != \"anom_any\"]\n",
    "\n",
    "investigation = pd.concat([df2[cols_for_view], flags[[\"anom_any\"] + anom_cols]], axis=1)\n",
    "suspects = investigation.loc[investigation[\"anom_any\"] == 1].copy()\n",
    "\n",
    "print(\"Suspicious rows:\", len(suspects), \"out of\", len(df2), f\"({len(suspects)/max(1,len(df2)):.2%})\")\n",
    "suspects.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7e1616-8296-413a-84ee-fd5cc33f1c0e",
   "metadata": {},
   "source": [
    "## 2E.3 - Distribution Checks: Cheap Drift Signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8021dd74-246d-45dc-90a9-6dacc437305a",
   "metadata": {},
   "source": [
    "We compute a few \"canary\" summaries that can highlight drift:  \n",
    "* requests per day\n",
    "* top agencies\n",
    "* top complaint categories (top-k or normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72e7b1ca-1d10-4a16-a7d2-81b752501912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_day</th>\n",
       "      <th>n_requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-27</td>\n",
       "      <td>17529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-28</td>\n",
       "      <td>16913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-29</td>\n",
       "      <td>15278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  created_day  n_requests\n",
       "0  2026-01-27       17529\n",
       "1  2026-01-28       16913\n",
       "2  2026-01-29       15278\n",
       "3  2026-01-30         280"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>agency</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HPD</td>\n",
       "      <td>18618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DSNY</td>\n",
       "      <td>13160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NYPD</td>\n",
       "      <td>11651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DOT</td>\n",
       "      <td>1980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEP</td>\n",
       "      <td>1339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DOB</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DOHMH</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DHS</td>\n",
       "      <td>613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DPR</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TLC</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DOE</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DCWP</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>EDC</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OOS</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OTI</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   agency      n\n",
       "0     HPD  18618\n",
       "1    DSNY  13160\n",
       "2    NYPD  11651\n",
       "3     DOT   1980\n",
       "4     DEP   1339\n",
       "5     DOB    766\n",
       "6   DOHMH    624\n",
       "7     DHS    613\n",
       "8     DPR    531\n",
       "9     TLC    246\n",
       "10    DOE    144\n",
       "11   DCWP    141\n",
       "12    EDC    126\n",
       "13    OOS     56\n",
       "14    OTI      5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_topk</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>snow or ice</td>\n",
       "      <td>12376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>heat/hot water</td>\n",
       "      <td>11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>other</td>\n",
       "      <td>7902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>illegal parking</td>\n",
       "      <td>4922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blocked driveway</td>\n",
       "      <td>2790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>noise - residential</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unsanitary condition</td>\n",
       "      <td>1288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>plumbing</td>\n",
       "      <td>1258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>paint/plaster</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>door/window</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>water leak</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>traffic signal condition</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>water system</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>homeless person assistance</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>general</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                complaint_topk      n\n",
       "0                  snow or ice  12376\n",
       "1               heat/hot water  11890\n",
       "2                        other   7902\n",
       "3              illegal parking   4922\n",
       "4             blocked driveway   2790\n",
       "5          noise - residential   2492\n",
       "6         unsanitary condition   1288\n",
       "7                     plumbing   1258\n",
       "8                paint/plaster    819\n",
       "9                  door/window    773\n",
       "10                  water leak    750\n",
       "11    traffic signal condition    722\n",
       "12                water system    549\n",
       "13  homeless person assistance    530\n",
       "14                     general    474"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summaries = {}\n",
    "\n",
    "if \"created_day\" in df2.columns:\n",
    "    by_day = df2.groupby(\"created_day\").size().rename(\"n_requests\").reset_index()\n",
    "    summaries[\"by_day\"] = by_day\n",
    "    display(by_day.tail(10))\n",
    "\n",
    "if \"agency\" in df2.columns:\n",
    "    by_agency = df2[\"agency\"].astype(\"string\").value_counts(dropna=False).head(15).rename_axis(\"agency\").reset_index(name=\"n\")\n",
    "    summaries[\"by_agency_top\"] = by_agency\n",
    "    display(by_agency)\n",
    "\n",
    "cat_col = None\n",
    "for candidate in [\"complaint_topk\", \"complaint_type_norm\", \"complaint_type\"]:\n",
    "    if candidate in df2.columns:\n",
    "        cat_col = candidate\n",
    "        break\n",
    "\n",
    "if cat_col:\n",
    "    by_cat = df2[cat_col].astype(\"string\").value_counts(dropna=False).head(15).rename_axis(cat_col).reset_index(name=\"n\")\n",
    "    summaries[\"by_category_top\"] = by_cat\n",
    "    display(by_cat)\n",
    "else:\n",
    "    print(\"No complaint category column found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47293abf-b1e1-4129-afd2-f26e7e56495d",
   "metadata": {},
   "source": [
    "**Simple spike detection (rule-based)**  \n",
    "\n",
    "Flag days where request count is unusually high relative to median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2831c75-08f3-4274-a195-b0fe205601b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median day requests: 16095.5\n",
      "Spike days: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_day</th>\n",
       "      <th>n_requests</th>\n",
       "      <th>is_spike</th>\n",
       "      <th>median_day_requests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [created_day, n_requests, is_spike, median_day_requests]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spike_report = None\n",
    "\n",
    "if \"created_day\" in df2.columns:\n",
    "    by_day = df2.groupby(\"created_day\").size().rename(\"n_requests\").reset_index()\n",
    "    med = float(by_day[\"n_requests\"].median()) if len(by_day) else 0.0\n",
    "    by_day[\"is_spike\"] = (by_day[\"n_requests\"] > 2.5 * med).astype(int)\n",
    "    by_day[\"median_day_requests\"] = med\n",
    "    spike_report = by_day.loc[by_day[\"is_spike\"] == 1].copy()\n",
    "\n",
    "    print(\"Median day requests:\", med)\n",
    "    print(\"Spike days:\", len(spike_report))\n",
    "    display(spike_report)\n",
    "else:\n",
    "    print(\"No created_day available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce1037f-ef23-4d3f-9161-25db3dac704d",
   "metadata": {},
   "source": [
    "## 2E.4 - Validation Checks: Fail-Fast Contracts (Report-First)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0dd5d3-0ccf-4d97-9d2d-40f1457c5c90",
   "metadata": {},
   "source": [
    "A scalable pipeline should run a small set of checks on every run. We create a report that can either:  \n",
    "* be used in dev (raise on failure), or\n",
    "* be used in production (alert/stop/quarantine)\n",
    "\n",
    "Checks:\n",
    "* required columns\n",
    "* uniqueness\n",
    "* timestamp validity\n",
    "* duration plausibility (if present)\n",
    "* missingness guardrails for key fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "36299540-2116-4945-82ad-1bf0cd42fc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation passed? False\n"
     ]
    }
   ],
   "source": [
    "def run_validations(df_in: pd.DataFrame) -> dict:\n",
    "    results = {\"passed\": True, \"checks\": []}\n",
    "\n",
    "    def record(name: str, passed: bool, details: dict):\n",
    "        results[\"checks\"].append(\n",
    "            {\"name\": name, \"passed\": bool(passed), \"details\": details}\n",
    "        )\n",
    "        if not passed:\n",
    "            results[\"passed\"] = False\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Required columns\n",
    "    # --------------------------------------------------\n",
    "    required = [\"unique_key\", \"created_date\", \"agency\"]\n",
    "    missing_required = [c for c in required if c not in df_in.columns]\n",
    "    record(\n",
    "        \"required_columns\",\n",
    "        passed=(len(missing_required) == 0),\n",
    "        details={\"required\": required, \"missing\": missing_required},\n",
    "    )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Uniqueness\n",
    "    # --------------------------------------------------\n",
    "    if \"unique_key\" in df_in.columns:\n",
    "        dupes = int(df_in[\"unique_key\"].duplicated().sum())\n",
    "        record(\n",
    "            \"unique_key_unique\",\n",
    "            passed=(dupes == 0),\n",
    "            details={\"duplicate_count\": dupes},\n",
    "        )\n",
    "    else:\n",
    "        record(\n",
    "            \"unique_key_unique\",\n",
    "            passed=False,\n",
    "            details={\"error\": \"unique_key not present\"},\n",
    "        )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # created_date checks\n",
    "    # --------------------------------------------------\n",
    "    if \"created_date\" in df_in.columns:\n",
    "        cd = pd.to_datetime(df_in[\"created_date\"], errors=\"coerce\")\n",
    "\n",
    "        missing_rate = float(cd.isna().mean())\n",
    "        record(\n",
    "            \"created_date_missing_rate\",\n",
    "            passed=(missing_rate < 0.01),\n",
    "            details={\"missing_rate\": missing_rate, \"threshold\": 0.01},\n",
    "        )\n",
    "\n",
    "        # Match timezone awareness\n",
    "        if getattr(cd.dt, \"tz\", None) is None:\n",
    "            now = pd.Timestamp.now()\n",
    "        else:\n",
    "            now = pd.Timestamp.now(tz=cd.dt.tz)\n",
    "\n",
    "        future = int((cd > now).sum())\n",
    "        record(\n",
    "            \"created_date_future_count\",\n",
    "            passed=(future == 0),\n",
    "            details={\"future_count\": future},\n",
    "        )\n",
    "    else:\n",
    "        record(\n",
    "            \"created_date_missing_rate\",\n",
    "            passed=False,\n",
    "            details={\"error\": \"created_date not present\"},\n",
    "        )\n",
    "        record(\n",
    "            \"created_date_future_count\",\n",
    "            passed=False,\n",
    "            details={\"error\": \"created_date not present\"},\n",
    "        )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Duration plausibility (optional)\n",
    "    # --------------------------------------------------\n",
    "    if \"resolution_hours\" in df_in.columns:\n",
    "        rh = pd.to_numeric(df_in[\"resolution_hours\"], errors=\"coerce\")\n",
    "\n",
    "        neg = int((rh < 0).sum())\n",
    "        record(\n",
    "            \"resolution_negative_count\",\n",
    "            passed=(neg == 0),\n",
    "            details={\"negative_count\": neg},\n",
    "        )\n",
    "\n",
    "        over_30d = int((rh > 30 * 24).sum())\n",
    "        record(\n",
    "            \"resolution_over_30d_count\",\n",
    "            passed=(over_30d == 0),\n",
    "            details={\"over_30d_count\": over_30d},\n",
    "        )\n",
    "    else:\n",
    "        record(\n",
    "            \"resolution_checks_skipped\",\n",
    "            passed=True,\n",
    "            details={\"note\": \"resolution_hours not present\"},\n",
    "        )\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # Missingness guardrails (high-value fields)\n",
    "    # --------------------------------------------------\n",
    "    for col, thresh in [\n",
    "        (\"agency\", 0.02),\n",
    "        (\"status\", 0.02),\n",
    "        (\"complaint_topk\", 0.10),\n",
    "        (\"complaint_type_norm\", 0.10),\n",
    "    ]:\n",
    "        if col in df_in.columns:\n",
    "            miss = float(df_in[col].isna().mean())\n",
    "            record(\n",
    "                f\"missing_rate:{col}\",\n",
    "                passed=(miss <= thresh),\n",
    "                details={\"missing_rate\": miss, \"threshold\": thresh},\n",
    "            )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "validation = run_validations(df2)\n",
    "print(\"Validation passed?\", validation[\"passed\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5507d225-b34c-4a0a-b866-77e12a6e384e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failures: 1\n",
      "- resolution_negative_count {'negative_count': 2}\n"
     ]
    }
   ],
   "source": [
    "fails = [c for c in validation[\"checks\"] if not c[\"passed\"]]\n",
    "print(\"Failures:\", len(fails))\n",
    "for f in fails:\n",
    "    print(\"-\", f[\"name\"], f[\"details\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7f5e6d-3923-40f7-8651-70d9f6262d88",
   "metadata": {},
   "source": [
    "## 2E.5 - Leakage Audit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e555905f-a1b9-4d6d-8d86-4dee42100363",
   "metadata": {},
   "source": [
    "Leakage is any information your model would not have at prediction time.  \n",
    "\n",
    "We generate:  \n",
    "* a list of risky columns present\n",
    "* a checklist you can use during feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae013613-de06-4f1f-84ca-391113a0e92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risky columns present: ['resolution_hours', 'status']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'present_risky_columns': {'resolution_hours': 'Derived from closed_date; not safe as an input feature for closure-related prediction tasks.',\n",
       "  'status': 'Often a label/outcome; may leak if used as an input feature for certain tasks.'},\n",
       " 'checklist': ['Any preprocessing stats (means/encoders/top-k) computed on TRAIN only?',\n",
       "  'Any joins pulling in future updates (time-insensitive joins)?',\n",
       "  'Any imputation using target-dependent information?',\n",
       "  'Any outcome-derived fields included as features?',\n",
       "  'Is row meaning tied to a timestamp (prediction time)?'],\n",
       " 'notes': [\"If modeling 'is_closed' or 'resolution_hours', treat resolution_hours (and closed timestamps) as labels/targets, not inputs.\",\n",
       "  'In later modules, fit encoders/imputers on TRAIN only (Pipeline/ColumnTransformer).']}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LEAKAGE_RISK_COLS = {\n",
    "    \"closed_date\": \"Outcome timestamp: only known after resolution.\",\n",
    "    \"resolution_hours\": \"Derived from closed_date; not safe as an input feature for closure-related prediction tasks.\",\n",
    "    \"status\": \"Often a label/outcome; may leak if used as an input feature for certain tasks.\",\n",
    "}\n",
    "\n",
    "present_risks = {c: LEAKAGE_RISK_COLS[c] for c in LEAKAGE_RISK_COLS if c in df2.columns}\n",
    "\n",
    "leakage_audit = {\n",
    "    \"present_risky_columns\": present_risks,\n",
    "    \"checklist\": [\n",
    "        \"Any preprocessing stats (means/encoders/top-k) computed on TRAIN only?\",\n",
    "        \"Any joins pulling in future updates (time-insensitive joins)?\",\n",
    "        \"Any imputation using target-dependent information?\",\n",
    "        \"Any outcome-derived fields included as features?\",\n",
    "        \"Is row meaning tied to a timestamp (prediction time)?\",\n",
    "    ],\n",
    "    \"notes\": [\n",
    "        \"If modeling 'is_closed' or 'resolution_hours', treat resolution_hours (and closed timestamps) as labels/targets, not inputs.\",\n",
    "        \"In later modules, fit encoders/imputers on TRAIN only (Pipeline/ColumnTransformer).\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(\"Risky columns present:\", list(present_risks.keys()))\n",
    "leakage_audit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e8db6d-cd25-479b-9ca9-e56b50b08df6",
   "metadata": {},
   "source": [
    "## 2E.6 - Write `validation_report.json`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eece4869-872f-4896-ae88-64f6ec6ed907",
   "metadata": {},
   "source": [
    "This is the artifact that can saved on every pipeline run and compare over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65ef9486-bdc1-411a-a205-d125eeef0fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: work/m2/data/reference/validation_report.json\n"
     ]
    }
   ],
   "source": [
    "report = {\n",
    "    \"generated_at_utc\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"data_source\": str(df[\"_source\"].iloc[0]) if \"_source\" in df.columns else \"unknown\",\n",
    "    \"n_rows\": int(len(df2)),\n",
    "    \"n_cols\": int(df2.shape[1]),\n",
    "    \"anomaly_rates\": flags.mean().sort_values(ascending=False).to_dict(),\n",
    "    \"n_suspicious_rows\": int(flags[\"anom_any\"].sum()),\n",
    "    \"validation\": validation,\n",
    "    \"leakage_audit\": leakage_audit,\n",
    "    \"distribution_canaries\": {},\n",
    "}\n",
    "\n",
    "if \"created_day\" in df2.columns:\n",
    "    by_day = df2.groupby(\"created_day\").size()\n",
    "    report[\"distribution_canaries\"][\"day_count_summary\"] = {\n",
    "        \"n_days\": int(by_day.shape[0]),\n",
    "        \"min\": int(by_day.min()) if len(by_day) else 0,\n",
    "        \"median\": float(by_day.median()) if len(by_day) else 0.0,\n",
    "        \"max\": int(by_day.max()) if len(by_day) else 0,\n",
    "    }\n",
    "\n",
    "if \"agency\" in df2.columns:\n",
    "    top_ag = df2[\"agency\"].astype(\"string\").value_counts(dropna=False).head(10)\n",
    "    report[\"distribution_canaries\"][\"top_agencies\"] = top_ag.to_dict()\n",
    "\n",
    "if cat_col:\n",
    "    top_cat = df2[cat_col].astype(\"string\").value_counts(dropna=False).head(10)\n",
    "    report[\"distribution_canaries\"][f\"top_categories:{cat_col}\"] = top_cat.to_dict()\n",
    "\n",
    "if spike_report is not None:\n",
    "    report[\"distribution_canaries\"][\"spike_days\"] = spike_report.to_dict(orient=\"records\")\n",
    "\n",
    "REF_DIR.mkdir(parents=True, exist_ok=True)\n",
    "VALIDATION_PATH.write_text(json.dumps(report, indent=2, default=str))\n",
    "print(\"Saved:\", VALIDATION_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb5a63a-247a-4dc8-9658-16dc597f2ecb",
   "metadata": {},
   "source": [
    "## 2E.7 - Deliverable: Pick Policies for Anomalies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15787ec3-21ec-42e6-aaa1-33fe54baed65",
   "metadata": {},
   "source": [
    "For each anomaly type, decide a policy:\n",
    "* **Fix**: correct obvious errors\n",
    "* **Drop:** rarely ideal; loses information\n",
    "* **Flag:** recommended default\n",
    "* **Quarantine:** exclude from modeling but keep for investigation\n",
    "\n",
    "Fill in and customize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09de14bd-959a-4053-bc29-7e8385532bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anom_duplicate_unique_key': 'flag + investigate upstream, consider dedupe in staging',\n",
       " 'anom_created_in_future': 'quarantine + investigate timezone/parsing bugs',\n",
       " 'anom_negative_duration': 'flag + investigate; consider setting duration to NaN',\n",
       " 'anom_over_30d': 'flag; may be real; consider robust models or caps depending on goal',\n",
       " 'anom_closed_missing_duration': 'flag; treat duration unknown; check status/timestamp consistency'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anomaly_policies = {\n",
    "    \"anom_duplicate_unique_key\": \"flag + investigate upstream, consider dedupe in staging\",\n",
    "    \"anom_created_in_future\": \"quarantine + investigate timezone/parsing bugs\",\n",
    "    \"anom_negative_duration\": \"flag + investigate; consider setting duration to NaN\",\n",
    "    \"anom_over_30d\": \"flag; may be real; consider robust models or caps depending on goal\",\n",
    "    \"anom_closed_missing_duration\": \"flag; treat duration unknown; check status/timestamp consistency\",\n",
    "}\n",
    "\n",
    "anomaly_policies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b32e83-5f8f-4f9e-baeb-daaa57e37d8f",
   "metadata": {},
   "source": [
    "## 2E.8 - Quick Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ad57d6-7488-435a-a1f5-0b39bbbec5bb",
   "metadata": {},
   "source": [
    "We should now have:\n",
    "* Anomaly flags + an investigation table\n",
    "* Fail-fast validations (contracts)\n",
    "* A leakage audit checklist\n",
    "* A reusable `validation_report.json` artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace9663-3012-49ba-a4c3-9b68d8b215a9",
   "metadata": {},
   "source": [
    "# F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c372ea-163b-448f-a841-c87d7f0907dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
