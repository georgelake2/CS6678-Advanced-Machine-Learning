{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76ffd72a-6ea0-48d3-b25b-b56146bbcaca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Module 2.A - Where Data Comes From (Real-World Pipeline Starter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f781be-2019-4f56-9cdc-d0eba52a15bb",
   "metadata": {},
   "source": [
    "### Core dataset for the whole module \n",
    "\n",
    "**NYC 311 Service Requests (2020 - present)** (NYC Open Data/Socrata)  \n",
    "Why this dataset works for learning:\n",
    "* **Real mess:** missing values, inconsistent strings, free-text fields, and \"weird\" categories.\n",
    "* **Real scale:** the full dataset is huge, so must learn how to pull a *slice*\n",
    "* **Multiple access modes:** the same data is available as **CSV, API (JSON), SQL**\n",
    "* **Real change over time:** fields and value distributions can shift (schema drift)\n",
    "\n",
    "Will also create two supporting assets that will be reused later:\n",
    "* **Data dictionary Excel file:** (`.xlsx`) from the publisher (documentation)\n",
    "* **Borough reference table:** either scraped from the web or created as a seed file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ceafff-0797-4d5c-9798-ce449f63132a",
   "metadata": {},
   "source": [
    "### What will be built in 2.A  \n",
    "\n",
    "Will produce a local, module-scoped workspace. Organized by module and stored as described:  \n",
    "```bash\n",
    "~/work/m2/data/\n",
    "    raw/          # downloaded files, API responses\n",
    "    reference/    # lookup tables, dictionaries\n",
    "    warehouse/    # SQLite databases\n",
    "```\n",
    "\n",
    "Later notebooks will assume these exist:\n",
    "* **2.B** Data quality: missingness, duplicates, inconsistent categories, schema drift\n",
    "* **2.C** Wrangling: groupby, joins, string cleaning, feature construction\n",
    "* **2.D** Scaling: incremental refresh, \"raw &rarr; staged &rarr; curated\" thinking\n",
    "* **2.E** Outliers/validation: response times, anomaly checks, \"is this plausible?\" rules\n",
    "\n",
    "The goal in 2.A is not perfect cleaning. It is learning how to acquire data reliably and keep the process reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a43184-3f38-4d12-b376-6bed75c45565",
   "metadata": {},
   "source": [
    "## Setup (requests, BeautifulSoup, and a writable workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810bac2c-e64d-42ea-ba60-6752e1d214b9",
   "metadata": {},
   "source": [
    "Common libraries:\n",
    "* **requests:** a simple way to make HTTP requests\n",
    "* **BeautifulSoup:** parses HTML to extract pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "460c6389-197e-4e02-8d38-00bb053b413b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writable Module 2 data workspace ready:\n",
      "  /home/glake/Nextcloud/Classwork/CS6678 - Advanced Machine Learning/Jupyter Notebooks/work/m2/data\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 60)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "# Writable workspace (module-scoped)\n",
    "WORK_DIR   = Path(\"work\")\n",
    "MODULE_DIR = WORK_DIR / \"m2\"\n",
    "DATA_DIR   = MODULE_DIR / \"data\"\n",
    "RAW_DIR    = DATA_DIR / \"raw\"\n",
    "REF_DIR    = DATA_DIR / \"reference\"\n",
    "WH_DIR     = DATA_DIR / \"warehouse\"\n",
    "\n",
    "for d in [RAW_DIR, REF_DIR, WH_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Writable Module 2 data workspace ready:\")\n",
    "print(\" \", DATA_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc54439-d0b3-4c49-aa60-bcc77c157d0d",
   "metadata": {},
   "source": [
    "## A.0 - Source Audit Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de33a29-bda7-45bc-8955-0015fdcc8a8f",
   "metadata": {},
   "source": [
    "Before cleaning, provide answers to:  \n",
    "* What does one row represent\n",
    "* What system produced it?\n",
    "* What time range does it cover?\n",
    "* What are known limitations?\n",
    "* Which fields look risky (missing, free-text, inconsistent categories)?\n",
    "\n",
    "We will keep a small structured dictionary of notes that can be reused later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a50976b2-57ee-4cc3-a219-1f9958393009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'NYC 311 Service Requests (2020-present)',\n",
       " 'publisher': 'NYC Open Data / 311',\n",
       " 'where_it_comes_from': 'City 311 request intake system (customer service requests routed to agencies).',\n",
       " 'unit_of_analysis': 'Each row represents one 311 service request.',\n",
       " 'time_grain': 'Requests are created continuously; rows include timestamps for created/closed when available.',\n",
       " 'known_limitations': ['Many fields are optional depending on request type (expect missingness).',\n",
       "  'Free-text fields (descriptor/address) can be inconsistent and messy.',\n",
       "  'The dataset is continuously updated; results can change between runs.'],\n",
       " 'Notes 1/30/26': []}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_audit = {\n",
    "    \"dataset_name\": \"NYC 311 Service Requests (2020-present)\",\n",
    "    \"publisher\": \"NYC Open Data / 311\",\n",
    "    \"where_it_comes_from\": \"City 311 request intake system (customer service requests routed to agencies).\",\n",
    "    \"unit_of_analysis\": \"Each row represents one 311 service request.\", \n",
    "    \"time_grain\": \"Requests are created continuously; rows include timestamps for created/closed when available.\",\n",
    "    \"known_limitations\": [\n",
    "        \"Many fields are optional depending on request type (expect missingness).\",\n",
    "        \"Free-text fields (descriptor/address) can be inconsistent and messy.\",\n",
    "        \"The dataset is continuously updated; results can change between runs.\",\n",
    "    ],\n",
    "    \"Notes 1/30/26\": []\n",
    "}\n",
    "\n",
    "source_audit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d007fc-6579-400b-9e30-56fb78247772",
   "metadata": {},
   "source": [
    "## A.1 Files (CSV): Download a Reproducible Slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3497e542-745e-4b3b-8108-3c315aae2f0b",
   "metadata": {},
   "source": [
    "Large public datasets are often too big to download in full for learning. A useful technique is to define a slice that is:  \n",
    "* small enough to iterate quickly (seconds, not minutes)\n",
    "* recent enough to include real mess\n",
    "* refreshable\n",
    "\n",
    "We will pull the **last 14 days** of NYC 311 requests as a CSV  \n",
    "\n",
    "**Note on Socrata Timestamps**  \n",
    "\n",
    "NYC Open Data uses Socrata. Many timestamp fields are \"floating timestamps\" and expect ISO8601 without timezone suffixes (No Z, No +00:00) in the query string. So we format timestamps like: `2026-01-04T04:03:21`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d46976b-2d28-4958-811e-4c97cbeecbce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where clause: created_date >= '2026-01-17T14:18:35'AND created_date < '2026-01-31T14:18:35'\n",
      "Used cached: work/m2/data/raw/nyc311_last14d.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('work/m2/data/raw/nyc311_last14d.csv')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYC311_BASE = \"https://data.cityofnewyork.us/resource/erm2-nwe9\"\n",
    "\n",
    "# Stable subset of columns that will be reused across Module 2.\n",
    "NYC311_COLUMNS = [\n",
    "    \"unique_key\",\n",
    "    \"created_date\",\n",
    "    \"closed_date\",\n",
    "    \"agency\",\n",
    "    \"agency_name\",\n",
    "    \"complaint_type\",\n",
    "    \"descriptor\",\n",
    "    \"status\",\n",
    "    \"borough\",\n",
    "    \"incident_zip\",\n",
    "    \"incident_address\",\n",
    "    \"street_name\",\n",
    "    \"city\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "]\n",
    "\n",
    "def iso_floating(dt: datetime) -> str:\n",
    "    \"\"\"\n",
    "    Socrata floating timestamps expect ISO8601 without timezone suffix.\n",
    "    We will drop tzinfo and milliseconds to be conservative\n",
    "    \"\"\"\n",
    "    dt = dt.astimezone(timezone.utc).replace(tzinfo=None)\n",
    "    return dt.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "def download_if_missing(url: str, path: Path, params: dict | None = None, timeout: int = 30) -> Path:\n",
    "    \"\"\"\n",
    "    Download a URL to disk only if the file is not already cached.\n",
    "    We chace downloads so later notebooks (2.B - 2.E) can reuse the same files\n",
    "    without hammering the public API repeatedly.\n",
    "    \"\"\"\n",
    "    if path.exists() and path.stat().st_size > 0:\n",
    "        print(\"Used cached:\", path)\n",
    "        return path\n",
    "\n",
    "    print(\"Downloading:\", url)\n",
    "    r = requests.get(url, params=params, timeout=timeout)\n",
    "\n",
    "    if r.status_code >= 400:\n",
    "        print(\"Status:\", r.status_code)\n",
    "        print(\"Body (first 300 chars):\", r.text[:300])\n",
    "\n",
    "    r.raise_for_status()\n",
    "    path.write_bytes(r.content)\n",
    "    print(\"Saved:\", path, f\"({path.stat().st_size/1e6:.2f} MB)\")\n",
    "    return path\n",
    "\n",
    "def socrata_csv_params(days: int=14, limit: int=5000) -> dict:\n",
    "    end = datetime.now(timezone.utc)\n",
    "    start = end - timedelta(days=days)\n",
    "\n",
    "    select = \",\".join(NYC311_COLUMNS)\n",
    "    where = (\n",
    "        f\"created_date >= '{iso_floating(start)}'\"\n",
    "        f\"AND created_date < '{iso_floating(end)}'\"\n",
    "    )\n",
    "    return {\"$select\": select, \"$where\": where, \"$order\": \"created_date DESC\", \"$limit\": limit}\n",
    "\n",
    "CSV_PATH = RAW_DIR / \"nyc311_last14d.csv\"\n",
    "params = socrata_csv_params(days=14, limit=50000)\n",
    "\n",
    "print(\"Where clause:\", params[\"$where\"])\n",
    "download_if_missing(f\"{NYC311_BASE}.csv\", CSV_PATH, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0752da8f-8e7d-4a99-b900-4b9a0ba78a76",
   "metadata": {},
   "source": [
    "### Load the CSV and do a quick source audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ad1efa-5939-48e4-a37f-4dd131817495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>status</th>\n",
       "      <th>borough</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30T01:51:21.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30T01:51:04.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOE</td>\n",
       "      <td>Department of Education</td>\n",
       "      <td>School Maintenance</td>\n",
       "      <td>Heating Problem</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11226.0</td>\n",
       "      <td>911 FLATBUSH AVENUE</td>\n",
       "      <td>FLATBUSH AVENUE</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40.649787</td>\n",
       "      <td>-73.958550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30T01:50:53.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10025.0</td>\n",
       "      <td>936 AMSTERDAM AVENUE</td>\n",
       "      <td>AMSTERDAM AVENUE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>40.800498</td>\n",
       "      <td>-73.965680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67707975</td>\n",
       "      <td>2026-01-30T01:50:52.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>10302.0</td>\n",
       "      <td>190 TRANTOR PLACE</td>\n",
       "      <td>TRANTOR PLACE</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>40.629156</td>\n",
       "      <td>-74.144411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67771794</td>\n",
       "      <td>2026-01-30T01:50:32.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Taxi and Limousine Commission</td>\n",
       "      <td>Taxi Complaint</td>\n",
       "      <td>Driver Complaint - Non Passenger</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11430.0</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JAMAICA</td>\n",
       "      <td>40.648320</td>\n",
       "      <td>-73.788281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key             created_date closed_date agency                      agency_name       complaint_type  \\\n",
       "0    67720523  2026-01-30T01:51:21.000         NaN   NYPD  New York City Police Department   Noise - Commercial   \n",
       "1    67746090  2026-01-30T01:51:04.000         NaN    DOE          Department of Education   School Maintenance   \n",
       "2    67758820  2026-01-30T01:50:53.000         NaN   NYPD  New York City Police Department  Noise - Residential   \n",
       "3    67707975  2026-01-30T01:50:52.000         NaN   NYPD  New York City Police Department  Noise - Residential   \n",
       "4    67771794  2026-01-30T01:50:32.000         NaN    TLC    Taxi and Limousine Commission       Taxi Complaint   \n",
       "\n",
       "                         descriptor       status        borough  incident_zip        incident_address             street_name  \\\n",
       "0                  Loud Music/Party  Unspecified    Unspecified           NaN                     NaN                     NaN   \n",
       "1                   Heating Problem  In Progress       BROOKLYN       11226.0     911 FLATBUSH AVENUE         FLATBUSH AVENUE   \n",
       "2                  Loud Music/Party  In Progress      MANHATTAN       10025.0    936 AMSTERDAM AVENUE        AMSTERDAM AVENUE   \n",
       "3                  Loud Music/Party  In Progress  STATEN ISLAND       10302.0       190 TRANTOR PLACE           TRANTOR PLACE   \n",
       "4  Driver Complaint - Non Passenger  In Progress         QUEENS       11430.0  JOHN F KENNEDY AIRPORT  JOHN F KENNEDY AIRPORT   \n",
       "\n",
       "            city   latitude  longitude  \n",
       "0            NaN        NaN        NaN  \n",
       "1       BROOKLYN  40.649787 -73.958550  \n",
       "2       NEW YORK  40.800498 -73.965680  \n",
       "3  STATEN ISLAND  40.629156 -74.144411  \n",
       "4        JAMAICA  40.648320 -73.788281  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv = pd.read_csv(CSV_PATH)\n",
    "df_csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68d17ed2-1361-4f29-bca2-02aaad41a2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_key            int64\n",
       "created_date         object\n",
       "closed_date          object\n",
       "agency               object\n",
       "agency_name          object\n",
       "complaint_type       object\n",
       "descriptor           object\n",
       "status               object\n",
       "borough              object\n",
       "incident_zip        float64\n",
       "incident_address     object\n",
       "street_name          object\n",
       "city                 object\n",
       "latitude            float64\n",
       "longitude           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4a7a92-f774-4b08-ac6b-69ccf4556502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "closed_date         0.60766\n",
       "city                0.07640\n",
       "street_name         0.02592\n",
       "incident_address    0.02588\n",
       "latitude            0.01222\n",
       "longitude           0.01222\n",
       "incident_zip        0.00732\n",
       "descriptor          0.00680\n",
       "complaint_type      0.00000\n",
       "agency              0.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.isna().mean().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59cb715-e1f4-48d5-84a7-8fe1dcdb4557",
   "metadata": {},
   "source": [
    "**Update Source Audit**  \n",
    "\n",
    "Add 3 observations to `source_audit[\"today_notes\"]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47c8d1d5-a987-4896-84a6-115d242e4502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'NYC 311 Service Requests (2020-present)',\n",
       " 'publisher': 'NYC Open Data / 311',\n",
       " 'where_it_comes_from': 'City 311 request intake system (customer service requests routed to agencies).',\n",
       " 'unit_of_analysis': 'Each row represents one 311 service request.',\n",
       " 'time_grain': 'Requests are created continuously; rows include timestamps for created/closed when available.',\n",
       " 'known_limitations': ['Many fields are optional depending on request type (expect missingness).',\n",
       "  'Free-text fields (descriptor/address) can be inconsistent and messy.',\n",
       "  'The dataset is continuously updated; results can change between runs.'],\n",
       " 'Notes 1/30/26': ['incident_zip does not need to be a float64',\n",
       "  'There is at least one entry that is incomplete',\n",
       "  'closed_date is often missing']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clear current notes so that the cell does not create duplicate entries\n",
    "source_audit[\"Notes 1/30/26\"] = []\n",
    "source_audit[\"Notes 1/30/26\"].append(\"incident_zip does not need to be a float64\")\n",
    "source_audit[\"Notes 1/30/26\"].append(\"There is at least one entry that is incomplete\")\n",
    "source_audit[\"Notes 1/30/26\"].append(\"closed_date is often missing\")\n",
    "\n",
    "source_audit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedab84d-83d9-4481-ab57-f00a74462a85",
   "metadata": {},
   "source": [
    "## A.2 SQL databases (SQLite): Land Raw Data Into a Local Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9f288a2-ac12-48cf-9fad-d00fbae2ad3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DB: /home/glake/Nextcloud/Classwork/CS6678 - Advanced Machine Learning/Jupyter Notebooks/work/m2/data/warehouse/module2.db\n"
     ]
    }
   ],
   "source": [
    "DB_PATH = WH_DIR / \"module2.db\"\n",
    "conn = sqlite3.connect(DB_PATH)\n",
    "print(\"DB:\", DB_PATH.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97839e0-0e6b-4e8a-be56-4c84dac86155",
   "metadata": {},
   "source": [
    "### Write the raw CSV into a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44b8b112-3750-41d8-ba33-5402b02d332a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in nyc311_raw: 50000\n"
     ]
    }
   ],
   "source": [
    "df_csv.to_sql(\"nyc311_raw\", conn, if_exists=\"replace\", index=False)\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"CREATE INDEX IF NOT EXISTS idx_nyc311_created_date ON nyc311_raw(created_date)\")\n",
    "cur.execute(\"CREATE INDEX IF NOT EXISTS idx_nyc311_borough ON nyc311_raw(borough)\")\n",
    "cur.execute(\"CREATE INDEX IF NOT EXISTS idx_nyc311_complaint_type ON nyc311_raw(complaint_type)\")\n",
    "conn.commit()\n",
    "\n",
    "print(\"Rows in nyc311_raw:\", cur.execute(\"SELECT COUNT(*) FROM nyc311_raw\").fetchone()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eedb0d-99e1-4150-bba7-d05243b033be",
   "metadata": {},
   "source": [
    "### SQL sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04c041d7-865c-4355-8f7d-5f056f0afa95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borough</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>15654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRONX</td>\n",
       "      <td>10806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>8876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>2798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Unspecified</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         borough      n\n",
       "0       BROOKLYN  15654\n",
       "1         QUEENS  11831\n",
       "2          BRONX  10806\n",
       "3      MANHATTAN   8876\n",
       "4  STATEN ISLAND   2798\n",
       "5    Unspecified     35"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT borough, COUNT(*) AS n\n",
    "FROM nyc311_raw\n",
    "GROUP BY borough\n",
    "ORDER BY n DESC\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(q, conn).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05519193-992d-4507-95a8-35f03d4a9c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Snow or Ice</td>\n",
       "      <td>12376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HEAT/HOT WATER</td>\n",
       "      <td>11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Illegal Parking</td>\n",
       "      <td>4922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blocked Driveway</td>\n",
       "      <td>2790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UNSANITARY CONDITION</td>\n",
       "      <td>1288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PLUMBING</td>\n",
       "      <td>1212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PAINT/PLASTER</td>\n",
       "      <td>819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DOOR/WINDOW</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WATER LEAK</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Traffic Signal Condition</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Water System</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Homeless Person Assistance</td>\n",
       "      <td>530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GENERAL</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ELECTRIC</td>\n",
       "      <td>465</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                complaint_type      n\n",
       "0                  Snow or Ice  12376\n",
       "1               HEAT/HOT WATER  11890\n",
       "2              Illegal Parking   4922\n",
       "3             Blocked Driveway   2790\n",
       "4          Noise - Residential   2492\n",
       "5         UNSANITARY CONDITION   1288\n",
       "6                     PLUMBING   1212\n",
       "7                PAINT/PLASTER    819\n",
       "8                  DOOR/WINDOW    773\n",
       "9                   WATER LEAK    750\n",
       "10    Traffic Signal Condition    722\n",
       "11                Water System    549\n",
       "12  Homeless Person Assistance    530\n",
       "13                     GENERAL    474\n",
       "14                    ELECTRIC    465"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT complaint_type, COUNT(*) AS n\n",
    "FROM nyc311_raw\n",
    "GROUP BY complaint_type\n",
    "ORDER BY n DESC\n",
    "LIMIT 15\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql_query(q, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fac982-8c72-4208-ab09-f2bf143b59f7",
   "metadata": {},
   "source": [
    "## A.3 APIs: query the same dataset via Socrata (JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffc4f89d-78dc-4eed-b967-f43b6d1cf7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records fetched (JSON): 2000\n",
      "Example record keys: ['unique_key', 'created_date', 'agency', 'agency_name', 'complaint_type', 'descriptor', 'status', 'borough']\n"
     ]
    }
   ],
   "source": [
    "def socrata_json(days: int=14, limit: int=1000, offset: int=0) -> List[Dict[str, Any]]:\n",
    "    end = datetime.now(timezone.utc)\n",
    "    start = end - timedelta(days=days)\n",
    "\n",
    "    select = \",\".join(NYC311_COLUMNS)\n",
    "    where = (\n",
    "        f\"created_date >= '{iso_floating(start)}'\"\n",
    "        f\"AND created_date < '{iso_floating(end)}'\"\n",
    "    )\n",
    "\n",
    "    params = {\"$select\": select, \"$where\": where, \"$order\": \"created_date DESC\", \"$limit\": limit, \"$offset\": offset}\n",
    "    r = requests.get(f\"{NYC311_BASE}.json\", params=params, timeout=30)\n",
    "\n",
    "    if r.status_code >= 400:\n",
    "        print(\"Status:\", r.status_code)\n",
    "        print(\"Where:\", where)\n",
    "        print(\"Body (first 300 chars):\", r.text[300])\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "page1 = socrata_json(days=14, limit=1000, offset=0)\n",
    "page2 = socrata_json(days=14, limit=1000, offset=1000)\n",
    "records = page1 + page2\n",
    "\n",
    "print(\"Records fetched (JSON):\", len(records))\n",
    "print(\"Example record keys:\", list(records[0].keys())[:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fa26e7-761f-48e0-a7ae-3d6d3dd1fee9",
   "metadata": {},
   "source": [
    "### Save raw JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2f8f129a-f8f2-4c38-be3e-f2a893293109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: work/m2/data/raw/nyc311_last14d.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>status</th>\n",
       "      <th>borough</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>closed_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30T01:51:21.000</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30T01:51:04.000</td>\n",
       "      <td>DOE</td>\n",
       "      <td>Department of Education</td>\n",
       "      <td>School Maintenance</td>\n",
       "      <td>Heating Problem</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11226</td>\n",
       "      <td>911 FLATBUSH AVENUE</td>\n",
       "      <td>FLATBUSH AVENUE</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40.64978696357874</td>\n",
       "      <td>-73.95854980692795</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30T01:50:53.000</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10025</td>\n",
       "      <td>936 AMSTERDAM AVENUE</td>\n",
       "      <td>AMSTERDAM AVENUE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>40.80049840941944</td>\n",
       "      <td>-73.96567975561733</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  unique_key             created_date agency                      agency_name       complaint_type        descriptor       status  \\\n",
       "0   67720523  2026-01-30T01:51:21.000   NYPD  New York City Police Department   Noise - Commercial  Loud Music/Party  Unspecified   \n",
       "1   67746090  2026-01-30T01:51:04.000    DOE          Department of Education   School Maintenance   Heating Problem  In Progress   \n",
       "2   67758820  2026-01-30T01:50:53.000   NYPD  New York City Police Department  Noise - Residential  Loud Music/Party  In Progress   \n",
       "\n",
       "       borough incident_zip      incident_address       street_name      city           latitude           longitude closed_date  \n",
       "0  Unspecified          NaN                   NaN               NaN       NaN                NaN                 NaN         NaN  \n",
       "1     BROOKLYN        11226   911 FLATBUSH AVENUE   FLATBUSH AVENUE  BROOKLYN  40.64978696357874  -73.95854980692795         NaN  \n",
       "2    MANHATTAN        10025  936 AMSTERDAM AVENUE  AMSTERDAM AVENUE  NEW YORK  40.80049840941944  -73.96567975561733         NaN  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON_PATH = RAW_DIR / \"nyc311_last14d.json\"\n",
    "if not JSON_PATH.exists():\n",
    "    JSON_PATH.write_text(json.dumps(records, indent=2))\n",
    "    print(\"Saved:\", JSON_PATH)\n",
    "else:\n",
    "    print(\"Using cached:\", JSON_PATH)\n",
    "\n",
    "df_api = pd.json_normalize(records)\n",
    "df_api.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282635ee-3b3e-4226-bf76-b3f70070888f",
   "metadata": {},
   "source": [
    "### Compare CSV vs API quickly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bb77300-e8ef-4d6c-b179-97dd3483ff01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'csv_columns': 15,\n",
       " 'api_columns': 15,\n",
       " 'columns_only_in_csv': [],\n",
       " 'columns_only_in_api': [],\n",
       " 'csv_missing_rate_top10': {'closed_date': 0.60766,\n",
       "  'city': 0.0764,\n",
       "  'street_name': 0.02592,\n",
       "  'incident_address': 0.02588,\n",
       "  'latitude': 0.01222,\n",
       "  'longitude': 0.01222,\n",
       "  'incident_zip': 0.00732,\n",
       "  'descriptor': 0.0068,\n",
       "  'complaint_type': 0.0,\n",
       "  'agency': 0.0},\n",
       " 'api_missing_rate_top10': {'closed_date': 0.649,\n",
       "  'city': 0.046,\n",
       "  'street_name': 0.024,\n",
       "  'incident_address': 0.024,\n",
       "  'latitude': 0.019,\n",
       "  'longitude': 0.019,\n",
       "  'incident_zip': 0.0075,\n",
       "  'status': 0.0,\n",
       "  'descriptor': 0.0,\n",
       "  'complaint_type': 0.0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_notes = {\n",
    "    \"csv_columns\": len(df_csv.columns),\n",
    "    \"api_columns\": len(df_api.columns),\n",
    "    \"columns_only_in_csv\": sorted(set(df_csv.columns) - set(df_api.columns))[:20],\n",
    "    \"columns_only_in_api\": sorted(set(df_api.columns) - set(df_csv.columns))[:20],\n",
    "    \"csv_missing_rate_top10\": df_csv.isna().mean().sort_values(ascending=False).head(10).to_dict(),\n",
    "    \"api_missing_rate_top10\": df_api.isna().mean().sort_values(ascending=False).head(10).to_dict(),\n",
    "}\n",
    "\n",
    "comparison_notes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caa7961-95c7-425b-bbff-47ac51ff3d9c",
   "metadata": {},
   "source": [
    "## A.4 Reference Data: Borough Lookup (Scrape OR Seed File)\n",
    "\n",
    "Try **Scrape** first, if it fails (403), fall back to **Seed File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c153ef5-ec35-4239-a3b5-7c8afde1d60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option A success: scraped boroughs and saved: work/m2/data/reference/nyc_boroughs.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borough</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jurisdiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Bronx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brooklyn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manhattan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Queens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Staten Island</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>City of New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>State of New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sources : [ 3 ] [ 4 ] [ 5 ] [ 6 ] and see indi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             borough\n",
       "0                                       Jurisdiction\n",
       "1                                          The Bronx\n",
       "2                                           Brooklyn\n",
       "3                                          Manhattan\n",
       "4                                             Queens\n",
       "5                                      Staten Island\n",
       "6                                   City of New York\n",
       "7                                  State of New York\n",
       "8  Sources : [ 3 ] [ 4 ] [ 5 ] [ 6 ] and see indi..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BORO_PATH = REF_DIR / \"nyc_boroughs.csv\"\n",
    "\n",
    "if BORO_PATH.exists():\n",
    "    print(\"Using cached:\", BORO_PATH)\n",
    "    df_boro = pd.read_csv(BORO_PATH)\n",
    "    display(df_boro)\n",
    "else:\n",
    "    WIKI_URL = \"https://en.wikipedia.org/wiki/Boroughs_of_New_York_City\"\n",
    "    HEADERS = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (educational; JupyterLab) requests\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        r = requests.get(WIKI_URL, headers=HEADERS, timeout=30)\n",
    "        if r.status_code >= 400:\n",
    "            raise RuntimeError(f\"HTTP {r.status_code} from Wikipedia\")\n",
    "\n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "\n",
    "        tables = soup.find_all(\"table\", class_=\"wikitable\")\n",
    "        target = None\n",
    "        for t in tables:\n",
    "            header_text = t.get_text(\" \", strip=True).lower()\n",
    "            if \"borough\" in header_text and \"population\" in header_text:\n",
    "                target = t\n",
    "                break\n",
    "\n",
    "        if target is None:\n",
    "            raise RuntimeError(\"Could not find expected borough table (page structure may have changed).\")\n",
    "\n",
    "        rows = []\n",
    "        for tr in target.find_all(\"tr\")[1:]:\n",
    "            tds = tr.find_all([\"th\", \"td\"])\n",
    "            if not tds:\n",
    "                continue\n",
    "            borough = tds[0].get_text(\" \", strip=True).strip()\n",
    "            if borough and borough.lower() != \"borough\":\n",
    "                rows.append({\"borough\": borough})\n",
    "\n",
    "        df_boro = pd.DataFrame(rows).drop_duplicates().reset_index(drop=True)\n",
    "        df_boro.to_csv(BORO_PATH, index=False)\n",
    "        print(\"Option A success: scraped boroughs and saved:\", BORO_PATH)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(\"Option A failed (scraping). Reason:\", e)\n",
    "        print(\"Falling back to Option B (seed file).\")\n",
    "    \n",
    "        df_boro = pd.DataFrame([\n",
    "            {\"borough\": \"BRONX\"},\n",
    "            {\"borough\": \"BROOKLYN\"},\n",
    "            {\"borough\": \"MANHATTAN\"},\n",
    "            {\"borough\": \"QUEENS\"},\n",
    "            {\"borough\": \"STATEN ISLAND\"},\n",
    "        ])\n",
    "        df_boro.to_csv(BORO_PATH, index=False)\n",
    "        print(\"Option B success: saved seed borough table:\", BORO_PATH)\n",
    "    \n",
    "    display(df_boro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656e59d-ac6f-4c8f-b565-8c648cd346ff",
   "metadata": {},
   "source": [
    "**Notes:**  \n",
    "* Scraping can break even if the code is correct (403, HTML changes)\n",
    "* In many teams, seed files are the standard approach for small reference tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a2c59d-41cf-4119-a9b7-3583446b21ad",
   "metadata": {},
   "source": [
    "## A.5 Excel: Download the 311 data dictionary (XLSX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb6c3f24-fa5d-4626-9efa-ab0a76cccf77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://nycopendata.socrata.com/api/views/erm2-nwe9/files/b372b884-f86a-453b-ba16-1fe06ce9d212?download=true&filename=311_ServiceRequest_2010-Present_DataDictionary_Updated_2023.xlsx\n",
      "Saved: work/m2/data/reference/nyc311_data_dictionary.xlsx (0.50 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('work/m2/data/reference/nyc311_data_dictionary.xlsx')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DICTIONARY_URL = (\n",
    "    \"https://nycopendata.socrata.com/api/views/erm2-nwe9/files/\"\n",
    "    \"b372b884-f86a-453b-ba16-1fe06ce9d212?download=true&filename=311_ServiceRequest_2010-Present_DataDictionary_Updated_2023.xlsx\"\n",
    ")\n",
    "\n",
    "XLSX_PATH = REF_DIR / \"nyc311_data_dictionary.xlsx\"\n",
    "download_if_missing(DATA_DICTIONARY_URL, XLSX_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "434ab8a0-0d39-48d3-bf6d-3133300958f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dataset Information',\n",
       " 'Column Information',\n",
       " 'All Agencies Complaint<>Details',\n",
       " 'HPD Complaint<>Details',\n",
       " 'Dataset Revision History',\n",
       " 'Primer Page & InternaI Informat',\n",
       " 'Hidden_Frequencies',\n",
       " 'Hidden_Agencies',\n",
       " 'Hidden_DataTypes']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openpyxl\n",
    "wb = openpyxl.load_workbook(XLSX_PATH, read_only=True)\n",
    "wb.sheetnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4d61c9a-86f2-4f43-a255-ad8fd7ac73c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/glake/miniconda3/envs/ml/lib/python3.12/site-packages/openpyxl/worksheet/_read_only.py:85: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Dictionary - Dataset Information</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dataset Name</td>\n",
       "      <td>311 Service Requests from 2010 to Present</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dataset URL</td>\n",
       "      <td>https://data.cityofnewyork.us/Social-Services/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Provided by\\nThe name of the NYC agency p...</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Each row is a... \\nThe unit of analysis/level ...</td>\n",
       "      <td>311 Service Request</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Publishing Frequency\\nHow often changed data i...</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Data Change Frequency\\nHow often the data unde...</td>\n",
       "      <td>Daily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Frequency Details\\nAdditional details about th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Dataset Description\\nOverview of the informati...</td>\n",
       "      <td>NYC311 responds to thousands of inquiries, com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Why is this data collected?\\nPurpose behind th...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>How is this data collected?\\nThe methods used ...</td>\n",
       "      <td>This dataset describes site-specific non-emerg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How can this data be used?\\nExamples of and/or...</td>\n",
       "      <td>Some questions that you can explore with this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What are the unique characteristics or limitat...</td>\n",
       "      <td>This dataset does not include inquiries, some ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Additional geospatial information\\nFor any dat...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Unnamed: 0                                         Unnamed: 1\n",
       "0                                                 NaN                                                NaN\n",
       "1                                                 NaN                                                NaN\n",
       "2                                                 NaN                                                NaN\n",
       "3                                                 NaN                                                NaN\n",
       "4                                                 NaN                                                NaN\n",
       "5                                                 NaN                                                NaN\n",
       "6               Data Dictionary - Dataset Information                                                NaN\n",
       "7                                        Dataset Name          311 Service Requests from 2010 to Present\n",
       "8                                         Dataset URL  https://data.cityofnewyork.us/Social-Services/...\n",
       "9   Data Provided by\\nThe name of the NYC agency p...                                                311\n",
       "10  Each row is a... \\nThe unit of analysis/level ...                                311 Service Request\n",
       "11  Publishing Frequency\\nHow often changed data i...                                              Daily\n",
       "12  Data Change Frequency\\nHow often the data unde...                                              Daily\n",
       "13  Frequency Details\\nAdditional details about th...                                                NaN\n",
       "14  Dataset Description\\nOverview of the informati...  NYC311 responds to thousands of inquiries, com...\n",
       "15  Why is this data collected?\\nPurpose behind th...                                                NaN\n",
       "16  How is this data collected?\\nThe methods used ...  This dataset describes site-specific non-emerg...\n",
       "17  How can this data be used?\\nExamples of and/or...  Some questions that you can explore with this ...\n",
       "18  What are the unique characteristics or limitat...  This dataset does not include inquiries, some ...\n",
       "19  Additional geospatial information\\nFor any dat...                                                NaN"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sheet = wb.sheetnames[0]\n",
    "df_dict_preview = pd.read_excel(XLSX_PATH, sheet_name=sheet)\n",
    "df_dict_preview.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77984639-93eb-40fa-adac-49229dbb76a3",
   "metadata": {},
   "source": [
    "Many data dictionaries are human-formatted spreadsheets with title blocks and notes. The first read may look messy (Unnamed columns, NaNs). That is normal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c4acb1-7360-4098-bfec-62319bba3718",
   "metadata": {},
   "source": [
    "## A.6 Wrap-up: Verify Reusable Artifacts Exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27716ded-1e6d-42c0-ab68-2edbcde7c67d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('work/m2/data/raw/nyc311_last14d.csv', True, 12.143),\n",
       " ('work/m2/data/raw/nyc311_last14d.json', True, 1.036),\n",
       " ('work/m2/data/reference/nyc_boroughs.csv', True, 0.0),\n",
       " ('work/m2/data/reference/nyc311_data_dictionary.xlsx', True, 0.497),\n",
       " ('work/m2/data/warehouse/module2.db', True, 13.627)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = [CSV_PATH, JSON_PATH, BORO_PATH, XLSX_PATH, DB_PATH]\n",
    "[(str(p), p.exists(), round(p.stat().st_size/1e6, 3) if p.exists() else None) for p in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd462c81-999f-4af2-8dd8-dfaf0f3da01b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'row_definition': 'Each row represents one 311 service request.',\n",
       " 'incremental_key': '',\n",
       " 'high_risk_columns': [],\n",
       " 'sensitive_columns': []}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reflection = {\n",
    "    \"row_definition\": \"Each row represents one 311 service request.\",\n",
    "    \"incremental_key\": \"\",\n",
    "    \"high_risk_columns\": [],\n",
    "    \"sensitive_columns\": [],\n",
    "}\n",
    "reflection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dd8608-e9b4-413f-a175-9df13a11ebf4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Module 2.B - Data Quality & Structure (NYC 311)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2334db-7fe3-4ef0-bf87-8e989c6879e7",
   "metadata": {},
   "source": [
    "in this notebook we will practice a realistic workflow.  \n",
    "1. **Load** the same NYC311 slice created in 2.A\n",
    "2. **Audit quality:** missingness, duplicates, inconsistencies\n",
    "3. **Detect drift:** \"today vs yesterday\" schema differences\n",
    "4. Produce a short **Data Quality Report** that will be reused in later modules\n",
    "\n",
    "**Note**:  \n",
    "We are not trying to make the dataset perfect.  \n",
    "We are trying to make it **trustworthy enough for a special decision** and to document what was done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10fc27e-0361-4a6a-99a3-a2d94c2fb55f",
   "metadata": {},
   "source": [
    "## 2B.0 - Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc49e2c-0c38-40f5-8f0a-b2813ed80cdd",
   "metadata": {},
   "source": [
    "This notebook expects that **Module 2.A** has already been ran and that a module data workspace has been created  \n",
    "\n",
    "`/work/m2/data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3389f046-a071-4737-aa54-4d0bbd0a47ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: /home/glake/Nextcloud/Classwork/CS6678 - Advanced Machine Learning/Jupyter Notebooks/work/m2/data\n",
      "CSV exists? True | work/m2/data/raw/nyc311_last14d.csv\n",
      "JSON exists? True | work/m2/data/raw/nyc311_last14d.json\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 80)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "WORK_DIR   = Path(\"work\")\n",
    "MODULE_DIR = WORK_DIR / \"m2\"\n",
    "DATA_DIR = MODULE_DIR / \"data\"\n",
    "\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "REF_DIR = DATA_DIR / \"reference\"\n",
    "WH_DIR  = DATA_DIR / \"warehouse\"\n",
    "\n",
    "for d in [RAW_DIR, REF_DIR, WH_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CSV_PATH = RAW_DIR / \"nyc311_last14d.csv\"\n",
    "JSON_PATH = RAW_DIR / \"nyc311_last14d.json\"  # optional if you created via API in 2.A\n",
    "\n",
    "print(\"Data directory:\", DATA_DIR.resolve())\n",
    "print(\"CSV exists?\", CSV_PATH.exists(), \"|\", CSV_PATH)\n",
    "print(\"JSON exists?\", JSON_PATH.exists(), \"|\", JSON_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831734f6-d25b-4a07-8fec-19616042f4a7",
   "metadata": {},
   "source": [
    "## 2B.1 - Load the Data and Establish a Row Definition\n",
    "\n",
    "**Row definition (target):** Each row represents one 311 service request, identified by `unique_key`  \n",
    "\n",
    "Before cleaning, we load as-is and profile the mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6c27193-1060-4270-829d-47b36397d7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (50000, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>status</th>\n",
       "      <th>borough</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30T01:51:21.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30T01:51:04.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOE</td>\n",
       "      <td>Department of Education</td>\n",
       "      <td>School Maintenance</td>\n",
       "      <td>Heating Problem</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11226.0</td>\n",
       "      <td>911 FLATBUSH AVENUE</td>\n",
       "      <td>FLATBUSH AVENUE</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40.649787</td>\n",
       "      <td>-73.958550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30T01:50:53.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10025.0</td>\n",
       "      <td>936 AMSTERDAM AVENUE</td>\n",
       "      <td>AMSTERDAM AVENUE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>40.800498</td>\n",
       "      <td>-73.965680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67707975</td>\n",
       "      <td>2026-01-30T01:50:52.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>10302.0</td>\n",
       "      <td>190 TRANTOR PLACE</td>\n",
       "      <td>TRANTOR PLACE</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>40.629156</td>\n",
       "      <td>-74.144411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67771794</td>\n",
       "      <td>2026-01-30T01:50:32.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Taxi and Limousine Commission</td>\n",
       "      <td>Taxi Complaint</td>\n",
       "      <td>Driver Complaint - Non Passenger</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11430.0</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JAMAICA</td>\n",
       "      <td>40.648320</td>\n",
       "      <td>-73.788281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key             created_date closed_date agency                      agency_name       complaint_type  \\\n",
       "0    67720523  2026-01-30T01:51:21.000         NaN   NYPD  New York City Police Department   Noise - Commercial   \n",
       "1    67746090  2026-01-30T01:51:04.000         NaN    DOE          Department of Education   School Maintenance   \n",
       "2    67758820  2026-01-30T01:50:53.000         NaN   NYPD  New York City Police Department  Noise - Residential   \n",
       "3    67707975  2026-01-30T01:50:52.000         NaN   NYPD  New York City Police Department  Noise - Residential   \n",
       "4    67771794  2026-01-30T01:50:32.000         NaN    TLC    Taxi and Limousine Commission       Taxi Complaint   \n",
       "\n",
       "                         descriptor       status        borough  incident_zip        incident_address             street_name  \\\n",
       "0                  Loud Music/Party  Unspecified    Unspecified           NaN                     NaN                     NaN   \n",
       "1                   Heating Problem  In Progress       BROOKLYN       11226.0     911 FLATBUSH AVENUE         FLATBUSH AVENUE   \n",
       "2                  Loud Music/Party  In Progress      MANHATTAN       10025.0    936 AMSTERDAM AVENUE        AMSTERDAM AVENUE   \n",
       "3                  Loud Music/Party  In Progress  STATEN ISLAND       10302.0       190 TRANTOR PLACE           TRANTOR PLACE   \n",
       "4  Driver Complaint - Non Passenger  In Progress         QUEENS       11430.0  JOHN F KENNEDY AIRPORT  JOHN F KENNEDY AIRPORT   \n",
       "\n",
       "            city   latitude  longitude  \n",
       "0            NaN        NaN        NaN  \n",
       "1       BROOKLYN  40.649787 -73.958550  \n",
       "2       NEW YORK  40.800498 -73.965680  \n",
       "3  STATEN ISLAND  40.629156 -74.144411  \n",
       "4        JAMAICA  40.648320 -73.788281  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(CSV_PATH)\n",
    "print(\"Shape:\", df_raw.shape)\n",
    "df_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e90d61f-3e54-4ef4-833e-e855a29cf8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>status</th>\n",
       "      <th>borough</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dtype</th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      unique_key created_date closed_date  agency agency_name complaint_type descriptor  status borough incident_zip incident_address  \\\n",
       "dtype      int64       object      object  object      object         object     object  object  object      float64           object   \n",
       "\n",
       "      street_name    city latitude longitude  \n",
       "dtype      object  object  float64   float64  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.dtypes.to_frame(\"dtype\").T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3509cca0-82c4-4d0b-98f1-ebd2cb7bc9e5",
   "metadata": {},
   "source": [
    "### Create quality notes  \n",
    "\n",
    "Write row definition and first impressions. Add 3-6 bullets:\n",
    "* What does one row represent?\n",
    "* What columns look risky?\n",
    "* What looks like \"encoded missingness\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa399c7e-9475-4aff-afb6-70180029a87e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'row_definition': 'Each row is one 311 service request (unique_key) created at created_date.',\n",
       " 'data_type_notes': ['incident_zip should be treated as a string to preserve leading zeros.',\n",
       "  'descriptor/incident_address are free-text and likely inconsistent.'],\n",
       " 'completeness_issues': [],\n",
       " 'date_added': '1/30/26'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quality_notes = {\n",
    "    \"row_definition\": \"Each row is one 311 service request (unique_key) created at created_date.\",\n",
    "    \"data_type_notes\": [\n",
    "        \"incident_zip should be treated as a string to preserve leading zeros.\",\n",
    "        \"descriptor/incident_address are free-text and likely inconsistent.\",\n",
    "    ],\n",
    "    \"completeness_issues\": [],\n",
    "    \"date_added\": \"1/30/26\"\n",
    "}\n",
    "quality_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f5272-6ded-4259-972f-9a0d1e7afcea",
   "metadata": {},
   "source": [
    "## 2B.2 - Missing data: Measure, then explain\n",
    "\n",
    "First rule: **do not impute yet**  \n",
    "Start by quantifying missingness and asking why it might be missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6ed7413-b941-453f-8a63-a1240cf122e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "closed_date         0.60766\n",
       "city                0.07640\n",
       "street_name         0.02592\n",
       "incident_address    0.02588\n",
       "latitude            0.01222\n",
       "longitude           0.01222\n",
       "incident_zip        0.00732\n",
       "descriptor          0.00680\n",
       "complaint_type      0.00000\n",
       "agency              0.00000\n",
       "created_date        0.00000\n",
       "unique_key          0.00000\n",
       "agency_name         0.00000\n",
       "status              0.00000\n",
       "borough             0.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_rate = df_raw.isna().mean().sort_values(ascending=False)\n",
    "missing_rate.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23599b62-771b-4a4c-9f81-1856a27c5ad6",
   "metadata": {},
   "source": [
    "### Normalize common \"missing\" encodings  \n",
    "\n",
    "Many real datasets use sentinel values like `\"\"`, `\"UNKNOWN\"`, `\"N/A\"`, or whitespace  \n",
    "\n",
    "Create a `df` as a cleaned copy while keeping `df_raw` unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a39c2d8-77f9-4d43-817b-b186934b9ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "closed_date         0.60766\n",
       "longitude           0.01222\n",
       "latitude            0.01222\n",
       "incident_zip        0.00732\n",
       "agency              0.00000\n",
       "unique_key          0.00000\n",
       "created_date        0.00000\n",
       "descriptor          0.00000\n",
       "complaint_type      0.00000\n",
       "agency_name         0.00000\n",
       "status              0.00000\n",
       "incident_address    0.00000\n",
       "borough             0.00000\n",
       "city                0.00000\n",
       "street_name         0.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "MISSING_TOKENS = {\"\", \" \", \"  \", \"UNKNOWN\", \"Unknown\", \"N/A\", \"NA\", \"NULL\", \"null\"}\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == \"object\":\n",
    "        # Normalize whitespace-only strings\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "        df.loc[df[col].isin(MISSING_TOKENS), col] = np.nan\n",
    "\n",
    "# Parse timestamps (coerce errors to NaT)\n",
    "for col in [\"created_date\", \"closed_date\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "\n",
    "# Treat ZIP as string (preserve leading zeros, handle NaN)\n",
    "if \"incident_zip\" in df.columns:\n",
    "    df[\"incident_zip\"] = df[\"incident_zip\"].astype(\"string\")\n",
    "\n",
    "df.isna().mean().sort_values(ascending=False).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add9dba2-64cf-4100-a199-64b56276c543",
   "metadata": {},
   "source": [
    "### Missingness by group  \n",
    "\n",
    "If missingness varies a lot by group (borough, agency, complaint type), it is often not random, and that affects modeling and fairness  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aada2c64-572c-4121-a85a-7ab0c13140a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting missingness for: incident_address\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "borough\n",
       "BRONX            0.0\n",
       "BROOKLYN         0.0\n",
       "MANHATTAN        0.0\n",
       "QUEENS           0.0\n",
       "STATEN ISLAND    0.0\n",
       "Unspecified      0.0\n",
       "Name: is_missing, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a column with substantial missingness to inspect\n",
    "target_col = \"incident_address\" if \"incident_address\" in df.columns else df.columns[df.isna().mean().idxmax()]\n",
    "print(\"Inspecting missingness for:\", target_col)\n",
    "\n",
    "group_col = \"borough\" if \"borough\" in df.columns else \"agency\"\n",
    "tmp = df[[group_col, target_col]].copy()\n",
    "tmp[\"is_missing\"] = tmp[target_col].isna().astype(int)\n",
    "\n",
    "missing_by_group = tmp.groupby(group_col)[\"is_missing\"].mean().sort_values(ascending=False)\n",
    "missing_by_group.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "833a1b50-2e11-4014-a7f5-c3bdbc2c4a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closed Date missingness for: closed_date\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "borough\n",
       "Unspecified      0.857143\n",
       "STATEN ISLAND    0.728735\n",
       "MANHATTAN        0.631478\n",
       "BROOKLYN         0.598952\n",
       "BRONX            0.593374\n",
       "QUEENS           0.584989\n",
       "Name: is_missing, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check another column - Closed Date\n",
    "target_col = \"closed_date\" if \"closed_date\" in df.columns else df.columns[df.isna().mean().idxmax()]\n",
    "print(\"Closed Date missingness for:\", target_col)\n",
    "\n",
    "group_col = \"borough\" if \"borough\" in df.columns else \"agency\"\n",
    "tmp = df[[group_col, target_col]].copy()\n",
    "tmp[\"is_missing\"] = tmp[target_col].isna().astype(int)\n",
    "\n",
    "missing_by_group = tmp.groupby(group_col)[\"is_missing\"].mean().sort_values(ascending=False)\n",
    "missing_by_group.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8ada2c-5915-4df6-8da8-baac9854cb23",
   "metadata": {},
   "source": [
    "### Task - Missingness Hypothesis  \n",
    "\n",
    "Pick one column with missingness > 20% and answer:\n",
    "1. What might cause it to be missing?\n",
    "2. Is it \"optional by design\" (depends on complaint type)?\n",
    "3. Would dropping rows with missing values change what the data represents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eecd232-9b38-402a-ade9-8a966450b81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Column: closed_date': 'often missing because requests are still open, or closure not required',\n",
       " 'More data': 'More data'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missingness_hypothesis = {\n",
    "    \"Column: closed_date\" : \"often missing because requests are still open, or closure not required\",\n",
    "    \"More data\" : \"More data\"\n",
    "}\n",
    "\n",
    "missingness_hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1bafa3-97dc-45a5-8cd1-77bbf20e165d",
   "metadata": {},
   "source": [
    "## 2B.3 - Duplicates: Exact vs Entity Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc8eb5e-331a-46af-8129-13df7a3300b1",
   "metadata": {},
   "source": [
    "For this dataset, `unique_key` should identify a request.  \n",
    "* **Exact duplicates:** identical rows repeated (export/pipeline issues)\n",
    "* **Key duplicates:** `unique_key` repeats (should be rare; indicates ingestion error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80165834-975f-4cae-b8c7-e284e2f7a6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact duplicate rows: 0\n",
      "Duplicate unique_key values: 0\n"
     ]
    }
   ],
   "source": [
    "# Exact duplicates across all columns\n",
    "exact_dup_count = df.duplicated().sum()\n",
    "print(\"Exact duplicate rows:\", int(exact_dup_count))\n",
    "\n",
    "# Duplicates in the request identifier\n",
    "if \"unique_key\" in df.columns:\n",
    "    key_dup_count = df[\"unique_key\"].duplicated().sum()\n",
    "    print(\"Duplicate unique_key values:\", int(key_dup_count))\n",
    "else:\n",
    "    print(\"No unique_key column found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad7ee661-b3a1-4f40-90ae-72fbca6b28da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No key duplicates found (good).\n"
     ]
    }
   ],
   "source": [
    "if \"unique_key\" in df.columns and df[\"unique_key\"].duplicated().any():\n",
    "    dup_keys = df.loc[df[\"unique_key\"].duplicated(keep=False), \"unique_key\"].head(10).tolist()\n",
    "    df[df[\"unique_key\"].isin(dup_keys)].sort_values(\"unique_key\").head(20)\n",
    "else:\n",
    "    print(\"No key duplicates found (good).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba6865f-fab7-467e-9d7a-c39c66a19016",
   "metadata": {},
   "source": [
    "### Decide a depupe rule (if needed)\n",
    "\n",
    "If key duplicates exists, must choose a rule:\n",
    "* keep the newest record (by created_date)\n",
    "* keep the most complete record\n",
    "* keep the first seen (not recommended unless you know ordering is stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c2c23bb-c20c-4eb4-8b31-8bfcdfa52065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (50000, 15) | After: (50000, 15)\n"
     ]
    }
   ],
   "source": [
    "def dedupe_by_key_keep_most_complete(df_in: pd.DataFrame, key: str) -> pd.DataFrame:\n",
    "    \"\"\"Example rule: keep the row with the fewest missing values per key.\"\"\"\n",
    "    if key not in df_in.columns:\n",
    "        return df_in.copy()\n",
    "\n",
    "    df_tmp = df_in.copy()\n",
    "    miss = df_tmp.isna().sum(axis=1)\n",
    "    df_tmp[\"_missing_count\"] = miss\n",
    "    df_tmp = df_tmp.sort_values([key, \"_missing_count\"]).drop_duplicates(subset=[key], keep=\"first\")\n",
    "    return df_tmp.drop(columns=[\"_missing_count\"])\n",
    "\n",
    "df_deduped = dedupe_by_key_keep_most_complete(df, \"unique_key\")\n",
    "print(\"Before:\", df.shape, \"| After:\", df_deduped.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6064ee-77e5-4323-8658-052deee28824",
   "metadata": {},
   "source": [
    "**Dedupe Notes:**  \n",
    "\n",
    "If duplicates are present, document the rule. If none are present document what was checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9162ff8f-8b47-440d-947f-1444648ea298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_duplicates': 'None found (or dropped them).',\n",
       " 'unique_key_duplicates': 'None found (or deduped by most complete row).',\n",
       " 'rationale': 'unique_key should be the request identifier; duplicates would indicate pipeline/export issues.',\n",
       " 'deduplication_date': '1/30/26'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dedupe_notes = {\n",
    "    \"exact_duplicates\": \"None found (or dropped them).\",\n",
    "    \"unique_key_duplicates\": \"None found (or deduped by most complete row).\",\n",
    "    \"rationale\": \"unique_key should be the request identifier; duplicates would indicate pipeline/export issues.\",\n",
    "    \"deduplication_date\": \"1/30/26\"\n",
    "}\n",
    "dedupe_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69141d08-91eb-48f1-8a36-ae1d402bec55",
   "metadata": {},
   "source": [
    "## 2B.4 - Inconsistencies: Categories, Strings, and \"Almost the Same\" Values  \n",
    "\n",
    "In this dataset, the biggest inconsistency risk tends to be  \n",
    "* **casing / whitespace** (e.g. borough values)\n",
    "* **free-text fields** (descriptor, address)\n",
    "* **categorical sprawl** (complaint_type has many levels)\n",
    "\n",
    "We will do light normalization and build a category audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76a9b682-088b-4fbc-812d-db8bbe729afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== borough ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>borough</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BROOKLYN</th>\n",
       "      <td>15654</td>\n",
       "      <td>0.31308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEENS</th>\n",
       "      <td>11831</td>\n",
       "      <td>0.23662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRONX</th>\n",
       "      <td>10806</td>\n",
       "      <td>0.21612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANHATTAN</th>\n",
       "      <td>8876</td>\n",
       "      <td>0.17752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATEN ISLAND</th>\n",
       "      <td>2798</td>\n",
       "      <td>0.05596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unspecified</th>\n",
       "      <td>35</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count    share\n",
       "borough                      \n",
       "BROOKLYN       15654  0.31308\n",
       "QUEENS         11831  0.23662\n",
       "BRONX          10806  0.21612\n",
       "MANHATTAN       8876  0.17752\n",
       "STATEN ISLAND   2798  0.05596\n",
       "Unspecified       35   0.0007"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== agency ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>agency</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HPD</th>\n",
       "      <td>18618</td>\n",
       "      <td>0.37236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DSNY</th>\n",
       "      <td>13160</td>\n",
       "      <td>0.2632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NYPD</th>\n",
       "      <td>11651</td>\n",
       "      <td>0.23302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOT</th>\n",
       "      <td>1980</td>\n",
       "      <td>0.0396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEP</th>\n",
       "      <td>1339</td>\n",
       "      <td>0.02678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOB</th>\n",
       "      <td>766</td>\n",
       "      <td>0.01532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOHMH</th>\n",
       "      <td>624</td>\n",
       "      <td>0.01248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DHS</th>\n",
       "      <td>613</td>\n",
       "      <td>0.01226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DPR</th>\n",
       "      <td>531</td>\n",
       "      <td>0.01062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TLC</th>\n",
       "      <td>246</td>\n",
       "      <td>0.00492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOE</th>\n",
       "      <td>144</td>\n",
       "      <td>0.00288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DCWP</th>\n",
       "      <td>141</td>\n",
       "      <td>0.00282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        count    share\n",
       "agency                \n",
       "HPD     18618  0.37236\n",
       "DSNY    13160   0.2632\n",
       "NYPD    11651  0.23302\n",
       "DOT      1980   0.0396\n",
       "DEP      1339  0.02678\n",
       "DOB       766  0.01532\n",
       "DOHMH     624  0.01248\n",
       "DHS       613  0.01226\n",
       "DPR       531  0.01062\n",
       "TLC       246  0.00492\n",
       "DOE       144  0.00288\n",
       "DCWP      141  0.00282"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== status ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Closed</th>\n",
       "      <td>18894</td>\n",
       "      <td>0.37788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>15728</td>\n",
       "      <td>0.31456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In Progress</th>\n",
       "      <td>15014</td>\n",
       "      <td>0.30028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assigned</th>\n",
       "      <td>203</td>\n",
       "      <td>0.00406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Started</th>\n",
       "      <td>137</td>\n",
       "      <td>0.00274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pending</th>\n",
       "      <td>22</td>\n",
       "      <td>0.00044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unspecified</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count    share\n",
       "status                     \n",
       "Closed       18894  0.37788\n",
       "Open         15728  0.31456\n",
       "In Progress  15014  0.30028\n",
       "Assigned       203  0.00406\n",
       "Started        137  0.00274\n",
       "Pending         22  0.00044\n",
       "Unspecified      2  0.00004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== complaint_type ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complaint_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Snow or Ice</th>\n",
       "      <td>12376</td>\n",
       "      <td>0.24752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HEAT/HOT WATER</th>\n",
       "      <td>11890</td>\n",
       "      <td>0.2378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Illegal Parking</th>\n",
       "      <td>4922</td>\n",
       "      <td>0.09844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blocked Driveway</th>\n",
       "      <td>2790</td>\n",
       "      <td>0.0558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Noise - Residential</th>\n",
       "      <td>2492</td>\n",
       "      <td>0.04984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNSANITARY CONDITION</th>\n",
       "      <td>1288</td>\n",
       "      <td>0.02576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PLUMBING</th>\n",
       "      <td>1212</td>\n",
       "      <td>0.02424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAINT/PLASTER</th>\n",
       "      <td>819</td>\n",
       "      <td>0.01638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DOOR/WINDOW</th>\n",
       "      <td>773</td>\n",
       "      <td>0.01546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WATER LEAK</th>\n",
       "      <td>750</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Traffic Signal Condition</th>\n",
       "      <td>722</td>\n",
       "      <td>0.01444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Water System</th>\n",
       "      <td>549</td>\n",
       "      <td>0.01098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count    share\n",
       "complaint_type                          \n",
       "Snow or Ice               12376  0.24752\n",
       "HEAT/HOT WATER            11890   0.2378\n",
       "Illegal Parking            4922  0.09844\n",
       "Blocked Driveway           2790   0.0558\n",
       "Noise - Residential        2492  0.04984\n",
       "UNSANITARY CONDITION       1288  0.02576\n",
       "PLUMBING                   1212  0.02424\n",
       "PAINT/PLASTER               819  0.01638\n",
       "DOOR/WINDOW                 773  0.01546\n",
       "WATER LEAK                  750    0.015\n",
       "Traffic Signal Condition    722  0.01444\n",
       "Water System                549  0.01098"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def value_counts_audit(df_in: pd.DataFrame, col: str, n: int = 15) -> pd.DataFrame:\n",
    "    vc = df_in[col].astype(\"string\").value_counts(dropna=False).head(n)\n",
    "    out = vc.to_frame(\"count\")\n",
    "    out[\"share\"] = out[\"count\"] / len(df_in)\n",
    "    return out\n",
    "\n",
    "for col in [\"borough\", \"agency\", \"status\", \"complaint_type\"]:\n",
    "    if col in df.columns:\n",
    "        print(\"\\n===\", col, \"===\")\n",
    "        display(value_counts_audit(df, col, n=12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71555d5f-8224-4f9a-8a3d-f546472c3525",
   "metadata": {},
   "source": [
    "### Normalize a few high-impact fields  \n",
    "\n",
    "Do not destroy meaning - just remove noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2de4a4b-45a4-498f-aaf7-ffb325658a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After normalization:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>borough</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BROOKLYN</th>\n",
       "      <td>15654</td>\n",
       "      <td>0.31308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QUEENS</th>\n",
       "      <td>11831</td>\n",
       "      <td>0.23662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRONX</th>\n",
       "      <td>10806</td>\n",
       "      <td>0.21612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MANHATTAN</th>\n",
       "      <td>8876</td>\n",
       "      <td>0.17752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATEN ISLAND</th>\n",
       "      <td>2798</td>\n",
       "      <td>0.05596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&lt;NA&gt;</th>\n",
       "      <td>35</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count    share\n",
       "borough                      \n",
       "BROOKLYN       15654  0.31308\n",
       "QUEENS         11831  0.23662\n",
       "BRONX          10806  0.21612\n",
       "MANHATTAN       8876  0.17752\n",
       "STATEN ISLAND   2798  0.05596\n",
       "<NA>              35   0.0007"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>status</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Closed</th>\n",
       "      <td>18894</td>\n",
       "      <td>0.37788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>15728</td>\n",
       "      <td>0.31456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In Progress</th>\n",
       "      <td>15014</td>\n",
       "      <td>0.30028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assigned</th>\n",
       "      <td>203</td>\n",
       "      <td>0.00406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Started</th>\n",
       "      <td>137</td>\n",
       "      <td>0.00274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pending</th>\n",
       "      <td>22</td>\n",
       "      <td>0.00044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unspecified</th>\n",
       "      <td>2</td>\n",
       "      <td>0.00004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count    share\n",
       "status                     \n",
       "Closed       18894  0.37788\n",
       "Open         15728  0.31456\n",
       "In Progress  15014  0.30028\n",
       "Assigned       203  0.00406\n",
       "Started        137  0.00274\n",
       "Pending         22  0.00044\n",
       "Unspecified      2  0.00004"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = df_deduped.copy()\n",
    "\n",
    "# Standardize borough to a small canonical set where possible\n",
    "if \"borough\" in df2.columns:\n",
    "    df2[\"borough\"] = df2[\"borough\"].astype(\"string\").str.strip().str.upper()\n",
    "\n",
    "    # Some datasets use \"Unspecified\" or blanks\n",
    "    df2.loc[df2[\"borough\"].isin([\"\", \"NAN\", \"UNSPECIFIED\"]), \"borough\"] = pd.NA\n",
    "\n",
    "# Standardize status\n",
    "if \"status\" in df2.columns:\n",
    "    df2[\"status\"] = df2[\"status\"].astype(\"string\").str.strip().str.title()\n",
    "\n",
    "print(\"After normalization:\")\n",
    "if \"borough\" in df2.columns:\n",
    "    display(value_counts_audit(df2, \"borough\", n=10))\n",
    "if \"status\" in df2.columns:\n",
    "    display(value_counts_audit(df2, \"status\", n=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3740033-e9a2-4d9e-b938-1a4bbf21191c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status_column': {'valid_set': 'Appears to be {Open, Closed, Assigned, Pending} (verify)',\n",
       "  'cleaning_policy': \"Strip whitespace, title-case, map near-duplicates (e.g., 'CLOSED' -> 'Closed').\",\n",
       "  'rare_values': \"If rare statuses exist (<0.5%), consider grouping as 'Other' depending on analysis goal.\"}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category_policy_notes = {\n",
    "    \"status_column\": {\n",
    "        \"valid_set\": \"Appears to be {Open, Closed, Assigned, Pending} (verify)\",\n",
    "        \"cleaning_policy\": \"Strip whitespace, title-case, map near-duplicates (e.g., 'CLOSED' -> 'Closed').\",\n",
    "        \"rare_values\": \"If rare statuses exist (<0.5%), consider grouping as 'Other' depending on analysis goal.\"\n",
    "    }\n",
    "}\n",
    "category_policy_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59184f0-1f6e-46d3-849c-2f4787d000a7",
   "metadata": {},
   "source": [
    "## 2B.5 - Schema Drift: Compare Versions and Fail Safely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04370c-8f31-4162-891a-34ed5c012db5",
   "metadata": {},
   "source": [
    "Drift can show up as:\n",
    "* column added/removed\n",
    "* type changes (number - string)\n",
    "* semantic changes (same name, different meaning)\n",
    "\n",
    "We will do two comparisons.  \n",
    "1. **CSV vs JSON**\n",
    "2. **yesterday vs today simulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1031df68-7aa9-43f6-9973-cc5a68b5282e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>agency</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agency_name</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>borough</td>\n",
       "      <td>string</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>city</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>closed_date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         column           dtype\n",
       "3        agency          object\n",
       "4   agency_name          object\n",
       "8       borough          string\n",
       "12         city          object\n",
       "2   closed_date  datetime64[ns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def schema_signature(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    return pd.DataFrame({\"column\": df_in.columns, \"dtype\": [str(t) for t in df_in.dtypes]}).sort_values(\"column\")\n",
    "\n",
    "def schema_diff(sig_a: pd.DataFrame, sig_b: pd.DataFrame) -> dict:\n",
    "    a_cols = set(sig_a[\"column\"])\n",
    "    b_cols = set(sig_b[\"column\"])\n",
    "    added = sorted(list(b_cols - a_cols))\n",
    "    removed = sorted(list(a_cols - b_cols))\n",
    "\n",
    "    merged = sig_a.merge(sig_b, on=\"column\", how=\"outer\", suffixes=(\"_a\", \"_b\"))\n",
    "    changed = merged[(merged[\"dtype_a\"].notna()) & (merged[\"dtype_b\"].notna()) & (merged[\"dtype_a\"] != merged[\"dtype_b\"])]\n",
    "    return {\n",
    "        \"added\": added,\n",
    "        \"removed\": removed,\n",
    "        \"dtype_changed\": changed.sort_values(\"column\")\n",
    "    }\n",
    "\n",
    "sig_csv = schema_signature(df2)\n",
    "sig_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09edb9e9-6ec3-46e8-a6d2-e2c52ed662a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CSV vs JSON schema drift ===\n",
      "Added in JSON (vs CSV): [] \n",
      "Removed in JSON (vs CSV): [] \n",
      "\n",
      "Dtype changes (top 20):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype_a</th>\n",
       "      <th>dtype_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>borough</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>closed_date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>created_date</td>\n",
       "      <td>datetime64[ns]</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>incident_zip</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>latitude</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>longitude</td>\n",
       "      <td>float64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>status</td>\n",
       "      <td>string</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>unique_key</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          column         dtype_a dtype_b\n",
       "2        borough          string  object\n",
       "4    closed_date  datetime64[ns]  object\n",
       "6   created_date  datetime64[ns]  object\n",
       "9   incident_zip          string  object\n",
       "10      latitude         float64  object\n",
       "11     longitude         float64  object\n",
       "12        status          string  object\n",
       "14    unique_key           int64  object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if JSON_PATH.exists():\n",
    "    records = json.loads(JSON_PATH.read_text())\n",
    "    df_json = pd.json_normalize(records)\n",
    "\n",
    "    sig_json = schema_signature(df_json)\n",
    "    diff = schema_diff(sig_csv, sig_json)\n",
    "\n",
    "    print(\"=== CSV vs JSON schema drift ===\")\n",
    "    print(\"Added in JSON (vs CSV):\", diff[\"added\"][:20], \"...\" if len(diff[\"added\"])>20 else \"\")\n",
    "    print(\"Removed in JSON (vs CSV):\", diff[\"removed\"][:20], \"...\" if len(diff[\"removed\"])>20 else \"\")\n",
    "    print(\"\\nDtype changes (top 20):\")\n",
    "    display(diff[\"dtype_changed\"].head(20))\n",
    "else:\n",
    "    print(\"JSON not found. (That's okay.) Run 2.A API section to generate:\", JSON_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c4f50a-893f-4fea-a00b-f82adc972fdc",
   "metadata": {},
   "source": [
    "### Drift Simulation - intentially mutate a new version  \n",
    "\n",
    "This is what drift feels like operationally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2a9e808-1ccc-4190-8396-547ece0804e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Today vs 'new version' ===\n",
      "Added: ['incident_zipcode']\n",
      "Removed: ['incident_zip']\n",
      "\n",
      "Dtype changes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>dtype_a</th>\n",
       "      <th>dtype_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>unique_key</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        column dtype_a dtype_b\n",
       "15  unique_key   int64  object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_new = df2.copy()\n",
    "\n",
    "# Simulate drift: rename a column and change a type\n",
    "if \"incident_zip\" in df_new.columns:\n",
    "    df_new = df_new.rename(columns={\"incident_zip\": \"incident_zipcode\"})  # column rename\n",
    "\n",
    "if \"unique_key\" in df_new.columns:\n",
    "    df_new[\"unique_key\"] = df_new[\"unique_key\"].astype(str)  # type change (int -> str)\n",
    "\n",
    "sig_new = schema_signature(df_new)\n",
    "diff2 = schema_diff(sig_csv, sig_new)\n",
    "\n",
    "print(\"=== Today vs 'new version' ===\")\n",
    "print(\"Added:\", diff2[\"added\"])\n",
    "print(\"Removed:\", diff2[\"removed\"])\n",
    "print(\"\\nDtype changes:\")\n",
    "display(diff2[\"dtype_changed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76b6462e-44b6-41bb-a004-d4d22dcb80ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'required_columns': ['unique_key',\n",
       "  'created_date',\n",
       "  'complaint_type',\n",
       "  'status'],\n",
       " 'policies': {'missing_required': 'Fail hard and alert (stop pipeline).',\n",
       "  'missing_optional': 'Add column filled with nulls + log warning.',\n",
       "  'dtype_changes': 'Attempt safe coercion; if coercion fails above threshold, fail hard.'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drift_strategy_notes = {\n",
    "    \"required_columns\": [\"unique_key\", \"created_date\", \"complaint_type\", \"status\"],\n",
    "    \"policies\": {\n",
    "        \"missing_required\": \"Fail hard and alert (stop pipeline).\",\n",
    "        \"missing_optional\": \"Add column filled with nulls + log warning.\",\n",
    "        \"dtype_changes\": \"Attempt safe coercion; if coercion fails above threshold, fail hard.\"\n",
    "    }\n",
    "}\n",
    "drift_strategy_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7b16fb-9ba8-4176-b3dd-e1e5fb71ee5f",
   "metadata": {},
   "source": [
    "## 2B.6 - Deliverable: Data Quality Report (draft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce61facd-28c8-4194-8d6b-72b4bd002cb4",
   "metadata": {},
   "source": [
    "This is a short artifact that can be reused in future modules  \n",
    "\n",
    "**Include:**\n",
    "1. Row definition\n",
    "2. Biggest missingness findings + hypothesis\n",
    "3. Dedupe checks + rule\n",
    "4. Category policy note\n",
    "5. Drift Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75854273-a0ac-4f30-9ee8-f8fea6adf4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"dataset\": \"NYC 311 Service Requests (last 14 days slice)\",\n",
      "  \"generated_at_utc\": \"2026-02-01T17:16:54.060563+00:00\",\n",
      "  \"row_definition\": \"Each row represents one 311 service request (unique_key).\",\n",
      "  \"quality_notes\": {\n",
      "    \"row_definition\": \"Each row is one 311 service request (unique_key) created at created_date.\",\n",
      "    \"data_type_notes\": [\n",
      "      \"incident_zip should be treated as a string to preserve leading zeros.\",\n",
      "      \"descriptor/incident_address are free-text and likely inconsistent.\"\n",
      "    ],\n",
      "    \"completeness_issues\": [],\n",
      "    \"date_added\": \"1/30/26\"\n",
      "  },\n",
      "  \"missingness_hypothesis\": {\n",
      "    \"Column: closed_date\": \"often missing because requests are still open, or closure not required\",\n",
      "    \"More data\": \"More data\"\n",
      "  },\n",
      "  \"dedupe_notes\": {\n",
      "    \"exact_duplicates\": \"None found (or dropped them).\",\n",
      "    \"unique_key_duplicates\": \"None found (or deduped by most complete row).\",\n",
      "    \"rationale\": \"unique_key should be the request identifier; duplicates would indicate pipeline/export issues.\",\n",
      "    \"deduplication_date\": \"1/30/26\"\n",
      "  },\n",
      "  \"category_policy_notes\": {\n",
      "    \"status_column\": {\n",
      "      \"valid_set\": \"Appears to be {Open, Closed, Assigned, Pending} (verify)\",\n",
      "      \"cleaning_policy\": \"Strip whitespace, title-case, map near-duplicates (e.g., 'CLOSED' -> 'Closed').\",\n",
      "      \"rare_values\": \"If rare statuses exist (<0.5%), consider grouping as 'Other' depending on analysis goal.\"\n",
      "    }\n",
      "  },\n",
      "  \"drift_strategy_notes\": {\n",
      "    \"required_columns\": [\n",
      "      \"unique_key\",\n",
      "      \"created_date\",\n",
      "      \"complaint_type\",\n",
      "      \"status\"\n",
      "    ],\n",
      "    \"policies\": {\n",
      "      \"missing_required\": \"Fail hard and alert (stop pipeline).\",\n",
      "      \"missing_optional\": \"Add column filled with nulls + log warning.\",\n",
      "      \"dtype_changes\": \"Attempt safe coercion; if coercion fails above threshold, fail hard.\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "... (truncated preview) ...\n"
     ]
    }
   ],
   "source": [
    "report = {\n",
    "    \"dataset\": \"NYC 311 Service Requests (last 14 days slice)\",\n",
    "    \"generated_at_utc\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"row_definition\": \"Each row represents one 311 service request (unique_key).\",\n",
    "    \"quality_notes\": quality_notes,\n",
    "    \"missingness_hypothesis\": missingness_hypothesis,\n",
    "    \"dedupe_notes\": dedupe_notes,\n",
    "    \"category_policy_notes\": category_policy_notes,\n",
    "    \"drift_strategy_notes\": drift_strategy_notes,\n",
    "}\n",
    "\n",
    "print(json.dumps(report, indent=2)[:2000] + \"\\n... (truncated preview) ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dab2e8-2f87-494d-8aab-717514fd2877",
   "metadata": {},
   "source": [
    "### Save Report  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "def2cc53-dcbf-4617-8f64-9e8e86290593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved report: work/m2/data/reference/quality_report.json\n"
     ]
    }
   ],
   "source": [
    "REPORT_PATH = REF_DIR / \"quality_report.json\"\n",
    "REPORT_PATH.write_text(json.dumps(report, indent=2))\n",
    "print(\"Saved report:\", REPORT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be5efb-bf1d-445f-85d6-b2e7856c7066",
   "metadata": {},
   "source": [
    "# Module 2.C - Data Wrangling and Transformation (NYC 311)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a3f9b-ef10-4845-bf02-9de8fb369e50",
   "metadata": {},
   "source": [
    "In this module, we will:  \n",
    "1. Load the NYC 311 slice created in **2.A**\n",
    "2. Reuse the quality assumptions from **2.B** (`quality_report.json`)\n",
    "3. Perform common wrangling patterns in pandas:\n",
    "    * selecting/filtering, creating columns\n",
    "    * `groupby` + aggregation\n",
    "    * merges/joins (with guardrails)\n",
    "    * string cleanup + regex extraction\n",
    "4. Construct a baseline-friendly **feature table** and save it for later modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557c354a-b089-43f9-ad70-bf0960d05e28",
   "metadata": {},
   "source": [
    "# 2C.0 - Setup and Paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beba8f09-b8aa-4738-9555-4aac51551700",
   "metadata": {},
   "source": [
    "This notebook assumes the module workspace:  \n",
    "\n",
    "`/work/m2/data`\n",
    "\n",
    "* Raw data from **2.A**: `raw/nyc311_last14d.csv`\n",
    "* Quality report from **2.B**: `reference/quality_report.json`\n",
    "\n",
    "We will write outputs to:\n",
    "\n",
    "* `warehouse/nyc311_requests_features.parquet`\n",
    "* `warehouse/nyc311_daily_features.parquet`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2fb1f54-10ff-4b41-8fd2-b472bb3f1e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV: work/m2/data/raw/nyc311_last14d.csv | exists? True\n",
      "Report: work/m2/data/reference/quality_report.json | exists? True\n",
      "Warehouse: work/m2/data/warehouse\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "WORK_DIR   = Path(\"work\")\n",
    "MODULE_DIR = WORK_DIR / \"m2\"\n",
    "DATA_DIR = MODULE_DIR / \"data\"\n",
    "\n",
    "RAW_DIR = DATA_DIR / \"raw\"\n",
    "REF_DIR = DATA_DIR / \"reference\"\n",
    "WH_DIR  = DATA_DIR / \"warehouse\"\n",
    "\n",
    "CSV_PATH = RAW_DIR / \"nyc311_last14d.csv\"\n",
    "REPORT_PATH = REF_DIR / \"quality_report.json\"\n",
    "\n",
    "OUT_REQUESTS = WH_DIR / \"nyc311_requests_features.parquet\"\n",
    "OUT_DAILY    = WH_DIR / \"nyc311_daily_features.parquet\"\n",
    "\n",
    "print(\"CSV:\", CSV_PATH, \"| exists?\", CSV_PATH.exists())\n",
    "print(\"Report:\", REPORT_PATH, \"| exists?\", REPORT_PATH.exists())\n",
    "print(\"Warehouse:\", WH_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4896248b-787d-4c91-8887-f432e84edd8f",
   "metadata": {},
   "source": [
    "### Load the quality report from from 2.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "81c537fa-fbc8-4445-be9d-68ea4fccabd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded report generated_at_utc: 2026-02-01T17:16:54.060563+00:00\n",
      "Row definition: Each row represents one 311 service request (unique_key).\n",
      "\n",
      "Top-level keys: ['category_policy_notes', 'dataset', 'dedupe_notes', 'drift_strategy_notes', 'generated_at_utc', 'missingness_hypothesis', 'quality_notes', 'row_definition']\n"
     ]
    }
   ],
   "source": [
    "report = None\n",
    "if REPORT_PATH.exists():\n",
    "    report = json.loads(REPORT_PATH.read_text())\n",
    "    print(\"Loaded report generated_at_utc:\", report.get(\"generated_at_utc\"))\n",
    "    print(\"Row definition:\", report.get(\"row_definition\"))\n",
    "else:\n",
    "    print(\"No quality_report.json found. Run 2.B to generate it.\")\n",
    "\n",
    "# Optional: inspect notes\n",
    "if report:\n",
    "    print(\"\\nTop-level keys:\", sorted(report.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d1dfff-64f5-42a0-8679-515062163cb3",
   "metadata": {},
   "source": [
    "## 2C.1 - Load Data and Re-apply Light Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a8a84-dc3d-4849-b3f5-6f1583f1e909",
   "metadata": {},
   "source": [
    "We keep this normalization conservative and explainable.  \n",
    "\n",
    "**Row definition:** Each row represents one 311 service request, identified by `unique_key`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "932cddd9-ab12-477c-9bb4-ce49101fe09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw shape: (50000, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>status</th>\n",
       "      <th>borough</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30T01:51:21.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30T01:51:04.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOE</td>\n",
       "      <td>Department of Education</td>\n",
       "      <td>School Maintenance</td>\n",
       "      <td>Heating Problem</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11226.0</td>\n",
       "      <td>911 FLATBUSH AVENUE</td>\n",
       "      <td>FLATBUSH AVENUE</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40.649787</td>\n",
       "      <td>-73.958550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30T01:50:53.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10025.0</td>\n",
       "      <td>936 AMSTERDAM AVENUE</td>\n",
       "      <td>AMSTERDAM AVENUE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>40.800498</td>\n",
       "      <td>-73.965680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67707975</td>\n",
       "      <td>2026-01-30T01:50:52.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>10302.0</td>\n",
       "      <td>190 TRANTOR PLACE</td>\n",
       "      <td>TRANTOR PLACE</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>40.629156</td>\n",
       "      <td>-74.144411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67771794</td>\n",
       "      <td>2026-01-30T01:50:32.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Taxi and Limousine Commission</td>\n",
       "      <td>Taxi Complaint</td>\n",
       "      <td>Driver Complaint - Non Passenger</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11430.0</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JAMAICA</td>\n",
       "      <td>40.648320</td>\n",
       "      <td>-73.788281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key             created_date closed_date agency                      agency_name       complaint_type  \\\n",
       "0    67720523  2026-01-30T01:51:21.000         NaN   NYPD  New York City Police Department   Noise - Commercial   \n",
       "1    67746090  2026-01-30T01:51:04.000         NaN    DOE          Department of Education   School Maintenance   \n",
       "2    67758820  2026-01-30T01:50:53.000         NaN   NYPD  New York City Police Department  Noise - Residential   \n",
       "3    67707975  2026-01-30T01:50:52.000         NaN   NYPD  New York City Police Department  Noise - Residential   \n",
       "4    67771794  2026-01-30T01:50:32.000         NaN    TLC    Taxi and Limousine Commission       Taxi Complaint   \n",
       "\n",
       "                         descriptor       status        borough  incident_zip        incident_address             street_name  \\\n",
       "0                  Loud Music/Party  Unspecified    Unspecified           NaN                     NaN                     NaN   \n",
       "1                   Heating Problem  In Progress       BROOKLYN       11226.0     911 FLATBUSH AVENUE         FLATBUSH AVENUE   \n",
       "2                  Loud Music/Party  In Progress      MANHATTAN       10025.0    936 AMSTERDAM AVENUE        AMSTERDAM AVENUE   \n",
       "3                  Loud Music/Party  In Progress  STATEN ISLAND       10302.0       190 TRANTOR PLACE           TRANTOR PLACE   \n",
       "4  Driver Complaint - Non Passenger  In Progress         QUEENS       11430.0  JOHN F KENNEDY AIRPORT  JOHN F KENNEDY AIRPORT   \n",
       "\n",
       "            city   latitude  longitude  \n",
       "0            NaN        NaN        NaN  \n",
       "1       BROOKLYN  40.649787 -73.958550  \n",
       "2       NEW YORK  40.800498 -73.965680  \n",
       "3  STATEN ISLAND  40.629156 -74.144411  \n",
       "4        JAMAICA  40.648320 -73.788281  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(CSV_PATH)\n",
    "print(\"Raw shape:\", df_raw.shape)\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6731050-b6e3-462b-a471-93628b1e9460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized shape: (50000, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>status</th>\n",
       "      <th>borough</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30 01:51:21</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30 01:51:04</td>\n",
       "      <td>NaT</td>\n",
       "      <td>DOE</td>\n",
       "      <td>Department of Education</td>\n",
       "      <td>School Maintenance</td>\n",
       "      <td>Heating Problem</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11226.0</td>\n",
       "      <td>911 FLATBUSH AVENUE</td>\n",
       "      <td>FLATBUSH AVENUE</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40.649787</td>\n",
       "      <td>-73.958550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30 01:50:53</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10025.0</td>\n",
       "      <td>936 AMSTERDAM AVENUE</td>\n",
       "      <td>AMSTERDAM AVENUE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>40.800498</td>\n",
       "      <td>-73.965680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67707975</td>\n",
       "      <td>2026-01-30 01:50:52</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>10302.0</td>\n",
       "      <td>190 TRANTOR PLACE</td>\n",
       "      <td>TRANTOR PLACE</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>40.629156</td>\n",
       "      <td>-74.144411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67771794</td>\n",
       "      <td>2026-01-30 01:50:32</td>\n",
       "      <td>NaT</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Taxi and Limousine Commission</td>\n",
       "      <td>Taxi Complaint</td>\n",
       "      <td>Driver Complaint - Non Passenger</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11430.0</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JAMAICA</td>\n",
       "      <td>40.648320</td>\n",
       "      <td>-73.788281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key        created_date closed_date agency                      agency_name       complaint_type  \\\n",
       "0    67720523 2026-01-30 01:51:21         NaT   NYPD  New York City Police Department   Noise - Commercial   \n",
       "1    67746090 2026-01-30 01:51:04         NaT    DOE          Department of Education   School Maintenance   \n",
       "2    67758820 2026-01-30 01:50:53         NaT   NYPD  New York City Police Department  Noise - Residential   \n",
       "3    67707975 2026-01-30 01:50:52         NaT   NYPD  New York City Police Department  Noise - Residential   \n",
       "4    67771794 2026-01-30 01:50:32         NaT    TLC    Taxi and Limousine Commission       Taxi Complaint   \n",
       "\n",
       "                         descriptor       status        borough incident_zip        incident_address             street_name  \\\n",
       "0                  Loud Music/Party  Unspecified           <NA>         <NA>                     nan                     nan   \n",
       "1                   Heating Problem  In Progress       BROOKLYN      11226.0     911 FLATBUSH AVENUE         FLATBUSH AVENUE   \n",
       "2                  Loud Music/Party  In Progress      MANHATTAN      10025.0    936 AMSTERDAM AVENUE        AMSTERDAM AVENUE   \n",
       "3                  Loud Music/Party  In Progress  STATEN ISLAND      10302.0       190 TRANTOR PLACE           TRANTOR PLACE   \n",
       "4  Driver Complaint - Non Passenger  In Progress         QUEENS      11430.0  JOHN F KENNEDY AIRPORT  JOHN F KENNEDY AIRPORT   \n",
       "\n",
       "            city   latitude  longitude  \n",
       "0            nan        NaN        NaN  \n",
       "1       BROOKLYN  40.649787 -73.958550  \n",
       "2       NEW YORK  40.800498 -73.965680  \n",
       "3  STATEN ISLAND  40.629156 -74.144411  \n",
       "4        JAMAICA  40.648320 -73.788281  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conservative normalization helpers (similar spirit 2.B)\n",
    "def normalize_missing_strings(df: pd.DataFrame, missing_tokens: str[str]) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in out.columns:\n",
    "        if out[c].dtype == \"object\":\n",
    "            s = out[c].astype(str).str.strip()\n",
    "            # Replace known tokens with NaN (exact match)\n",
    "            s = s.replace({t: np.nan for t in missing_tokens})\n",
    "            out[c] = s\n",
    "    return out\n",
    "\n",
    "MISSING_TOKENS = {\"\", \" \", \"  \", \"UNKNOWN\", \"Unkown\", \"N/A\", \"NA\", \"NULL\", \"null\"}\n",
    "\n",
    "df = normalize_missing_strings(df_raw, MISSING_TOKENS)\n",
    "\n",
    "# Parse timestamps\n",
    "for c in [\"created_date\", \"closed_date\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_datetime(df[c], errors=\"coerce\")\n",
    "\n",
    "# Preserve ZIP as string (leading zeros)\n",
    "if \"incident_zip\" in df.columns:\n",
    "    df[\"incident_zip\"] = df[\"incident_zip\"].astype(\"string\")\n",
    "\n",
    "# Normalize a few key categoricals\n",
    "if \"borough\" in df.columns:\n",
    "    df[\"borough\"] = df[\"borough\"].astype(\"string\").str.strip().str.upper()\n",
    "    df.loc[df[\"borough\"].isin([\"\", \"NAN\", \"UNSPECIFIED\"]), \"borough\"] = pd.NA\n",
    "\n",
    "if \"status\" in df.columns:\n",
    "    df[\"status\"] = df[\"status\"].astype(\"string\").str.strip().str.title()\n",
    "\n",
    "print(\"Normalized shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e7a168-dd18-4f8f-a3ab-50a9a539486a",
   "metadata": {},
   "source": [
    "### Wrangling sanity checks  \n",
    "\n",
    "These prevent accidentally breaking row meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a2fd5a1-f71c-49ea-adf6-565277739554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate unique_key: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "closed_date         0.60766\n",
       "longitude           0.01222\n",
       "latitude            0.01222\n",
       "incident_zip        0.00732\n",
       "borough             0.00070\n",
       "unique_key          0.00000\n",
       "created_date        0.00000\n",
       "descriptor          0.00000\n",
       "complaint_type      0.00000\n",
       "agency_name         0.00000\n",
       "agency              0.00000\n",
       "incident_address    0.00000\n",
       "status              0.00000\n",
       "city                0.00000\n",
       "street_name         0.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert \"unique_key\" in df.columns, \"Expected unique_key column (row identifier).\"\n",
    "\n",
    "dup_keys = df[\"unique_key\"].duplicated().sum()\n",
    "print(\"Duplicate unique_key:\", int(dup_keys))\n",
    "\n",
    "missing = df.isna().mean().sort_values(ascending=False)\n",
    "missing.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff0428f-1ca5-4f9b-8d31-e7103da2f6a5",
   "metadata": {},
   "source": [
    "## 2B.2 - Pandas Fundamentals: Derived Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ce2d5b-bb50-4057-979d-c5c1db29a5b3",
   "metadata": {},
   "source": [
    "We will add a small set of readable derived fields:  \n",
    "* `created_day`(date)\n",
    "* `created_hour`, `dayofweek`, `is_weekend`\n",
    "* `is_closed`\n",
    "* `resolution_hours`(only when closed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "601fd7aa-46b0-4779-b470-d38b3990c2f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>status</th>\n",
       "      <th>is_closed</th>\n",
       "      <th>resolution_hours</th>\n",
       "      <th>resolution_negative</th>\n",
       "      <th>resolution_over_30d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30 01:51:21</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30 01:51:04</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30 01:50:53</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67707975</td>\n",
       "      <td>2026-01-30 01:50:52</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67771794</td>\n",
       "      <td>2026-01-30 01:50:32</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>67708260</td>\n",
       "      <td>2026-01-30 01:50:14</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>67771651</td>\n",
       "      <td>2026-01-30 01:48:41</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>67682527</td>\n",
       "      <td>2026-01-30 01:48:20</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>67720759</td>\n",
       "      <td>2026-01-30 01:45:16</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>67707981</td>\n",
       "      <td>2026-01-30 01:44:53</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key        created_date       status  is_closed  resolution_hours  resolution_negative  resolution_over_30d\n",
       "0    67720523 2026-01-30 01:51:21  Unspecified          0               NaN                    0                    0\n",
       "1    67746090 2026-01-30 01:51:04  In Progress          0               NaN                    0                    0\n",
       "2    67758820 2026-01-30 01:50:53  In Progress          0               NaN                    0                    0\n",
       "3    67707975 2026-01-30 01:50:52  In Progress          0               NaN                    0                    0\n",
       "4    67771794 2026-01-30 01:50:32  In Progress          0               NaN                    0                    0\n",
       "5    67708260 2026-01-30 01:50:14  In Progress          0               NaN                    0                    0\n",
       "6    67771651 2026-01-30 01:48:41  In Progress          0               NaN                    0                    0\n",
       "7    67682527 2026-01-30 01:48:20  In Progress          0               NaN                    0                    0\n",
       "8    67720759 2026-01-30 01:45:16  In Progress          0               NaN                    0                    0\n",
       "9    67707981 2026-01-30 01:44:53  In Progress          0               NaN                    0                    0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "\n",
    "df2[\"created_day\"] = df2[\"created_date\"].dt.date\n",
    "df2[\"created_hour\"] = df2[\"created_date\"].dt.hour\n",
    "df2[\"dayofweek\"] = df2[\"created_date\"].dt.dayofweek  # 0=Mon\n",
    "df2[\"is_weekend\"] = df2[\"dayofweek\"].isin([5, 6]).astype(int)\n",
    "\n",
    "df2[\"is_closed\"] = (df2[\"status\"] == \"Closed\").astype(int)\n",
    "\n",
    "df2[\"resolution_hours\"] = (df2[\"closed_date\"] - df2[\"created_date\"]).dt.total_seconds() / 3600\n",
    "df2.loc[df2[\"closed_date\"].isna(), \"resolution_hours\"] = np.nan\n",
    "\n",
    "# Flag suspicious durations (useful for later validation)\n",
    "df2[\"resolution_negative\"] = (df2[\"resolution_hours\"] < 0).astype(int)\n",
    "df2[\"resolution_over_30d\"] = (df2[\"resolution_hours\"] > (30 * 24)).astype(int)\n",
    "\n",
    "df2[[\"unique_key\",\"created_date\",\"status\",\"is_closed\",\"resolution_hours\",\"resolution_negative\",\"resolution_over_30d\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc320506-0677-4de8-be80-dd1eaf38550c",
   "metadata": {},
   "source": [
    "**Checkpoint - Row count should be unchanged**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f61d8a38-cbcf-49dc-9ccf-382edd036de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before: 50000 | after derived cols: 50000\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows before:\", len(df), \"| after derived cols:\", len(df2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6727ca3b-39a6-49ef-a347-0fb6d94a1683",
   "metadata": {},
   "source": [
    "## 2C.3 - Groupby: Build Summary Tables, Then Merge Back"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9e5524-9489-448d-b84f-b8b7187f4c9b",
   "metadata": {},
   "source": [
    "We build two summary tables:  \n",
    "1. Daily metrics (one row per day)\n",
    "2. Agency metrics (one row per agency)\n",
    "\n",
    "Then merge them back as request-level features.  \n",
    "\n",
    "**Guardrail:** Merges should not change row count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44d5c338-62bb-4875-bdc4-2e9a6c9fb2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_day</th>\n",
       "      <th>n_requests</th>\n",
       "      <th>closed_rate</th>\n",
       "      <th>median_resolution_hours</th>\n",
       "      <th>p90_resolution_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-01-27</td>\n",
       "      <td>17529</td>\n",
       "      <td>0.405557</td>\n",
       "      <td>4.092778</td>\n",
       "      <td>42.981000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-01-28</td>\n",
       "      <td>16913</td>\n",
       "      <td>0.403063</td>\n",
       "      <td>2.390000</td>\n",
       "      <td>25.913028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-01-29</td>\n",
       "      <td>15278</td>\n",
       "      <td>0.317188</td>\n",
       "      <td>1.326389</td>\n",
       "      <td>6.508389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-01-30</td>\n",
       "      <td>280</td>\n",
       "      <td>0.435714</td>\n",
       "      <td>0.480972</td>\n",
       "      <td>1.098250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  created_day  n_requests  closed_rate  median_resolution_hours  p90_resolution_hours\n",
       "0  2026-01-27       17529     0.405557                 4.092778             42.981000\n",
       "1  2026-01-28       16913     0.403063                 2.390000             25.913028\n",
       "2  2026-01-29       15278     0.317188                 1.326389              6.508389\n",
       "3  2026-01-30         280     0.435714                 0.480972              1.098250"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Daily table (unit: day)\n",
    "daily = (\n",
    "    df2.groupby(\"created_day\", dropna=False)\n",
    "       .agg(\n",
    "           n_requests=(\"unique_key\", \"count\"),\n",
    "           closed_rate=(\"is_closed\", \"mean\"),\n",
    "           median_resolution_hours=(\"resolution_hours\", \"median\"),\n",
    "           p90_resolution_hours=(\"resolution_hours\", lambda s: np.nanpercentile(s, 90) if np.isfinite(s).any() else np.nan),\n",
    "       )\n",
    "       .reset_index()\n",
    ")\n",
    "\n",
    "daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c840842-dcb1-44cc-ac6c-cdb91a60f678",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
