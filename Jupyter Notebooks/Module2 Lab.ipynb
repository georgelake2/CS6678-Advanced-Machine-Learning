{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76ffd72a-6ea0-48d3-b25b-b56146bbcaca",
   "metadata": {},
   "source": [
    "# Module 2.A - Where Data Comes From (Real-World Pipeline Starter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f781be-2019-4f56-9cdc-d0eba52a15bb",
   "metadata": {},
   "source": [
    "### Core dataset for the whole module \n",
    "\n",
    "**NYC 311 Service Requests (2020 - present)** (NYC Open Data/Socrata)  \n",
    "Why this dataset works for learning:\n",
    "* **Real mess:** missing values, inconsistent strings, free-text fields, and \"weird\" categories.\n",
    "* **Real scale:** the full dataset is huge, so must learn how to pull a *slice*\n",
    "* **Multiple access modes:** the same data is available as **CSV, API (JSON), SQL**\n",
    "* **Real change over time:** fields and value distributions can shift (schema drift)\n",
    "\n",
    "Will also create two supporting assets that will be reused later:\n",
    "* **Data dictionary Excel file:** (`.xlsx`) from the publisher (documentation)\n",
    "* **Borough reference table:** either scraped from the web or created as a seed file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ceafff-0797-4d5c-9798-ce449f63132a",
   "metadata": {},
   "source": [
    "### What will be built in 2.A  \n",
    "\n",
    "Will produce a local, module-scoped workspace. Organized by module and stored as described:  \n",
    "```bash\n",
    "~/work/m2/data/\n",
    "    raw/          # downloaded files, API responses\n",
    "    reference/    # lookup tables, dictionaries\n",
    "    warehouse/    # SQLite databases\n",
    "```\n",
    "\n",
    "Later notebooks will assume these exist:\n",
    "* **2.B** Data quality: missingness, duplicates, inconsistent categories, schema drift\n",
    "* **2.C** Wrangling: groupby, joins, string cleaning, feature construction\n",
    "* **2.D** Scaling: incremental refresh, \"raw &rarr; staged &rarr; curated\" thinking\n",
    "* **2.E** Outliers/validation: response times, anomaly checks, \"is this plausible?\" rules\n",
    "\n",
    "The goal in 2.A is not perfect cleaning. It is learning how to acquire data reliably and keep the process reproducible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a43184-3f38-4d12-b376-6bed75c45565",
   "metadata": {},
   "source": [
    "## Setup (requests, BeautifulSoup, and a writable workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810bac2c-e64d-42ea-ba60-6752e1d214b9",
   "metadata": {},
   "source": [
    "Common libraries:\n",
    "* **requests:** a simple way to make HTTP requests\n",
    "* **BeautifulSoup:** parses HTML to extract pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "460c6389-197e-4e02-8d38-00bb053b413b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writable Module 2 data workspace ready:\n",
      "  /home/glake/Nextcloud/Classwork/CS6678 - Advanced Machine Learning/Jupyter Notebooks/work/m2/data\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import sqlite3\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 60)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "# Writable workspace (module-scoped)\n",
    "WORK_DIR   = Path(\"work\")\n",
    "MODULE_DIR = WORK_DIR / \"m2\"\n",
    "DATA_DIR   = MODULE_DIR / \"data\"\n",
    "RAW_DIR    = DATA_DIR / \"raw\"\n",
    "REF_DIR    = DATA_DIR / \"reference\"\n",
    "WH_DIR     = DATA_DIR / \"warehouse\"\n",
    "\n",
    "for d in [RAW_DIR, REF_DIR, WH_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Writable Module 2 data workspace ready:\")\n",
    "print(\" \", DATA_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc54439-d0b3-4c49-aa60-bcc77c157d0d",
   "metadata": {},
   "source": [
    "## A.0 - Source Audit Template"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de33a29-bda7-45bc-8955-0015fdcc8a8f",
   "metadata": {},
   "source": [
    "Before cleaning, provide answers to:  \n",
    "* What does one row represent\n",
    "* What system produced it?\n",
    "* What time range does it cover?\n",
    "* What are known limitations?\n",
    "* Which fields look risky (missing, free-text, inconsistent categories)?\n",
    "\n",
    "We will keep a small structured dictionary of notes that can be reused later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a50976b2-57ee-4cc3-a219-1f9958393009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset_name': 'NYC 311 Service Requests (2020-present)',\n",
       " 'publisher': 'NYC Open Data / 311',\n",
       " 'where_it_comes_from': 'City 311 request intake system (customer service requests routed to agencies).',\n",
       " 'unit_of_analysis': 'Each row represents one 311 service request.',\n",
       " 'time_grain': 'Requests are created continuously; rows include timestamps for created/closed when available.',\n",
       " 'known_limitations': ['Many fields are optional depending on request type (expect missingness).',\n",
       "  'Free-text fields (descriptor/address) can be inconsistent and messy.',\n",
       "  'The dataset is continuously updated; results can change between runs.'],\n",
       " 'Notes 1/30/26': []}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_audit = {\n",
    "    \"dataset_name\": \"NYC 311 Service Requests (2020-present)\",\n",
    "    \"publisher\": \"NYC Open Data / 311\",\n",
    "    \"where_it_comes_from\": \"City 311 request intake system (customer service requests routed to agencies).\",\n",
    "    \"unit_of_analysis\": \"Each row represents one 311 service request.\", \n",
    "    \"time_grain\": \"Requests are created continuously; rows include timestamps for created/closed when available.\",\n",
    "    \"known_limitations\": [\n",
    "        \"Many fields are optional depending on request type (expect missingness).\",\n",
    "        \"Free-text fields (descriptor/address) can be inconsistent and messy.\",\n",
    "        \"The dataset is continuously updated; results can change between runs.\",\n",
    "    ],\n",
    "    \"Notes 1/30/26\": []\n",
    "}\n",
    "\n",
    "source_audit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d007fc-6579-400b-9e30-56fb78247772",
   "metadata": {},
   "source": [
    "## A.1 Files (CSV): Download a Reproducible Slice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3497e542-745e-4b3b-8108-3c315aae2f0b",
   "metadata": {},
   "source": [
    "Large public datasets are often too big to download in full for learning. A useful technique is to define a slice that is:  \n",
    "* small enough to iterate quickly (seconds, not minutes)\n",
    "* recent enough to include real mess\n",
    "* refreshable\n",
    "\n",
    "We will pull the **last 14 days** of NYC 311 requests as a CSV  \n",
    "\n",
    "**Note on Socrata Timestamps**  \n",
    "\n",
    "NYC Open Data uses Socrata. Many timestamp fields are \"floating timestamps\" and expect ISO8601 without timezone suffixes (No Z, No +00:00) in the query string. So we format timestamps like: `2026-01-04T04:03:21`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d46976b-2d28-4958-811e-4c97cbeecbce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where clause: created_date >= '2026-01-17T04:58:39'AND created_date < '2026-01-31T04:58:39'\n",
      "Downloading: https://data.cityofnewyork.us/resource/erm2-nwe9.csv\n",
      "Saved: work/m2/data/raw/nyc311_last14d.csv (12.14 MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('work/m2/data/raw/nyc311_last14d.csv')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NYC311_BASE = \"https://data.cityofnewyork.us/resource/erm2-nwe9\"\n",
    "\n",
    "# Stable subset of columns that will be reused across Module 2.\n",
    "NYC311_COLUMNS = [\n",
    "    \"unique_key\",\n",
    "    \"created_date\",\n",
    "    \"closed_date\",\n",
    "    \"agency\",\n",
    "    \"agency_name\",\n",
    "    \"complaint_type\",\n",
    "    \"descriptor\",\n",
    "    \"status\",\n",
    "    \"borough\",\n",
    "    \"incident_zip\",\n",
    "    \"incident_address\",\n",
    "    \"street_name\",\n",
    "    \"city\",\n",
    "    \"latitude\",\n",
    "    \"longitude\",\n",
    "]\n",
    "\n",
    "def iso_floating(dt: datetime) -> str:\n",
    "    \"\"\"\n",
    "    Socrata floating timestamps expect ISO8601 without timezone suffix.\n",
    "    We will drop tzinfo and milliseconds to be conservative\n",
    "    \"\"\"\n",
    "    dt = dt.astimezone(timezone.utc).replace(tzinfo=None)\n",
    "    return dt.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "\n",
    "def download_if_missing(url: str, path: Path, params: dict | None = None, timeout: int = 30) -> Path:\n",
    "    \"\"\"\n",
    "    Download a URL to disk only if the file is not already cached.\n",
    "    We chace downloads so later notebooks (2.B - 2.E) can reuse the same files\n",
    "    without hammering the public API repeatedly.\n",
    "    \"\"\"\n",
    "    if path.exists() and path.stat().st_size > 0:\n",
    "        print(\"Used cached:\", path)\n",
    "        return path\n",
    "\n",
    "    print(\"Downloading:\", url)\n",
    "    r = requests.get(url, params=params, timeout=timeout)\n",
    "\n",
    "    if r.status_code >= 400:\n",
    "        print(\"Status:\", r.status_code)\n",
    "        print(\"Body (first 300 chars):\", r.text[:300])\n",
    "\n",
    "    r.raise_for_status()\n",
    "    path.write_bytes(r.content)\n",
    "    print(\"Saved:\", path, f\"({path.stat().st_size/1e6:.2f} MB)\")\n",
    "    return path\n",
    "\n",
    "def socrata_csv_params(days: int=14, limit: int=5000) -> dict:\n",
    "    end = datetime.now(timezone.utc)\n",
    "    start = end - timedelta(days=days)\n",
    "\n",
    "    select = \",\".join(NYC311_COLUMNS)\n",
    "    where = (\n",
    "        f\"created_date >= '{iso_floating(start)}'\"\n",
    "        f\"AND created_date < '{iso_floating(end)}'\"\n",
    "    )\n",
    "    return {\"$select\": select, \"$where\": where, \"$order\": \"created_date DESC\", \"$limit\": limit}\n",
    "\n",
    "CSV_PATH = RAW_DIR / \"nyc311_last14d.csv\"\n",
    "params = socrata_csv_params(days=14, limit=50000)\n",
    "\n",
    "print(\"Where clause:\", params[\"$where\"])\n",
    "download_if_missing(f\"{NYC311_BASE}.csv\", CSV_PATH, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0752da8f-8e7d-4a99-b900-4b9a0ba78a76",
   "metadata": {},
   "source": [
    "### Load the CSV and do a quick source audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4ad1efa-5939-48e4-a37f-4dd131817495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>created_date</th>\n",
       "      <th>closed_date</th>\n",
       "      <th>agency</th>\n",
       "      <th>agency_name</th>\n",
       "      <th>complaint_type</th>\n",
       "      <th>descriptor</th>\n",
       "      <th>status</th>\n",
       "      <th>borough</th>\n",
       "      <th>incident_zip</th>\n",
       "      <th>incident_address</th>\n",
       "      <th>street_name</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67720523</td>\n",
       "      <td>2026-01-30T01:51:21.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Commercial</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>Unspecified</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67746090</td>\n",
       "      <td>2026-01-30T01:51:04.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>DOE</td>\n",
       "      <td>Department of Education</td>\n",
       "      <td>School Maintenance</td>\n",
       "      <td>Heating Problem</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>11226.0</td>\n",
       "      <td>911 FLATBUSH AVENUE</td>\n",
       "      <td>FLATBUSH AVENUE</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>40.649787</td>\n",
       "      <td>-73.958550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67758820</td>\n",
       "      <td>2026-01-30T01:50:53.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10025.0</td>\n",
       "      <td>936 AMSTERDAM AVENUE</td>\n",
       "      <td>AMSTERDAM AVENUE</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>40.800498</td>\n",
       "      <td>-73.965680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67707975</td>\n",
       "      <td>2026-01-30T01:50:52.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NYPD</td>\n",
       "      <td>New York City Police Department</td>\n",
       "      <td>Noise - Residential</td>\n",
       "      <td>Loud Music/Party</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>10302.0</td>\n",
       "      <td>190 TRANTOR PLACE</td>\n",
       "      <td>TRANTOR PLACE</td>\n",
       "      <td>STATEN ISLAND</td>\n",
       "      <td>40.629156</td>\n",
       "      <td>-74.144411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67771794</td>\n",
       "      <td>2026-01-30T01:50:32.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TLC</td>\n",
       "      <td>Taxi and Limousine Commission</td>\n",
       "      <td>Taxi Complaint</td>\n",
       "      <td>Driver Complaint - Non Passenger</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11430.0</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JOHN F KENNEDY AIRPORT</td>\n",
       "      <td>JAMAICA</td>\n",
       "      <td>40.648320</td>\n",
       "      <td>-73.788281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unique_key             created_date closed_date agency                      agency_name       complaint_type  \\\n",
       "0    67720523  2026-01-30T01:51:21.000         NaN   NYPD  New York City Police Department   Noise - Commercial   \n",
       "1    67746090  2026-01-30T01:51:04.000         NaN    DOE          Department of Education   School Maintenance   \n",
       "2    67758820  2026-01-30T01:50:53.000         NaN   NYPD  New York City Police Department  Noise - Residential   \n",
       "3    67707975  2026-01-30T01:50:52.000         NaN   NYPD  New York City Police Department  Noise - Residential   \n",
       "4    67771794  2026-01-30T01:50:32.000         NaN    TLC    Taxi and Limousine Commission       Taxi Complaint   \n",
       "\n",
       "                         descriptor       status        borough  incident_zip        incident_address             street_name  \\\n",
       "0                  Loud Music/Party  Unspecified    Unspecified           NaN                     NaN                     NaN   \n",
       "1                   Heating Problem  In Progress       BROOKLYN       11226.0     911 FLATBUSH AVENUE         FLATBUSH AVENUE   \n",
       "2                  Loud Music/Party  In Progress      MANHATTAN       10025.0    936 AMSTERDAM AVENUE        AMSTERDAM AVENUE   \n",
       "3                  Loud Music/Party  In Progress  STATEN ISLAND       10302.0       190 TRANTOR PLACE           TRANTOR PLACE   \n",
       "4  Driver Complaint - Non Passenger  In Progress         QUEENS       11430.0  JOHN F KENNEDY AIRPORT  JOHN F KENNEDY AIRPORT   \n",
       "\n",
       "            city   latitude  longitude  \n",
       "0            NaN        NaN        NaN  \n",
       "1       BROOKLYN  40.649787 -73.958550  \n",
       "2       NEW YORK  40.800498 -73.965680  \n",
       "3  STATEN ISLAND  40.629156 -74.144411  \n",
       "4        JAMAICA  40.648320 -73.788281  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv = pd.read_csv(CSV_PATH)\n",
    "df_csv.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68d17ed2-1361-4f29-bca2-02aaad41a2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_key            int64\n",
       "created_date         object\n",
       "closed_date          object\n",
       "agency               object\n",
       "agency_name          object\n",
       "complaint_type       object\n",
       "descriptor           object\n",
       "status               object\n",
       "borough              object\n",
       "incident_zip        float64\n",
       "incident_address     object\n",
       "street_name          object\n",
       "city                 object\n",
       "latitude            float64\n",
       "longitude           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd4a7a92-f774-4b08-ac6b-69ccf4556502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "closed_date         0.60766\n",
       "city                0.07640\n",
       "street_name         0.02592\n",
       "incident_address    0.02588\n",
       "latitude            0.01222\n",
       "longitude           0.01222\n",
       "incident_zip        0.00732\n",
       "descriptor          0.00680\n",
       "complaint_type      0.00000\n",
       "agency              0.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.isna().mean().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59cb715-e1f4-48d5-84a7-8fe1dcdb4557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
