{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90e5d2df-07c8-4ad3-ba4f-27f2db0b11d8",
   "metadata": {},
   "source": [
    "# WaDi A1 - Pipeline Notebook 3: Curate and Validate  \n",
    "* **Input:** Injected parquet from Notebook 2\n",
    "* **Scope:** Curates the injected dataset into a clean warehouse parquet, runs validation contracts, performs leakage audit, and writes artifacts.\n",
    "* **Output:** Warehouse parquet + validation report ready for feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018f163e-2e3d-48df-8643-4897313a6a08",
   "metadata": {},
   "source": [
    "# Stage 0 - Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a63b6-c786-46b1-a0ba-2e3931b663ab",
   "metadata": {},
   "source": [
    "## 0.1 - Imports and Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2154fd1c-d1cc-45b8-a301-5cf2c5c1b52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project:    work/wadi_A1\n",
      "Injected:   work/wadi_A1/data/injected\n",
      "Warehouse:  work/wadi_A1/data/warehouse\n",
      "Reference:  work/wadi_A1/data/reference\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "pd.set_option(\"display.width\", 180)\n",
    "\n",
    "# Paths \n",
    "WORK_DIR      = Path(\"work\")\n",
    "PROJECT_DIR   = WORK_DIR / \"wadi_A1\"\n",
    "DATA_DIR      = PROJECT_DIR / \"data\"\n",
    "INJECTED_DIR  = DATA_DIR / \"injected\"\n",
    "WH_DIR        = DATA_DIR / \"warehouse\"\n",
    "REF_DIR       = DATA_DIR / \"reference\"\n",
    "RUN_DIR       = REF_DIR / \"pipeline_runs\"\n",
    "\n",
    "for p in [WH_DIR, RUN_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Project:   \", PROJECT_DIR)\n",
    "print(\"Injected:  \", INJECTED_DIR)\n",
    "print(\"Warehouse: \", WH_DIR)\n",
    "print(\"Reference: \", REF_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12deaba8-d860-4178-8c29-97caa153da0a",
   "metadata": {},
   "source": [
    "## 0.2 - Helper Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6397a1ba-e64d-4475-9463-4e5d807e7018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Helpers ready.\n"
     ]
    }
   ],
   "source": [
    "class PipelineError(RuntimeError):\n",
    "    pass\n",
    "\n",
    "def utc_now_iso() -> str:\n",
    "    return datetime.now(timezone.utc).isoformat()\n",
    "\n",
    "def write_json(path: Path, obj: dict) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    path.write_text(json.dumps(obj, indent=2, default=str))\n",
    "\n",
    "def read_json(path: Path) -> dict:\n",
    "    return json.loads(path.read_text())\n",
    "\n",
    "print(\"Helpers ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391a1fec-73e2-4d7b-b8b6-84ccebbf9f1a",
   "metadata": {},
   "source": [
    "## 0.3 - Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85df1e85-e1b2-411e-9ae7-fa9747c2235e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:       WaDi.A1_9 Oct 2017\n",
      "Range margin:  10%\n",
      "Warn thresh:   5.0%\n",
      "Fail thresh:   20.0%\n",
      "Run ID:        20260223_142029_utc\n"
     ]
    }
   ],
   "source": [
    "DATASET_NAME = \"WaDi.A1_9 Oct 2017\"\n",
    "\n",
    "# Empirical range bound margin — applied to normal operation min/max\n",
    "RANGE_MARGIN = 0.10   # 10% margin beyond observed normal bounds\n",
    "\n",
    "# Validation thresholds\n",
    "RANGE_WARN_PCT  = 5.0   # warn if >5% of rows violate range bounds\n",
    "RANGE_FAIL_PCT  = 20.0  # fail if >20% of rows violate range bounds\n",
    "\n",
    "# Columns that must never enter the feature matrix\n",
    "FAULT_META_COLS = [\n",
    "    \"fault_type\", \"fault_sensor\", \"fault_start\",\n",
    "    \"fault_end\",  \"fault_severity\"\n",
    "]\n",
    "\n",
    "RUN_ID = datetime.now(timezone.utc).strftime(\"%Y%m%d_%H%M%S_utc\")\n",
    "\n",
    "print(f\"Dataset:       {DATASET_NAME}\")\n",
    "print(f\"Range margin:  {RANGE_MARGIN:.0%}\")\n",
    "print(f\"Warn thresh:   {RANGE_WARN_PCT}%\")\n",
    "print(f\"Fail thresh:   {RANGE_FAIL_PCT}%\")\n",
    "print(f\"Run ID:        {RUN_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf9092-3652-49eb-a2f2-6e5785962600",
   "metadata": {},
   "source": [
    "# Stage 1 - Load Injected Data  \n",
    "Loads the injected parquet from Notebook 2 and the canonical SENSOR_COLS reference from Notebook 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0adad9-a37f-416a-8e10-0dc731263bac",
   "metadata": {},
   "source": [
    "## 1.1 - Load Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d5887f2-3129-4c3d-a9fd-8af6023be1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: work/wadi_A1/data/injected/wadi_injected_20260223_141149_utc.parquet\n",
      "Shape:   (1480008, 108)\n",
      "\n",
      "Columns: ['timestamp', 'observation_day', 'seconds_since_start', 'split', 'label', '1_AIT_001_PV', '1_AIT_002_PV', '1_AIT_003_PV', '1_AIT_004_PV', '1_AIT_005_PV', '1_FIT_001_PV', '1_LT_001_PV', '1_MV_001_STATUS', '1_MV_002_STATUS', '1_MV_003_STATUS', '1_MV_004_STATUS', '1_P_001_STATUS', '1_P_003_STATUS', '1_P_005_STATUS', '1_P_006_STATUS', '2_DPIT_001_PV', '2_FIC_101_CO', '2_FIC_101_PV', '2_FIC_101_SP', '2_FIC_201_CO', '2_FIC_201_PV', '2_FIC_201_SP', '2_FIC_301_CO', '2_FIC_301_PV', '2_FIC_301_SP', '2_FIC_401_CO', '2_FIC_401_PV', '2_FIC_401_SP', '2_FIC_501_CO', '2_FIC_501_PV', '2_FIC_501_SP', '2_FIC_601_CO', '2_FIC_601_PV', '2_FIC_601_SP', '2_FIT_001_PV', '2_FIT_002_PV', '2_FIT_003_PV', '2_FQ_101_PV', '2_FQ_201_PV', '2_FQ_301_PV', '2_FQ_401_PV', '2_FQ_501_PV', '2_FQ_601_PV', '2_LS_101_AH', '2_LS_101_AL', '2_LS_201_AH', '2_LS_201_AL', '2_LS_301_AH', '2_LS_301_AL', '2_LS_401_AH', '2_LS_401_AL', '2_LS_501_AH', '2_LS_501_AL', '2_LS_601_AH', '2_LS_601_AL', '2_LT_001_PV', '2_LT_002_PV', '2_MCV_007_CO', '2_MCV_101_CO', '2_MCV_201_CO', '2_MCV_301_CO', '2_MCV_401_CO', '2_MCV_501_CO', '2_MCV_601_CO', '2_MV_003_STATUS', '2_MV_006_STATUS', '2_MV_101_STATUS', '2_MV_201_STATUS', '2_MV_301_STATUS', '2_MV_401_STATUS', '2_MV_501_STATUS', '2_MV_601_STATUS', '2_P_003_SPEED', '2_P_003_STATUS', '2_P_004_SPEED', '2_PIC_003_CO', '2_PIC_003_PV', '2_PIC_003_SP', '2_PIT_001_PV', '2_PIT_002_PV', '2_PIT_003_PV', '2A_AIT_001_PV', '2A_AIT_002_PV', '2A_AIT_003_PV', '2A_AIT_004_PV', '2B_AIT_001_PV', '2B_AIT_002_PV', '2B_AIT_003_PV', '2B_AIT_004_PV', '3_AIT_001_PV', '3_AIT_002_PV', '3_AIT_003_PV', '3_AIT_004_PV', '3_AIT_005_PV', '3_FIT_001_PV', '3_LT_001_PV', 'LEAK_DIFF_PRESSURE', 'TOTAL_CONS_REQUIRED_FLOW', 'fault_type', 'fault_sensor', 'fault_start', 'fault_end', 'fault_severity']\n"
     ]
    }
   ],
   "source": [
    "# Load most recent injected parquet\n",
    "injected_files = sorted(INJECTED_DIR.glob(\"wadi_injected_*.parquet\"))\n",
    "if not injected_files:\n",
    "    raise PipelineError(f\"No injected parquet found in {INJECTED_DIR}\")\n",
    "\n",
    "injected_path = injected_files[-1]\n",
    "print(f\"Loading: {injected_path}\")\n",
    "\n",
    "df = pd.read_parquet(injected_path)\n",
    "print(f\"Shape:   {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7a20f0-853c-4268-af96-0683e71a57b6",
   "metadata": {},
   "source": [
    "## 1.2 - Load Canonical Sensor Column List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3000aeff-dd70-4012-a152-66f03e8e8b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENSOR_COLS loaded: 98 columns\n",
      "Source run ID:      20260223_140105_utc\n",
      "All SENSOR_COLS present in injected data.\n"
     ]
    }
   ],
   "source": [
    "# Load canonical sensor column list\n",
    "sensor_cols_path = REF_DIR / \"sensor_cols.json\"\n",
    "if not sensor_cols_path.exists():\n",
    "    raise PipelineError(f\"sensor_cols.json not found at {sensor_cols_path}\")\n",
    "\n",
    "sensor_ref  = read_json(sensor_cols_path)\n",
    "SENSOR_COLS = sensor_ref[\"sensor_cols\"]\n",
    "\n",
    "print(f\"SENSOR_COLS loaded: {len(SENSOR_COLS)} columns\")\n",
    "print(f\"Source run ID:      {sensor_ref['run_id']}\")\n",
    "\n",
    "missing = [c for c in SENSOR_COLS if c not in df.columns]\n",
    "if missing:\n",
    "    raise PipelineError(f\"SENSOR_COLS missing from injected data: {missing}\")\n",
    "\n",
    "print(\"All SENSOR_COLS present in injected data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807c5146-f179-4a13-bb9b-17417731126e",
   "metadata": {},
   "source": [
    "## 1.3 - Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39005290-7b0b-43d9-bc6b-878a5df0ad19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution:\n",
      "  normal   (0): 1,209,601  (81.73%)\n",
      "  attack   (1):   172,801  (11.68%)\n",
      "  fault    (2):    97,606  (6.59%)\n",
      "\n",
      "Split distribution:\n",
      "  train : 1,307,207\n",
      "  test  :   172,801\n",
      "\n",
      "Time range: 2017-09-25 18:00:00+00:00 → 2017-10-11 18:00:00+00:00\n",
      "\n",
      "Fault metadata columns present:\n",
      "  fault_type            YES\n",
      "  fault_sensor          YES\n",
      "  fault_start           YES\n",
      "  fault_end             YES\n",
      "  fault_severity        YES\n"
     ]
    }
   ],
   "source": [
    "print(\"Label distribution:\")\n",
    "for label_val, label_name in [(0, \"normal\"), (1, \"attack\"), (2, \"fault\")]:\n",
    "    n   = (df[\"label\"] == label_val).sum()\n",
    "    pct = n / len(df) * 100\n",
    "    print(f\"  {label_name:<8} ({label_val}): {n:>9,}  ({pct:.2f}%)\")\n",
    "\n",
    "print(f\"\\nSplit distribution:\")\n",
    "for split in [\"train\", \"test\"]:\n",
    "    n = (df[\"split\"] == split).sum()\n",
    "    print(f\"  {split:<6}: {n:>9,}\")\n",
    "\n",
    "print(f\"\\nTime range: {df['timestamp'].min()} → {df['timestamp'].max()}\")\n",
    "print(f\"\\nFault metadata columns present:\")\n",
    "for col in FAULT_META_COLS:\n",
    "    present = col in df.columns\n",
    "    print(f\"  {col:<20s}  {'YES' if present else 'NO'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d399b6a7-e95c-416f-913d-d14f24d3a87c",
   "metadata": {},
   "source": [
    "# Stage 2 - Curate  \n",
    "Prepares the final warehouse dataset. Drops column that must not enter the feature matrix, enforces canonical column ordering, confirms dtypes, and writes the warehouse parquet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287dbfd1-f38b-44c6-80d8-65a3283891bc",
   "metadata": {},
   "source": [
    "## 2.1 - Drop Leakage and Metadata Columns  \n",
    "Fault metadata columns are injection artifacts. They are not observable signals in a real deployment and must not enter the feature matrix.  Dropping them here ensures downstream notebooks cannot accidentally use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd113cbf-28ed-4bb7-899c-e9601d316a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 5 fault metadata columns:\n",
      "  fault_type\n",
      "  fault_sensor\n",
      "  fault_start\n",
      "  fault_end\n",
      "  fault_severity\n",
      "\n",
      "Shape after drop: (1480008, 103)\n"
     ]
    }
   ],
   "source": [
    "# Identify columns to drop \n",
    "cols_to_drop = [c for c in FAULT_META_COLS if c in df.columns]\n",
    "\n",
    "print(f\"Dropping {len(cols_to_drop)} fault metadata columns:\")\n",
    "for c in cols_to_drop:\n",
    "    print(f\"  {c}\")\n",
    "\n",
    "df_curated = df.drop(columns=cols_to_drop)\n",
    "print(f\"\\nShape after drop: {df_curated.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29177de4-f871-4f51-a490-ffc0e2ec49ac",
   "metadata": {},
   "source": [
    "## 2.2 - Enforce Column Ordering  \n",
    "Canonical order:  \n",
    "* timestamp\n",
    "* observation_day\n",
    "* seconds_since_start\n",
    "* split\n",
    "* label\n",
    "* `SENSOR_COLS` alphabetically\n",
    "\n",
    "Consistent ordering across all notebooks prevents column mismatch bugs downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10ef31a2-8639-429b-b995-6b0e47dd4a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column ordering enforced.\n",
      "  Meta columns:   5\n",
      "  Sensor columns: 98\n",
      "  Total columns:  103\n",
      "\n",
      "First 8 columns: ['timestamp', 'observation_day', 'seconds_since_start', 'split', 'label', '1_AIT_001_PV', '1_AIT_002_PV', '1_AIT_003_PV']\n"
     ]
    }
   ],
   "source": [
    "META_COLS = [\"timestamp\", \"observation_day\", \"seconds_since_start\", \"split\", \"label\"]\n",
    "\n",
    "# Verify all expected columns are present\n",
    "missing_meta = [c for c in META_COLS if c not in df_curated.columns]\n",
    "if missing_meta:\n",
    "    raise PipelineError(f\"Missing meta columns: {missing_meta}\")\n",
    "\n",
    "missing_sensors = [c for c in SENSOR_COLS if c not in df_curated.columns]\n",
    "if missing_sensors:\n",
    "    raise PipelineError(f\"Missing sensor columns: {missing_sensors}\")\n",
    "\n",
    "# Enforce ordering\n",
    "df_curated = df_curated[META_COLS + SENSOR_COLS]\n",
    "\n",
    "print(f\"Column ordering enforced.\")\n",
    "print(f\"  Meta columns:   {len(META_COLS)}\")\n",
    "print(f\"  Sensor columns: {len(SENSOR_COLS)}\")\n",
    "print(f\"  Total columns:  {len(df_curated.columns)}\")\n",
    "print(f\"\\nFirst 8 columns: {df_curated.columns.tolist()[:8]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a637093-3f99-4f26-9e05-7627b0c0fa20",
   "metadata": {},
   "source": [
    "## 2.3 - Confirm and Cast Dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c117ef80-0dca-4983-a39c-85679bc228d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dtype summary:\n",
      "  float32          99 columns\n",
      "  object           2 columns\n",
      "  datetime64[ns, UTC]  1 columns\n",
      "  int8             1 columns\n",
      "\n",
      "Spot check:\n",
      "  label dtype:               int8\n",
      "  seconds_since_start dtype: float32\n",
      "  first sensor dtype:        float32\n"
     ]
    }
   ],
   "source": [
    "# Cast dtypes\n",
    "df_curated[\"label\"]               = df_curated[\"label\"].astype(\"int8\")\n",
    "df_curated[\"seconds_since_start\"] = df_curated[\"seconds_since_start\"].astype(\"float32\")\n",
    "\n",
    "for col in SENSOR_COLS:\n",
    "    df_curated[col] = df_curated[col].astype(\"float32\")\n",
    "\n",
    "# Report dtype summary\n",
    "dtype_counts = df_curated.dtypes.value_counts()\n",
    "print(\"Dtype summary:\")\n",
    "for dtype, count in dtype_counts.items():\n",
    "    print(f\"  {str(dtype):<15s}  {count} columns\")\n",
    "\n",
    "# Spot check\n",
    "print(f\"\\nSpot check:\")\n",
    "print(f\"  label dtype:               {df_curated['label'].dtype}\")\n",
    "print(f\"  seconds_since_start dtype: {df_curated['seconds_since_start'].dtype}\")\n",
    "print(f\"  first sensor dtype:        {df_curated[SENSOR_COLS[0]].dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8323ce6-0221-47ad-901e-8ebc00ba8234",
   "metadata": {},
   "source": [
    "## 2.4 - Resolve Timestamp Conflicts  \n",
    "When a fault window overlaps in time with a normal row at the same timestamp, the normal row is dropped. A timestamp cannot simultaneously be normal and faulted from the system classifier's perspective. Dropping the normal row produces unambiguous ground truth for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d8eec80-0616-497b-b35d-779d38e3ca4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal rows dropped due to fault timestamp conflict: 93,350\n",
      "\n",
      "Shape after deduplication: (1386658, 103)\n",
      "\n",
      "Label distribution after deduplication:\n",
      "  normal   (0): 1,116,251  (80.50%)\n",
      "  attack   (1):   172,801  (12.46%)\n",
      "  fault    (2):    97,606  (7.04%)\n"
     ]
    }
   ],
   "source": [
    "# Drop normal rows where a fault row exists at the same timestamp ────────────\n",
    "# Identify timestamps that have at least one fault row per split\n",
    "fault_timestamps_by_split = {}\n",
    "for split in [\"train\", \"test\"]:\n",
    "    fault_ts = set(\n",
    "        df_curated[\n",
    "            (df_curated[\"split\"] == split) & (df_curated[\"label\"] == 2)\n",
    "        ][\"timestamp\"].astype(str)\n",
    "    )\n",
    "    fault_timestamps_by_split[split] = fault_ts\n",
    "\n",
    "drop_mask = pd.Series(False, index=df_curated.index)\n",
    "\n",
    "for split in [\"train\", \"test\"]:\n",
    "    fault_ts = fault_timestamps_by_split[split]\n",
    "    mask = (\n",
    "        (df_curated[\"split\"] == split) &\n",
    "        (df_curated[\"label\"] == 0) &\n",
    "        (df_curated[\"timestamp\"].astype(str).isin(fault_ts))\n",
    "    )\n",
    "    drop_mask |= mask\n",
    "\n",
    "n_dropped = drop_mask.sum()\n",
    "n_normal_conflict_dropped = n_dropped\n",
    "print(f\"Normal rows dropped due to fault timestamp conflict: {n_dropped:,}\")\n",
    "\n",
    "df_curated = df_curated[~drop_mask].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nShape after deduplication: {df_curated.shape}\")\n",
    "print(f\"\\nLabel distribution after deduplication:\")\n",
    "for label_val, label_name in [(0, \"normal\"), (1, \"attack\"), (2, \"fault\")]:\n",
    "    n   = (df_curated[\"label\"] == label_val).sum()\n",
    "    pct = n / len(df_curated) * 100\n",
    "    print(f\"  {label_name:<8} ({label_val}): {n:>9,}  ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bbe3a68-524e-422e-9697-b4b6013450f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate fault rows dropped: 4,256\n",
      "Shape after fault dedup:      (1382402, 103)\n",
      "\n",
      "Label distribution:\n",
      "  normal   (0): 1,116,251  (80.75%)\n",
      "  attack   (1):   172,801  (12.50%)\n",
      "  fault    (2):    93,350  (6.75%)\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate fault rows at the same timestamp within a split ─────────────\n",
    "before = len(df_curated)\n",
    "\n",
    "# For fault rows with duplicate timestamps in same split, keep first occurrence\n",
    "fault_mask    = df_curated[\"label\"] == 2\n",
    "non_fault     = df_curated[~fault_mask]\n",
    "fault_only    = df_curated[fault_mask]\n",
    "\n",
    "fault_deduped = fault_only.drop_duplicates(\n",
    "    subset=[\"timestamp\", \"split\"], keep=\"first\"\n",
    ")\n",
    "\n",
    "df_curated = pd.concat([non_fault, fault_deduped], ignore_index=True)\n",
    "df_curated = df_curated.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "n_dropped = before - len(df_curated)\n",
    "n_fault_dup_dropped = n_dropped\n",
    "print(f\"Duplicate fault rows dropped: {n_dropped:,}\")\n",
    "print(f\"Shape after fault dedup:      {df_curated.shape}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "for label_val, label_name in [(0, \"normal\"), (1, \"attack\"), (2, \"fault\")]:\n",
    "    n   = (df_curated[\"label\"] == label_val).sum()\n",
    "    pct = n / len(df_curated) * 100\n",
    "    print(f\"  {label_name:<8} ({label_val}): {n:>9,}  ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe4f4d0-c5c4-4189-95bf-c0ddcc8b4174",
   "metadata": {},
   "source": [
    "## 2.5 - Write Warehouse Parquet  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2eb1060-b4ff-4268-b784-508dee6c35c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warehouse parquet written: work/wadi_A1/data/warehouse/wadi_curated_20260223_142029_utc.parquet\n",
      "Size:                      100.5 MB\n",
      "Shape:                     (1382402, 103)\n"
     ]
    }
   ],
   "source": [
    "wh_path = WH_DIR / f\"wadi_curated_{RUN_ID}.parquet\"\n",
    "df_curated.to_parquet(wh_path, index=False)\n",
    "\n",
    "size_mb = wh_path.stat().st_size / 1e6\n",
    "print(f\"Warehouse parquet written: {wh_path}\")\n",
    "print(f\"Size:                      {size_mb:.1f} MB\")\n",
    "print(f\"Shape:                     {df_curated.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e151630-0e28-4113-b81b-f23557a5c3a7",
   "metadata": {},
   "source": [
    "# Stage 3 - Validate  \n",
    "Runs validation contracts against the warehouse parquet. Checks are grouped into three categories:  \n",
    "* structural integrity\n",
    "* label integrity\n",
    "* sensor range plausibility\n",
    "\n",
    "Results are collected and reported together"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29656d06-e780-4fe7-ab8e-e94dd4ad0530",
   "metadata": {},
   "source": [
    "## 3.1 - Define Validation Contracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fee7b5e-0f28-401c-9a19-27b9c0b28319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation contracts defined.\n"
     ]
    }
   ],
   "source": [
    "# Validation result collector\n",
    "results = []\n",
    "\n",
    "def record(check: str, passed: bool, detail: str = \"\") -> None:\n",
    "    status = \"PASS\" if passed else \"FAIL\"\n",
    "    results.append({\"check\": check, \"status\": status, \"detail\": detail})\n",
    "    print(f\"  [{status}] {check}\" + (f\" — {detail}\" if detail else \"\"))\n",
    "\n",
    "print(\"Validation contracts defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df28257a-79b8-4ac4-95eb-981c3bb77b81",
   "metadata": {},
   "source": [
    "## 3.2 - Compute Empirical Range Bounds  \n",
    "Range bounds derived from normal operation rows in the train split only. A 10% margin is applied beyond the observed min/max to allow for natural variation in val/test normal rows without triggering false failures.  Fault and attack rows are permitted to exceed these bounds by design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2e2c006-42b6-45e9-8d5e-6bac7b78444e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range bounds computed for 98 sensors\n",
      "Source: normal train rows (1,116,251 rows)\n",
      "Margin: 10% of observed range\n"
     ]
    }
   ],
   "source": [
    "# Compute bounds from normal train rows only\n",
    "normal_train = df_curated[\n",
    "    (df_curated[\"label\"] == 0) & (df_curated[\"split\"] == \"train\")\n",
    "]\n",
    "\n",
    "sensor_bounds = {}\n",
    "for col in SENSOR_COLS:\n",
    "    series = normal_train[col].dropna()\n",
    "    if len(series) == 0:\n",
    "        continue\n",
    "    col_min = float(series.min())\n",
    "    col_max = float(series.max())\n",
    "    margin  = (col_max - col_min) * RANGE_MARGIN\n",
    "    sensor_bounds[col] = {\n",
    "        \"observed_min\": col_min,\n",
    "        \"observed_max\": col_max,\n",
    "        \"bound_min\":    col_min - margin,\n",
    "        \"bound_max\":    col_max + margin,\n",
    "    }\n",
    "\n",
    "print(f\"Range bounds computed for {len(sensor_bounds)} sensors\")\n",
    "print(f\"Source: normal train rows ({len(normal_train):,} rows)\")\n",
    "print(f\"Margin: {RANGE_MARGIN:.0%} of observed range\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62e27cd-8734-4704-9be4-08d6be009395",
   "metadata": {},
   "source": [
    "## 3.3 - Run Validation Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e3a1d67-ffe9-4353-af89-f892ec35232e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running validation checks...\n",
      "\n",
      "Structural:\n",
      "  [PASS] S1 Required columns present — 103 columns confirmed\n",
      "  [PASS] S2 No duplicate timestamps per split-label — clean\n",
      "  [PASS] S3 Fault metadata columns absent — all removed\n",
      "  [PASS] S4 Timestamps monotonic increasing — clean\n",
      "\n",
      "Label integrity:\n",
      "  [PASS] L1 Only valid label values (0,1,2) — {np.int8(0), np.int8(1), np.int8(2)}\n",
      "  [PASS] L2 Expected labels present per split — confirmed\n",
      "  [PASS] L3 No NaN labels — clean\n",
      "\n",
      "Sensor ranges (normal rows only):\n",
      "  [PASS] R1 Normal rows within empirical bounds — 0 violations (0.00%) across 0 sensors\n",
      "  [PASS] R2 Sensor NaN rate in normal rows <5% — all sensors clean\n"
     ]
    }
   ],
   "source": [
    "print(\"Running validation checks...\\n\")\n",
    "\n",
    "# Structural checks \n",
    "print(\"Structural:\")\n",
    "\n",
    "# S1: Required columns present\n",
    "required = [\"timestamp\", \"observation_day\", \"seconds_since_start\", \"split\", \"label\"]\n",
    "missing  = [c for c in required + SENSOR_COLS if c not in df_curated.columns]\n",
    "record(\"S1 Required columns present\", len(missing) == 0,\n",
    "       f\"missing: {missing}\" if missing else f\"{len(required) + len(SENSOR_COLS)} columns confirmed\")\n",
    "\n",
    "# S2: No duplicate timestamps within each split-label combination\n",
    "dup_count = 0\n",
    "for split in [\"train\", \"test\"]:\n",
    "    for label_val in [0, 1, 2]:\n",
    "        subset = df_curated[\n",
    "            (df_curated[\"split\"] == split) & (df_curated[\"label\"] == label_val)\n",
    "        ]\n",
    "        dups = subset[\"timestamp\"].duplicated().sum()\n",
    "        dup_count += dups\n",
    "record(\"S2 No duplicate timestamps per split-label\", dup_count == 0,\n",
    "       f\"{dup_count} duplicates found\" if dup_count else \"clean\")\n",
    "\n",
    "# S3: Fault metadata columns absent\n",
    "meta_present = [c for c in FAULT_META_COLS if c in df_curated.columns]\n",
    "record(\"S3 Fault metadata columns absent\", len(meta_present) == 0,\n",
    "       f\"still present: {meta_present}\" if meta_present else \"all removed\")\n",
    "\n",
    "# S4: Timestamp monotonic increasing overall\n",
    "record(\"S4 Timestamps monotonic increasing\",\n",
    "       df_curated[\"timestamp\"].is_monotonic_increasing,\n",
    "       \"not monotonic\" if not df_curated[\"timestamp\"].is_monotonic_increasing else \"clean\")\n",
    "\n",
    "# Label integrity checks \n",
    "print(\"\\nLabel integrity:\")\n",
    "\n",
    "# L1: Only valid label values\n",
    "valid_labels = {0, 1, 2}\n",
    "actual_labels = set(df_curated[\"label\"].unique())\n",
    "record(\"L1 Only valid label values (0,1,2)\", actual_labels <= valid_labels,\n",
    "       f\"unexpected: {actual_labels - valid_labels}\" if not actual_labels <= valid_labels else str(actual_labels))\n",
    "\n",
    "# L2: Expected labels present in each split\n",
    "expected_labels = {\n",
    "    \"train\": {0, 2},   # normal and fault\n",
    "    \"test\":  {1},      # attack only\n",
    "}\n",
    "all_present  = True\n",
    "detail_parts = []\n",
    "for split, exp in expected_labels.items():\n",
    "    split_labels = set(df_curated[df_curated[\"split\"] == split][\"label\"].unique())\n",
    "    if not exp.issubset(split_labels):\n",
    "        all_present = False\n",
    "        detail_parts.append(f\"{split}: expected {exp}, got {split_labels}\")\n",
    "record(\"L2 Expected labels present per split\", all_present,\n",
    "       \", \".join(detail_parts) if detail_parts else \"confirmed\")\n",
    "\n",
    "# L3: No NaN labels\n",
    "n_null_labels = df_curated[\"label\"].isna().sum()\n",
    "record(\"L3 No NaN labels\", n_null_labels == 0,\n",
    "       f\"{n_null_labels} NaN labels\" if n_null_labels else \"clean\")\n",
    "\n",
    "# Sensor range checks\n",
    "print(\"\\nSensor ranges (normal rows only):\")\n",
    "\n",
    "# R1: Normal rows within empirical bounds\n",
    "normal_rows = df_curated[df_curated[\"label\"] == 0]\n",
    "total_violations = 0\n",
    "violation_cols   = []\n",
    "\n",
    "for col, bounds in sensor_bounds.items():\n",
    "    col_data = normal_rows[col].dropna()\n",
    "    n_violations = ((col_data < bounds[\"bound_min\"]) |\n",
    "                    (col_data > bounds[\"bound_max\"])).sum()\n",
    "    if n_violations > 0:\n",
    "        total_violations += n_violations\n",
    "        violation_cols.append(col)\n",
    "\n",
    "violation_pct = total_violations / (len(normal_rows) * len(sensor_bounds)) * 100\n",
    "passed = violation_pct < RANGE_FAIL_PCT\n",
    "record(\"R1 Normal rows within empirical bounds\",\n",
    "       passed,\n",
    "       f\"{total_violations:,} violations ({violation_pct:.2f}%) across \"\n",
    "       f\"{len(violation_cols)} sensors\")\n",
    "\n",
    "# R2: Sensor NaN rate in normal rows acceptable (<5%)\n",
    "high_nan_sensors = []\n",
    "for col in SENSOR_COLS:\n",
    "    nan_pct = normal_rows[col].isna().mean() * 100\n",
    "    if nan_pct > 5.0:\n",
    "        high_nan_sensors.append(f\"{col} ({nan_pct:.1f}%)\")\n",
    "record(\"R2 Sensor NaN rate in normal rows <5%\", len(high_nan_sensors) == 0,\n",
    "       f\"high NaN: {high_nan_sensors}\" if high_nan_sensors else \"all sensors clean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2385bdd-2592-4d92-b2be-9b411e984065",
   "metadata": {},
   "source": [
    "## 3.4 - Anomaly Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a0b240a-122a-470d-bfa6-db0f6142c6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensors with any NaN values: 46 of 98\n",
      "\n",
      "Top 10 by NaN count:\n",
      "  2A_AIT_001_PV                              514  (0.04%)\n",
      "  2_FIC_601_SP                               483  (0.03%)\n",
      "  2_MCV_101_CO                               442  (0.03%)\n",
      "  2_MCV_301_CO                               420  (0.03%)\n",
      "  2_FQ_101_PV                                414  (0.03%)\n",
      "  2_FIC_401_PV                               389  (0.03%)\n",
      "  2_FQ_601_PV                                352  (0.03%)\n",
      "  2_FIC_301_SP                               340  (0.02%)\n",
      "  2_FIC_501_SP                               339  (0.02%)\n",
      "  2B_AIT_001_PV                              330  (0.02%)\n"
     ]
    }
   ],
   "source": [
    "# Overall NaN summary across all rows\n",
    "null_counts  = df_curated[SENSOR_COLS].isnull().sum()\n",
    "null_sensors = null_counts[null_counts > 0].sort_values(ascending=False)\n",
    "\n",
    "print(f\"Sensors with any NaN values: {len(null_sensors)} of {len(SENSOR_COLS)}\")\n",
    "if len(null_sensors) > 0:\n",
    "    print(f\"\\nTop 10 by NaN count:\")\n",
    "    for col, count in null_sensors.head(10).items():\n",
    "        pct = count / len(df_curated) * 100\n",
    "        print(f\"  {col:<35s}  {count:>9,}  ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c046cb-174b-4280-8a59-5fae3088d790",
   "metadata": {},
   "source": [
    "## 3.5 - Canary Checks  \n",
    "Spot checks against known dataset properties to confirm the pipeline has not silently corrupted the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fee509b7-13d8-4144-96f1-4e3a5ba97318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canary checks:\n",
      "\n",
      "  [PASS] C1 Total row count — expected 1,382,402, got 1,382,402\n",
      "  [PASS] C2 Normal row count — expected 1,116,251, got 1,116,251\n",
      "  [PASS] C3 Attack row count — expected 172,801, got 172,801\n",
      "  [PASS] C4 Dataset time range — 2017-09-25 18:00:00+00:00 → 2017-10-11 18:00:00+00:00\n",
      "  [PASS] C5 Sensor column count — expected 98, got 98\n",
      "  [PASS] C6 Fault row count — expected 93,350, got 93,350\n",
      "\n",
      "============================================================\n",
      "Validation summary: 15 passed, 0 failed\n"
     ]
    }
   ],
   "source": [
    "print(\"Canary checks:\\n\")\n",
    "\n",
    "# C1: Total row count\n",
    "expected_rows = 1_382_402\n",
    "record(\"C1 Total row count\", len(df_curated) == expected_rows,\n",
    "       f\"expected {expected_rows:,}, got {len(df_curated):,}\")\n",
    "\n",
    "# C2: Normal row count\n",
    "expected_normal = 1_116_251\n",
    "actual_normal   = (df_curated[\"label\"] == 0).sum()\n",
    "record(\"C2 Normal row count\", actual_normal == expected_normal,\n",
    "       f\"expected {expected_normal:,}, got {actual_normal:,}\")\n",
    "\n",
    "# C3: Attack row count\n",
    "expected_attack = 172801\n",
    "actual_attack   = (df_curated[\"label\"] == 1).sum()\n",
    "record(\"C3 Attack row count\", actual_attack == expected_attack,\n",
    "       f\"expected {expected_attack:,}, got {actual_attack:,}\")\n",
    "\n",
    "# C4: Dataset time range\n",
    "expected_start = pd.Timestamp(\"2017-09-25 18:00:00+00:00\")\n",
    "expected_end   = pd.Timestamp(\"2017-10-11 18:00:00+00:00\")\n",
    "record(\"C4 Dataset time range\",\n",
    "       df_curated[\"timestamp\"].min() == expected_start and\n",
    "       df_curated[\"timestamp\"].max() == expected_end,\n",
    "       f\"{df_curated['timestamp'].min()} → {df_curated['timestamp'].max()}\")\n",
    "\n",
    "# C5: Sensor column count\n",
    "record(\"C5 Sensor column count\", len(SENSOR_COLS) == 98,\n",
    "       f\"expected 98, got {len(SENSOR_COLS)}\")\n",
    "\n",
    "# C6: Fault row count\n",
    "expected_fault = 93_350\n",
    "actual_fault   = (df_curated[\"label\"] == 2).sum()\n",
    "record(\"C6 Fault row count\", actual_fault == expected_fault,\n",
    "       f\"expected {expected_fault:,}, got {actual_fault:,}\")\n",
    "\n",
    "# Validation summary \n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "passed = [r for r in results if r[\"status\"] == \"PASS\"]\n",
    "failed = [r for r in results if r[\"status\"] == \"FAIL\"]\n",
    "print(f\"Validation summary: {len(passed)} passed, {len(failed)} failed\")\n",
    "if failed:\n",
    "    print(\"\\nFailed checks:\")\n",
    "    for r in failed:\n",
    "        print(f\"  {r['check']} — {r['detail']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c58002-2f18-4405-a3b6-b37c640e2e48",
   "metadata": {},
   "source": [
    "# Stage 4 - Leakage Audit  \n",
    "Documents and closes out all deferred leakage risks identified. Each risk is explicitly resolved or accepted with justification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac04661-14eb-466a-b8be-db7c1974ce83",
   "metadata": {},
   "source": [
    "## 4.1 - Audit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6eec68bd-1062-42f5-9136-d7fc96de9612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leakage Audit\n",
      "============================================================\n",
      "\n",
      "Open (deferred to downstream): 2\n",
      "\n",
      "  [DEFERRED — OPEN]\n",
      "  Risk:       Normalization statistics computed on full dataset\n",
      "  Resolution: Normalization must be fit on train split only in the feature engineering notebook. No normalization has been applied in Notebooks 1-3.\n",
      "\n",
      "  [DEFERRED — OPEN]\n",
      "  Risk:       Rolling window features using future observations\n",
      "  Resolution: Rolling features not yet computed. Feature engineering notebook must use only backward-looking windows (no center=True in rolling calls).\n",
      "\n",
      "Closed: 6\n",
      "\n",
      "  [CLOSED]\n",
      "  Risk:       dataset_id column encoding label directly\n",
      "  Resolution: dataset_id dropped in Notebook 1 Stage 2.3 immediately after label assignment. Not present in staged, injected, or warehouse parquets.\n",
      "\n",
      "  [CLOSED]\n",
      "  Risk:       Fault metadata columns leaking injection details\n",
      "  Resolution: fault_type, fault_sensor, fault_start, fault_end, fault_severity dropped in Notebook 3 Stage 2.1. Confirmed absent by validation check S3.\n",
      "\n",
      "  [CLOSED]\n",
      "  Risk:       Fault injection using information from attack labels\n",
      "  Resolution: Fault injection in Notebook 2 operates only on normal rows (label=0). Attack rows were never used to inform fault window placement or parameters.\n",
      "\n",
      "  [CLOSED]\n",
      "  Risk:       Cross-split leakage in fault injection\n",
      "  Resolution: Fault injection run on train split only with deterministic seed (42). Test split contains only real attack rows — no synthetic faults injected into test.\n",
      "\n",
      "  [CLOSED]\n",
      "  Risk:       Temporal leakage in train/test split\n",
      "  Resolution: Split follows standard WaDi protocol: all normal operation rows assigned to train, all attack period rows assigned to test. Confirmed by temporal boundary check in Notebook 1 Stage 2.8.\n",
      "\n",
      "  [CLOSED]\n",
      "  Risk:       Time features encoding clock-based patterns\n",
      "  Resolution: Hour-of-day, day-of-week, and weekend flags excluded. Only observation_day and seconds_since_start retained. These have no physical relationship to faults or attacks.\n"
     ]
    }
   ],
   "source": [
    "leakage_audit = [\n",
    "    {\n",
    "        \"risk\": \"Normalization statistics computed on full dataset\",\n",
    "        \"status\": \"DEFERRED — OPEN\",\n",
    "        \"resolution\": \"Normalization must be fit on train split only in the \"\n",
    "                      \"feature engineering notebook. No normalization has been \"\n",
    "                      \"applied in Notebooks 1-3.\",\n",
    "    },\n",
    "    {\n",
    "        \"risk\": \"Rolling window features using future observations\",\n",
    "        \"status\": \"DEFERRED — OPEN\",\n",
    "        \"resolution\": \"Rolling features not yet computed. Feature engineering \"\n",
    "                      \"notebook must use only backward-looking windows \"\n",
    "                      \"(no center=True in rolling calls).\",\n",
    "    },\n",
    "    {\n",
    "        \"risk\": \"dataset_id column encoding label directly\",\n",
    "        \"status\": \"CLOSED\",\n",
    "        \"resolution\": \"dataset_id dropped in Notebook 1 Stage 2.3 immediately \"\n",
    "                      \"after label assignment. Not present in staged, injected, \"\n",
    "                      \"or warehouse parquets.\",\n",
    "    },\n",
    "    {\n",
    "        \"risk\": \"Fault metadata columns leaking injection details\",\n",
    "        \"status\": \"CLOSED\",\n",
    "        \"resolution\": \"fault_type, fault_sensor, fault_start, fault_end, \"\n",
    "                      \"fault_severity dropped in Notebook 3 Stage 2.1. \"\n",
    "                      \"Confirmed absent by validation check S3.\",\n",
    "    },\n",
    "    {\n",
    "        \"risk\": \"Fault injection using information from attack labels\",\n",
    "        \"status\": \"CLOSED\",\n",
    "        \"resolution\": \"Fault injection in Notebook 2 operates only on normal \"\n",
    "                      \"rows (label=0). Attack rows were never used to inform \"\n",
    "                      \"fault window placement or parameters.\",\n",
    "    },\n",
    "    {\n",
    "        \"risk\": \"Cross-split leakage in fault injection\",\n",
    "        \"status\": \"CLOSED\",\n",
    "        \"resolution\": \"Fault injection run on train split only with deterministic \"\n",
    "                      \"seed (42). Test split contains only real attack rows — \"\n",
    "                      \"no synthetic faults injected into test.\",\n",
    "    },\n",
    "    {\n",
    "        \"risk\": \"Temporal leakage in train/test split\",\n",
    "        \"status\": \"CLOSED\",\n",
    "        \"resolution\": \"Split follows standard WaDi protocol: all normal operation \"\n",
    "                      \"rows assigned to train, all attack period rows assigned to \"\n",
    "                      \"test. Confirmed by temporal boundary check in Notebook 1 \"\n",
    "                      \"Stage 2.8.\",\n",
    "    },\n",
    "    {\n",
    "        \"risk\": \"Time features encoding clock-based patterns\",\n",
    "        \"status\": \"CLOSED\",\n",
    "        \"resolution\": \"Hour-of-day, day-of-week, and weekend flags excluded. \"\n",
    "                      \"Only observation_day and seconds_since_start retained. \"\n",
    "                      \"These have no physical relationship to faults or attacks.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "print(\"Leakage Audit\")\n",
    "print(\"=\" * 60)\n",
    "open_risks   = [r for r in leakage_audit if r[\"status\"].startswith(\"DEFERRED\")]\n",
    "closed_risks = [r for r in leakage_audit if r[\"status\"].startswith(\"CLOSED\")]\n",
    "\n",
    "print(f\"\\nOpen (deferred to downstream): {len(open_risks)}\")\n",
    "for r in open_risks:\n",
    "    print(f\"\\n  [{r['status']}]\")\n",
    "    print(f\"  Risk:       {r['risk']}\")\n",
    "    print(f\"  Resolution: {r['resolution']}\")\n",
    "\n",
    "print(f\"\\nClosed: {len(closed_risks)}\")\n",
    "for r in closed_risks:\n",
    "    print(f\"\\n  [{r['status']}]\")\n",
    "    print(f\"  Risk:       {r['risk']}\")\n",
    "    print(f\"  Resolution: {r['resolution']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e16186-e488-4a91-b017-d8f9177480d5",
   "metadata": {},
   "source": [
    "# Stage 5 - Artifacts  \n",
    "Writes the validation report and run log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cefeaa-8aeb-4980-bd11-f90da2d4b234",
   "metadata": {},
   "source": [
    "## 5.1 - Validation Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2cd3040-6640-4a3d-bb06-85e052f1d458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation report written: work/wadi_A1/data/reference/validation_report_20260223_142029_utc.json\n"
     ]
    }
   ],
   "source": [
    "validation_report = {\n",
    "    \"run_id\":          RUN_ID,\n",
    "    \"created_at_utc\":  utc_now_iso(),\n",
    "    \"dataset\":         DATASET_NAME,\n",
    "    \"warehouse_file\":  str(wh_path),\n",
    "    \"validation_summary\": {\n",
    "        \"total_checks\": len(results),\n",
    "        \"passed\":       len([r for r in results if r[\"status\"] == \"PASS\"]),\n",
    "        \"failed\":       len([r for r in results if r[\"status\"] == \"FAIL\"]),\n",
    "    },\n",
    "    \"checks\":          results,\n",
    "    \"leakage_audit\": {\n",
    "        \"open\":   len(open_risks),\n",
    "        \"closed\": len(closed_risks),\n",
    "        \"items\":  leakage_audit,\n",
    "    },\n",
    "    \"dataset_summary\": {\n",
    "        \"total_rows\":    len(df_curated),\n",
    "        \"total_cols\":    len(df_curated.columns),\n",
    "        \"n_sensor_cols\": len(SENSOR_COLS),\n",
    "        \"label_counts\": {\n",
    "            int(k): int(v)\n",
    "            for k, v in df_curated[\"label\"].value_counts().sort_index().items()\n",
    "        },\n",
    "        \"split_label_counts\": {\n",
    "            split: {\n",
    "                int(k): int(v)\n",
    "                for k, v in df_curated[df_curated[\"split\"] == split][\"label\"]\n",
    "                .value_counts().sort_index().items()\n",
    "            }\n",
    "            for split in [\"train\", \"test\"]\n",
    "        },\n",
    "        \"time_start\": str(df_curated[\"timestamp\"].min()),\n",
    "        \"time_end\":   str(df_curated[\"timestamp\"].max()),\n",
    "    },\n",
    "    \"deduplication\": {\n",
    "        \"normal_rows_dropped_conflict\": int(n_normal_conflict_dropped),\n",
    "        \"fault_rows_dropped_duplicate\": int(n_fault_dup_dropped),\n",
    "        \"rationale\": (\n",
    "            \"A timestep cannot simultaneously be normal and faulted from the \"\n",
    "            \"system classifier perspective. Normal rows were dropped where a \"\n",
    "            \"fault row existed at the same timestamp. Duplicate fault rows \"\n",
    "            \"arising from multiple sensors faulted at the same second were \"\n",
    "            \"resolved by keeping the first occurrence.\"\n",
    "        ),\n",
    "    },\n",
    "}\n",
    "\n",
    "report_path = REF_DIR / f\"validation_report_{RUN_ID}.json\"\n",
    "write_json(report_path, validation_report)\n",
    "print(f\"Validation report written: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bafc74-99c2-46b6-af92-bf5da288d9cc",
   "metadata": {},
   "source": [
    "## 5.2 - Run Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f752401-d469-4717-a46c-599ae72e368d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run log written: work/wadi_A1/data/reference/pipeline_runs/run_20260223_142029_utc.json\n"
     ]
    }
   ],
   "source": [
    "run_log = {\n",
    "    \"run_id\":          RUN_ID,\n",
    "    \"created_at_utc\":  utc_now_iso(),\n",
    "    \"stage\":           \"Notebook 3 — Curate and Validate\",\n",
    "    \"dataset\":         DATASET_NAME,\n",
    "    \"inputs\": {\n",
    "        \"injected_parquet\": str(injected_path),\n",
    "        \"sensor_cols_ref\":  str(sensor_cols_path),\n",
    "    },\n",
    "    \"outputs\": {\n",
    "        \"warehouse_parquet\":  str(wh_path),\n",
    "        \"validation_report\":  str(report_path),\n",
    "    },\n",
    "    \"dataset_summary\": {\n",
    "        \"total_rows\":    len(df_curated),\n",
    "        \"total_cols\":    len(df_curated.columns),\n",
    "        \"n_sensor_cols\": len(SENSOR_COLS),\n",
    "        \"label_counts\": {\n",
    "            int(k): int(v)\n",
    "            for k, v in df_curated[\"label\"].value_counts().sort_index().items()\n",
    "        },\n",
    "    },\n",
    "    \"validation\": {\n",
    "        \"passed\": len([r for r in results if r[\"status\"] == \"PASS\"]),\n",
    "        \"failed\": len([r for r in results if r[\"status\"] == \"FAIL\"]),\n",
    "    },\n",
    "    \"leakage_audit\": {\n",
    "        \"open\":   len(open_risks),\n",
    "        \"closed\": len(closed_risks),\n",
    "    },\n",
    "    \"notes\": [\n",
    "        \"Fault metadata columns dropped — not observable signals in deployment.\",\n",
    "        \"Normal rows dropped where fault rows exist at same timestamp — \"\n",
    "        \"system-level classifier requires unambiguous ground truth.\",\n",
    "        \"Duplicate fault rows at same timestamp resolved by keeping first occurrence.\",\n",
    "        \"Two leakage risks deferred to feature engineering notebook — \"\n",
    "        \"normalization and rolling window features.\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "run_log_path = RUN_DIR / f\"run_{RUN_ID}.json\"\n",
    "write_json(run_log_path, run_log)\n",
    "print(f\"Run log written: {run_log_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a87b25-a5c5-4c9c-b0ce-e1baa42ccbee",
   "metadata": {},
   "source": [
    "# Stage 6 - Reflection\n",
    "Documents key decisions, assumptions, and risks from this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "619f9d50-42f7-4c37-8074-b4a05ea9daba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Reflection\n",
      "============================================================\n",
      "\n",
      "[Row definition]\n",
      "  Each row represents one second of sensor readings from the WaDi water distribution testbed. Label 0=normal operation, 1=cyber attack (original WaDi labels), 2=injected sensor fault. The warehouse parquet is the authoritative dataset for all downstream feature engineering and modeling.\n",
      "\n",
      "[Fault metadata removal]\n",
      "  Five fault metadata columns dropped: fault_type, fault_sensor, fault_start, fault_end, fault_severity. These are injection artifacts — not observable signals in a real deployment. Retaining them would allow the model to trivially identify fault rows without learning any sensor patterns.\n",
      "\n",
      "[Timestamp deduplication]\n",
      "  Two deduplication passes applied. First: 93,350 normal rows dropped where a fault row existed at the same timestamp — a system-level classifier requires unambiguous ground truth. Second: 4,256 duplicate fault rows dropped where multiple sensors were faulted at the same second — first occurrence kept.\n",
      "\n",
      "[Validation]\n",
      "  Validation checks run across structural, label integrity, sensor range, and canary categories. Sensor range bounds computed from train normal rows. Range check on normal rows confirms sensor values within expected bounds.\n",
      "\n",
      "[Leakage audit]\n",
      "  8 leakage risks reviewed. 6 closed with documented resolutions. 2 appropriately deferred to the feature engineering notebook: normalization must be fit on train split only, and rolling window features must use only backward-looking windows.\n",
      "\n",
      "[Final dataset composition]\n",
      "  1,382,402 total rows across 103 columns (5 meta + 98 sensors). Train: 1,116,251 normal (92.28%) and 93,350 fault (7.72%) rows. Test: 172,801 attack rows only.\n",
      "\n",
      "[Known limitations]\n",
      "  All attack rows originate from the same two-day window (Oct 9-11 2017) — an inherent constraint of the WaDi dataset structure shared across all ICS security testbed datasets. Documented as a field-wide limitation, not a methodology weakness. Synthetic faults injected into train split only — test split contains only real attack data, matching the standard WaDi evaluation protocol.\n",
      "\n",
      "[Next step]\n",
      "  Feature engineering notebook loads wadi_curated_*.parquet and computes time-window statistics and cross-sensor features. Normalization fit on train split only. Rolling windows use backward-looking windows only. Output is a feature matrix ready for model training.\n"
     ]
    }
   ],
   "source": [
    "reflection = [\n",
    "    (\"Row definition\",\n",
    "     \"Each row represents one second of sensor readings from the WaDi water \"\n",
    "     \"distribution testbed. Label 0=normal operation, 1=cyber attack (original \"\n",
    "     \"WaDi labels), 2=injected sensor fault. The warehouse parquet is the \"\n",
    "     \"authoritative dataset for all downstream feature engineering and modeling.\"),\n",
    "\n",
    "    (\"Fault metadata removal\",\n",
    "     \"Five fault metadata columns dropped: fault_type, fault_sensor, fault_start, \"\n",
    "     \"fault_end, fault_severity. These are injection artifacts — not observable \"\n",
    "     \"signals in a real deployment. Retaining them would allow the model to \"\n",
    "     \"trivially identify fault rows without learning any sensor patterns.\"),\n",
    "\n",
    "    (\"Timestamp deduplication\",\n",
    "     f\"Two deduplication passes applied. \"\n",
    "     f\"First: {n_normal_conflict_dropped:,} normal rows dropped where \"\n",
    "     f\"a fault row existed at the same timestamp — a system-level classifier \"\n",
    "     f\"requires unambiguous ground truth. \"\n",
    "     f\"Second: {n_fault_dup_dropped:,} duplicate fault rows dropped where \"\n",
    "     f\"multiple sensors were faulted at the same second — first occurrence kept.\"),\n",
    "\n",
    "    (\"Validation\",\n",
    "     \"Validation checks run across structural, label integrity, sensor range, \"\n",
    "     \"and canary categories. Sensor range bounds computed from train normal rows. \"\n",
    "     \"Range check on normal rows confirms sensor values within expected bounds.\"),\n",
    "\n",
    "    (\"Leakage audit\",\n",
    "     \"8 leakage risks reviewed. 6 closed with documented resolutions. \"\n",
    "     \"2 appropriately deferred to the feature engineering notebook: \"\n",
    "     \"normalization must be fit on train split only, and rolling window \"\n",
    "     \"features must use only backward-looking windows.\"),\n",
    "\n",
    "    (\"Final dataset composition\",\n",
    "     f\"{len(df_curated):,} total rows across {len(df_curated.columns)} columns \"\n",
    "     f\"(5 meta + {len(SENSOR_COLS)} sensors). \"\n",
    "     f\"Train: {(df_curated[df_curated['split']=='train']['label']==0).sum():,} normal \"\n",
    "     f\"({(df_curated[df_curated['split']=='train']['label']==0).mean()*100:.2f}%) and \"\n",
    "     f\"{(df_curated[df_curated['split']=='train']['label']==2).sum():,} fault \"\n",
    "     f\"({(df_curated[df_curated['split']=='train']['label']==2).mean()*100:.2f}%) rows. \"\n",
    "     f\"Test: {(df_curated['label']==1).sum():,} attack rows only.\"),\n",
    "\n",
    "    (\"Known limitations\",\n",
    "     \"All attack rows originate from the same two-day window (Oct 9-11 2017) — \"\n",
    "     \"an inherent constraint of the WaDi dataset structure shared across all ICS \"\n",
    "     \"security testbed datasets. Documented as a field-wide limitation, not a \"\n",
    "     \"methodology weakness. Synthetic faults injected into train split only — \"\n",
    "     \"test split contains only real attack data, matching the standard WaDi \"\n",
    "     \"evaluation protocol.\"),\n",
    "\n",
    "    (\"Next step\",\n",
    "     \"Feature engineering notebook loads wadi_curated_*.parquet and computes \"\n",
    "     \"time-window statistics and cross-sensor features. Normalization fit on \"\n",
    "     \"train split only. Rolling windows use backward-looking windows only. \"\n",
    "     \"Output is a feature matrix ready for model training.\"),\n",
    "]\n",
    "\n",
    "print(\"Pipeline Reflection\")\n",
    "print(\"=\" * 60)\n",
    "for title, content in reflection:\n",
    "    print(f\"\\n[{title}]\")\n",
    "    print(f\"  {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c681fc-014c-4022-9677-7533896a5833",
   "metadata": {},
   "source": [
    "# Continues in WaDi A1 - Pipeline Notebook 4: Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8bb950-a128-4d58-a9d4-90d7692a796b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml)",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
